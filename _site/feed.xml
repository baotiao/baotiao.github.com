<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>baotiao</title>
    <description>做有积累的事情</description>
    <link>http://baotiao.github.io//</link>
    <atom:link href="http://baotiao.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>swappiness 是否需要设置成0</title>
        <description>&lt;p&gt;在我们的线上机器里面, 为了避免内存对性能的影响, 经常会将 swappiness 设置成0.  这个 swappiness 具体含义是什么? 这里就能够完全避免 swap 么? 这样做好么?&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;结论:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;swappiness 的具体含义是当物理内存不够的时候, 有两种选项&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;将一部分 anonymous page 置换到 swap区&lt;/li&gt;
  &lt;li&gt;将 page cache 里面的数据刷回到磁盘, 或者直接清理掉&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这两种选项里面, 置换到swap 的权重, 但不是 swap 和 page cache 的比例, 比如 swappiness = 100 意思是swappiness 和 page cache 的比例是相同的. swappiness = 20 就是 swappiness 和 page cache 比例是1:9, 当然具体 kernle 还做的更细. 具体的计算公式就是,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;anon_prio = sc-&amp;gt;swappiness;
file_prio = 200 - sc-&amp;gt;swappiness;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;这样不能避免swap, 当内存不够的时候还是会 swap. 需要执行 swapoff -a 才是完全关闭 swap 的方法&lt;/li&gt;
  &lt;li&gt;不建议线上将 swappiness 设置成0, 因为kernel 对于该 reclaim 的页还是做了很多工作, 选择的是最不活跃的页, 而且 kernel 还会比较每一次 reclaim 的效果.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section-1&quot;&gt;具体分析&lt;/h4&gt;

&lt;p&gt;这个问题主要涉及到操作系统是如何做 page reclaim 的&lt;/p&gt;

&lt;p&gt;首先我们知道操作系统的物理页主要被两部分使用, 一部分是实际使用的物理内存, 也叫anonymous page, 另一部分是 page cache. 同时我们还有 swap 区, 用来在内存不够的时候将 anonymous page 里面的页面置换到 swap 上.&lt;/p&gt;

&lt;p&gt;那么在操作系统内存不够(下一篇文章介绍, 什么时候是内存不够的时候)的时候, 有两个选择. 一个是将 page cache里面的脏页刷回到磁盘, 将干净的页直接丢弃掉. 一个是将实际使用的物理内存里面的不常用的页刷回到 swap 区. 那么操作系统怎么做选择的?&lt;/p&gt;

&lt;p&gt;这里最重要的需要判断是否需要swap 的在 get_scan_ratio 这个函数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   这里可以看到如果把swap 给关闭了, 那么确实就不会进行swap 这个操作了
   所以这里想把 swap 完全关闭的方法应该是 swapoff -a  
	if (!sc-&amp;gt;may_swap || (nr_swap_pages &amp;lt;= 0)) {
		noswap = 1;
		percent[0] = 0;
		percent[1] = 100;
	} else
		get_scan_ratio(zone, sc, percent);

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;那么在这个get_scan_radio 里面, 就是计算这次 swap 和 page cache 的比例的时候了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
  /*
   * 首先获得anon 页的个数 和 page cache页的个数
   */
	anon  = zone_nr_lru_pages(zone, sc, LRU_ACTIVE_ANON) +
		zone_nr_lru_pages(zone, sc, LRU_INACTIVE_ANON);
	file  = zone_nr_lru_pages(zone, sc, LRU_ACTIVE_FILE) +
		zone_nr_lru_pages(zone, sc, LRU_INACTIVE_FILE);


	if (scanning_global_lru(sc)) {
		free  = zone_page_state(zone, NR_FREE_PAGES);
		/* If we have very few page cache pages,
		   force-scan anon pages. */
    /*
     * 这里就是如果我们的page cache page 和我们的 free
     * page数小于high_wmark_pages, 也就是3/2 的min_free_pages 的时候, 那么这个时候即使swapiness是0
     * 也是强制的让这次都走这个swapiness, 也就是swapiness 被设置成100
     *
     */
		if (unlikely(file + free &amp;lt;= high_wmark_pages(zone))) {
			percent[0] = 100;
			percent[1] = 0;
			return;
		}
	}
   .....

	/*
	 * With swappiness at 100, anonymous and file have the same priority.
	 * This scanning priority is essentially the inverse of IO cost.
   * 这里可以看到 swappiness 设成100的时候, 意思是从匿名页释放 page 和从 page
   * cache 里面释放 page 是相同的比例 
	 */
	anon_prio = sc-&amp;gt;swappiness;
	file_prio = 200 - sc-&amp;gt;swappiness;

	/*
   * 这里从获得了 anon 和 file 的比例以后继续的优化, 根据的是历史的 scanned 和
   * rotated page 的比例, 来计算这些 page 是否有效
   *
   * 这里比如我再 anon 区域扫描了100个 page, 然后 rotated 就是从 swap
   * 里面又置换到内存里面50 个 page, 另外我在 page cache 区域里面扫描了100个 page,
   * 又置换了10个 page, 这说明在 anon 区域里面的内容是比较经常访问的,
   * 换出去了以后又要换回内存, 所以应该尽量不要让 anno 区域里面的 page 换出 
	 */

  /*
   *   80 * 100 / 50 = 160
   *   120 * 100 / 10 = 1200
   *   percent[0] = 100 * 160 / 1360 = 11
   *   percent[1] = 89
   * 
   *   如果没有经过这一步, percent 应该是
   *   percent[0] = 80 / (80 + 120)  * 100 = 40
   *   percent[1] = 60
   * 
   *   这样可以看出这样就再一次减少了从 anon 区域 reclaim 的比例, 因为 anan里面的 page 是更经常访问的 
   */
	ap = (anon_prio + 1) * (reclaim_stat-&amp;gt;recent_scanned[0] + 1);
	ap /= reclaim_stat-&amp;gt;recent_rotated[0] + 1;

	fp = (file_prio + 1) * (reclaim_stat-&amp;gt;recent_scanned[1] + 1);
	fp /= reclaim_stat-&amp;gt;recent_rotated[1] + 1;

	/* Normalize to percentages */
	percent[0] = 100 * ap / (ap + fp + 1);
	percent[1] = 100 - percent[0];
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 01 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20memory/2016/06/01/swappiness-zero/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20memory/2016/06/01/swappiness-zero/</guid>
      </item>
    
      <item>
        <title>page reclaim wartermark</title>
        <description>&lt;p&gt;首先我们知道操作系统的物理页主要被两部分使用, 一部分是实际使用的物理内存, 也叫anonymous page, 另一部分是 page cache. 同时我们还有 swap 区, 用来在内存不够的时候将 anonymous page 里面的页面置换到 swap 上.&lt;/p&gt;

&lt;p&gt;那么kernel 什么时候认为内存是不够的, 需要做 page reclaim呢?&lt;/p&gt;

&lt;p&gt;我们通过 cat /proc/zoneinfo 可以看到这样的信息&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Node 1, zone   Normal
  pages free     19387934
        min      11289
        low      14111
        high     16933
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里这几个 min, low, high 又是什么意思?&lt;/p&gt;

&lt;p&gt;首先需要了解的一个概念是The Pool of Reserved Page Frames. 意思是每一个 zone 都需要保留一些 page frame. 为什么每一个 zone 都需要保留一些 page frames 呢? 我们知道操作系统在内存不够的时候, 可以直接进行 direct page reclaim, 回收部分的page frame, 那为什么还需要保留一些 page frames 呢?&lt;/p&gt;

&lt;p&gt;因为在 kernel 内部有一些操作是不允许切换的, 比如在处理一个中断的时候或者执行代码的某一临界区域. 在这个时候kernel 的内存申请操作必须是 atomic 的(这个在内存申请的 flag 里面有GFP_ATOMIC). 为了满足这个 atomic 内存申请的需求, 因此我们必须在每个 zone 保留一定数目的 page. 所以低于这个数目的 free pages frame 以后, kernel 就认为自己处于 low_memory 状态了. 我们管这个数叫 min_free_bytes. 那么这个数是怎么算的?&lt;/p&gt;

&lt;p&gt;每一个 zone 的初始化的时候都需要执行&lt;/p&gt;

&lt;p&gt;mm/wmark_alloc:init_per_zone_wmark_min()&lt;/p&gt;

&lt;p&gt;在init_per_zone_wmark_min 里面主要初始化设置了 min_free_kbytes&lt;/p&gt;

&lt;p&gt;The amount of the reserved memory (in kilobytes) is stored in the min_free_kbytes variable. Its initial value is set during kernel initialization and depends on the amount of physical memory that is directly mapped in the kernel’s fourth gigabyte of linear addresses—that is, it depends on the number of page frames included in the ZONE_DMA and ZONE_NORMAL memory zones:&lt;/p&gt;

&lt;p&gt;min_free_kbytes = int_sqrt(16 × directly mapped memory)     (kilobytes)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 这里 lowmem_kbytes 就是映射在操作系统的实际物理内存上面的 physical memory 的 page 数, 其实就是 ZONE_DMA + ZONE_NORMAL 的 page
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowmem_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nr_free_buffer_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wmark_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;min_free_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int_sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowmem_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;However, initially min_free_kbytes cannot be lower than 128 and greater than 65,536.&lt;/p&gt;

&lt;p&gt;这个min_free_kbytes 最大64M 最小128k,  所以一般 kernel 里面为 atomic 操作留的 page 数有几十 M. 这个 min_free_kbytes 是对于全部的 zone 而言,  因为希望满足 kernel 的 atomic 类型的内存申请操作肯定是对于全部的物理内存而言的&lt;/p&gt;

&lt;p&gt;有了这个概念以后, 我们就知道每一个 zone 里面的 wmark_min, wmark_low, wmark_high 这些 watermark 数值是什么意思了&lt;/p&gt;

&lt;p&gt;然后接下来设置wmark_min, wmark_low, wmark_high 这几个watermark 主要在setup_per_zone_wmarks() 这个函数里面&lt;/p&gt;

&lt;p&gt;那么具体的计算 wmark_min, wmark_low, wmark_high 过程&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pages_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_free_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PAGE_SHIFT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* Calculate total number of !ZONE_HIGHMEM pages */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;for_each_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_highmem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;present_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;for_each_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;spin_lock_irqsave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pages_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;present_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;do_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_MIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_LOW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_wmark_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_HIGH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_wmark_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出这里每一个 zone 的 wmark_min 的根据自己的内存大小比例分配对应百分比的 min_free_kbytes. 也就是所有 zone 的 wmark_min 加起来就是这个 min_free_kbytes&lt;/p&gt;

&lt;p&gt;wmark_low = 5/4 * wmark_min&lt;/p&gt;

&lt;p&gt;wmark_high = 3/2 * wmark_min&lt;/p&gt;

&lt;p&gt;每一个zone 还有一个reserve page, 用来限制在 high level zone 满足不了请求的情况下, low level zone 自己需要保留的page数.具体的初始化在&lt;/p&gt;

&lt;p&gt;setup_per_zone_lowmem_reserve()&lt;/p&gt;

&lt;p&gt;那么这里来理解一下设置这些wmark_min, wmark_low, wmark_high 的目的了.&lt;/p&gt;

&lt;p&gt;这里min_free_kbytes 主要是kernel 为了留给&lt;code class=&quot;highlighter-rouge&quot;&gt;__GFP_ATOMIC&lt;/code&gt; 类型的内存申请操作, 因为在操作系统里面有一些内存申请操作是不允许切换的,也就是不能在这个时候把当前这个 cpu 交给别的进程, 比如handling an interrupt or executing code inside an critical region. 那么这时候肯定也是希望kernel 内存申请操作应该是非阻塞的. 因此希望系统至少能够留下 min_free_kbytes 的空间用户&lt;code class=&quot;highlighter-rouge&quot;&gt;__GFP_ATOMIC&lt;/code&gt; 类型的内存申请操作.&lt;/p&gt;

&lt;p&gt;wmark_min 是说当前的这个空闲的 page frame 已经极地了, 当有内存申请操作的时候, 如果是非内核的内存申请操作, 那么就返回失败, 如果申请操作来自kernel, 比如调用的是 __alloc_pages_high_priority() 的时候, 就可以返回内存&lt;/p&gt;

&lt;p&gt;wmark_low 是用来唤醒 kswap 进程, 当我们某一个__alloc_pages 的时候发现 free page fram 小于 wmark_low 的时候, 就会唤醒这个kswapd 进程, 进行 page reclaim&lt;/p&gt;

&lt;p&gt;wmark_high 是当 kswapd 这个进程进行 page reclaim 了以后, 什么时候停止的标志, 只有当 page frame 大于这个 pagh_high 的时候, kswapd 进程才会停止, 继续sleep&lt;/p&gt;

&lt;p&gt;所以其实wmark_min, wmark_low, wmark_high 都是为了kernel 能够允许atomic 类型的申请操作成功服务的&lt;/p&gt;

&lt;p&gt;注: 代码都是基于 linux2.6.32版本&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20memory/2016/06/01/page-reclaim/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20memory/2016/06/01/page-reclaim/</guid>
      </item>
    
      <item>
        <title>xfs kmalloc failure problem</title>
        <description>&lt;p&gt;记录一次线上实体机的xfs kmem_alloc 操作一直失败排查&lt;/p&gt;

&lt;p&gt;Hi all:&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;问题现象&lt;/h3&gt;

&lt;p&gt;线上有些实体机dmesg出现xfs 报错&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Apr 29 21:54:31 w-openstack86 kernel: XFS: possible memory allocation deadlock in kmem_alloc (mode:0x250)
Apr 29 21:54:33 w-openstack86 kernel: XFS: possible memory allocation deadlock in kmem_alloc (mode:0x250)
Apr 29 21:54:34 w-openstack86 kernel: INFO: task qemu-system-x86:6902 blocked for more than 120 seconds.
Apr 29 21:54:34 w-openstack86 kernel: &quot;echo 0 &amp;gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.
Apr 29 21:54:34 w-openstack86 kernel: qemu-system-x86 D ffff88105065e800     0  6902      1 0x00000080
Apr 29 21:54:34 w-openstack86 kernel: ffff880155c63778 0000000000000086 ffff88099719d080 ffff880155c63fd8
Apr 29 21:54:34 w-openstack86 kernel: ffff880155c63fd8 ffff880155c63fd8 ffff88099719d080 ffff88099719d080
Apr 29 21:54:34 w-openstack86 kernel: ffff88081018de10 ffffffffffffffff ffff88081018de18 ffff88105065e800
Apr 29 21:54:34 w-openstack86 kernel: Call Trace:
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff8163a879&amp;gt;] schedule+0x29/0x70
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff8163c235&amp;gt;] rwsem_down_read_failed+0xf5/0x170
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa0256a30&amp;gt;] ? xfs_ilock_data_map_shared+0x30/0x40 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff81301764&amp;gt;] call_rwsem_down_read_failed+0x14/0x30
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff81639a90&amp;gt;] ? down_read+0x20/0x30
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa02569bc&amp;gt;] xfs_ilock+0xdc/0x120 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa0256a30&amp;gt;] xfs_ilock_data_map_shared+0x30/0x40 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f4f4&amp;gt;] __xfs_get_blocks+0x94/0x4b0 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff810654f2&amp;gt;] ? get_user_pages_fast+0x122/0x1a0
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f944&amp;gt;] xfs_get_blocks_direct+0x14/0x20 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff8121d704&amp;gt;] do_blockdev_direct_IO+0x13f4/0x2620
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff8121e985&amp;gt;] __blockdev_direct_IO+0x55/0x60
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f210&amp;gt;] ? xfs_finish_ioend_sync+0x30/0x30 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023e5ca&amp;gt;] xfs_vm_direct_IO+0xda/0x180 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa023f210&amp;gt;] ? xfs_finish_ioend_sync+0x30/0x30 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff8116afed&amp;gt;] generic_file_direct_write+0xcd/0x190
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa027f1fc&amp;gt;] xfs_file_dio_aio_write+0x1f3/0x232 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa024bd2d&amp;gt;] xfs_file_aio_write+0x13d/0x150 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff811ddde9&amp;gt;] do_sync_readv_writev+0x79/0xd0
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff811df3be&amp;gt;] do_readv_writev+0xce/0x260
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffffa024bbf0&amp;gt;] ? xfs_file_buffered_aio_write+0x260/0x260 [xfs]
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff811ddca0&amp;gt;] ? do_sync_read+0xd0/0xd0
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff810e506e&amp;gt;] ? do_futex+0xfe/0x5b0
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff811df5e5&amp;gt;] vfs_writev+0x35/0x60
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff811df9e2&amp;gt;] SyS_pwritev+0xc2/0xf0
Apr 29 21:54:34 w-openstack86 kernel: [&amp;lt;ffffffff816458c9&amp;gt;] system_call_fastpath+0x16/0x1b
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;进而导致虚拟机因为文件系统的内存申请操作出现了问题, 导致这个虚拟机挂掉&lt;/p&gt;

&lt;p&gt;解决办法:&lt;/p&gt;

&lt;p&gt;sync &amp;amp;&amp;amp; echo 3 &amp;gt; /proc/sys/vm/drop_caches&lt;/p&gt;

&lt;p&gt;将page cache 里面的内容清空, 那么就不再报错. 但是为什么简单的清空page cache 就可以解决这个问题, 如果系统被page cache 占用着难道不应该申请内存操作的时候将一部分page cache 里面的内存刷回, 然后让出部分空闲空间么?&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;看了一下代码, 出现这个报错在xfs module里面, 这个错误是在kmalloc 失败以后就会报出来, 并且会重试100次, 如果100 次以后还是失败, 就直接return error. 那么为什么kmalloc 会失败呢?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;void *
kmem_alloc(size_t size, xfs_km_flags_t flags)
{
  int retries = 0;
  gfp_t lflags = kmem_flags_convert(flags);
  void  *ptr;

  do {
    ptr = kmalloc(size, lflags);
    if (ptr || (flags &amp;amp; (KM_MAYFAIL|KM_NOSLEEP)))
      return ptr;
    if (!(++retries % 100))
      xfs_err(NULL,
    &quot;possible memory allocation deadlock in %s (mode:0x%x)&quot;,
          __func__, lflags);
    congestion_wait(BLK_RW_ASYNC, HZ/50);
  } while (1);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里首先我们必须知道如果一个操作kmalloc() 是向slab allocator 申请具体的小块的内存, 而slab allocator 是想buddy system 通过&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 去申请连续的内存. 那么肯定就是在&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 申请内存的时候失败了, 那为什么进行&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 操作的时候会失败呢? 即使实际物理内存里面还有page cache页以及swap 空间还没占满&lt;/p&gt;

&lt;p&gt;从出现问题的机器上面我们可以看到, 机器的状态大概是这个样子&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[chenzongzhi@w-openstack86 ~]$ free -m
              total        used        free      shared  buff/cache   available
Mem:          64272       26298        4379         129       33595       37051
Swap:         32255           0       32255
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里我们同时看一下机器的内存碎片状态&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;这里并不是现场的机器, 只是另一台线上内存用的差不多的机器 
[chenzongzhi@w-openstack81 ~]$ cat /proc/buddyinfo
Node 0, zone      DMA      0      0      0      1      2      1      1      0      1      1      3
Node 0, zone    DMA32   2983   2230   1037    290    121     63     47     61     16      0      0
Node 0, zone   Normal  13707   1126    285    268    291    160     64     21     11      0      0
Node 1, zone   Normal  10678   5041   1167    705    316    158     61     22      0      0      0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到这里比较大块的连续的page 是基本没有的. 因为在xfs 的申请内存操作里面我们看到有这种连续的大块的内存申请的操作的请求,  比如:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;6000:   map = kmem_alloc(subnex * sizeof(*map), KM_MAYFAIL | KM_NOFS);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;因此比较大的可能是线上虽然有少量的空闲内存, 但是这些内存非常的碎片, 因此只要有一个稍微大的的连续内存的请求都无法满足. 但是为什么不使用page cache呢?&lt;/p&gt;

&lt;p&gt;到这里. 我们可以看到整个系统的内存基本全部被使用, 有少量的空闲. 但是这里面包含了大量的page cache. 理论上page cache 里面只会包含几M的需要刷回磁盘的内容, 大量的page cache 只是为了加快读, 里面的内容应该可以随时清空掉. 所以在kmalloc申请内存的时候应该能够把page cache 里面的内容清空, 然后给kernel 留出空闲的连续的大内存空间才是. 那么为什么这次申请内存操作&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt;的时候不把page cache 里面的内容清空一部分, 然后给这次&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 预留出来空间呢?&lt;/p&gt;

&lt;p&gt;这里xfs 的申请内存操作因为是文件系统的申请内存操作, 所以一般带上GFP_NOFS 这个参数, 这个参数的意思是&lt;/p&gt;

&lt;p&gt;GFP_NOFS&lt;/p&gt;

&lt;p&gt;These flags function like GFP_KERNEL, but they add restrictions on what the kernel can do to satisfy the request. A GFP_NOFS allocation is not allowed to perform any filesystem calls, while GFP_NOIO disallows the initiation of any I/O at all. They are used primarily in the filesystem and virtual memory code where an allocation may be allowed to sleep, but recursive filesystem calls would be a bad idea.&lt;/p&gt;

&lt;p&gt;也就是说如果带上这个GFP_NOFS的flag, 那么本次 &lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 是不允许有任何的filesystem calls的操作的, 那么如果物理内存不够了, 也就是不能触发这个page_reclaim 的操作. 具体的实现是在page reclaim 的 do_try_to_free_pages 里面shrink_page_list 的时候会判断这次的scan_control 里面有没有这个 __GFP_FS flag, 如果是没有GFP_FS flag, 就不会就行这个page_reclaim&lt;/p&gt;

&lt;p&gt;为什么要这样, 因为如果在文件系统申请内存的时候, 你又触发了一次文件系统相关的操作, 比如把page cache 里面的内容刷会到文件, 那么刷会到文件这个操作必然又会有内存申请相关的操作, 这样就进入是循环了. kernel 为了避免这样的死循环尝试, 所以在文件系统相关的内存申请就不允许有任何filesystem calls. 也就是这个原因导致kernel 本身kmalloc 一直失败&lt;/p&gt;

&lt;p&gt;那么接下来 sync &amp;amp;&amp;amp; echo 3 &amp;gt; /proc/sys/vm/drop_caches 操作为什么能够成功, 并且后续就不会有报错了呢?&lt;/p&gt;

&lt;p&gt;因为drop_caches 这个操作属于外部操作, 不属于文件系统本身的操作, 因此没有GFP_NOFS这个flag, 因此可以很轻松的就把page cache 里面的内容清空, 让Kernel 有足够多的连续的大内存. 线上自然就不报错了&lt;/p&gt;

</description>
        <pubDate>Thu, 26 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20memory,%20xfs/2016/05/26/xfs-kmalloc-failure/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20memory,%20xfs/2016/05/26/xfs-kmalloc-failure/</guid>
      </item>
    
      <item>
        <title>我对存储的一些看法</title>
        <description>&lt;p&gt;其实计算机主要分成两个部分 计算 + 存储, 存储应该是计算的基石&lt;/p&gt;

&lt;p&gt;那么存储其实又主要分成两个部分 在线存储 + 离线存储&lt;/p&gt;

&lt;p&gt;离线存储的需求很统一, 就是离线数据分析, 产生报表等等. 也因为这统一的需求, 所以目前hdfs 为首的离线存储基本统一了离线存储这个平台. 离线存储最重要的就是吞吐, 以及资源的利用率. 对性能, 可靠性的要求其实并不多. (所以这也是为什么java系在离线存储这块基本一统的原因, java提供的大量的基础库, 包等等. 而离线存储又对性能, 可靠性没有比较高的要求, 因此java GC等问题也不明显)&lt;/p&gt;

&lt;p&gt;所以我们可以看到虽然现在离线的分析工具一直在变, 有hadoop, spark, storm 等等, 但是离线的存储基本都没有变化. 还是hdfs 一统这一套. 所以我认为未来离线存储这块不会有太大的变化&lt;/p&gt;

&lt;p&gt;在线存储&lt;/p&gt;

&lt;p&gt;指的是直接面向用户请求的存储类型. 由于用户请求的多样性, 因此在线存储通常需要满足各种不同场景的需求.&lt;/p&gt;

&lt;p&gt;比如用户系统存储是提供对象的服务, 能够直接通过HTTP接口来访问, 那么自然就诞生了对象存储这样的服务&lt;/p&gt;

&lt;p&gt;比如用户希望所存储的数据是关系性数据库的模型, 能够以SQL 的形式来访问, 那么其实就是mysql, 或者现在比较火热的NewSql&lt;/p&gt;

&lt;p&gt;比如用户只希望访问key, value的形式, 那么我们就可以用最简单的kv接口, 那么就有Nosql, bada, cassandra 等等就提供这样的服务&lt;/p&gt;

&lt;p&gt;当然也有多数据结构的求情, hash, list 等等就有了redis, 有POSIX文件系统接口了请求, 那么就有了CephFs. 有了希望提供跟磁盘一样的iSCSI 这样接口的快设备的需求, 就有了块存储, 就是ceph.&lt;/p&gt;

&lt;p&gt;从上面可以看到和离线存储对比, 在线存储的需求更加的复杂, 从接口类型, 从对访问延期的需求, 比如对于kv的接口, 我们一般希望是2ms左右, 那么对于对象存储的接口我们一般在10ms~20ms. 对于SQL, 我们的容忍度可能更高一些, 可以允许有100 ms. 处理延迟的需求, 我们还会有数据可靠性的不同, 比如一般在SQL 里面我们一般需要做到强一致. 但是在kv接口里面我们一般只需要做到最终一致性即可. 同样对于资源的利用也是不一样, 如果存储的是稍微偏冷的数据, 一定是EC编码, 然后存在大的机械盘. 对于线上比较热的数据, 延迟要求比较高. 一定是3副本, 存在SSD盘上&lt;/p&gt;

&lt;p&gt;从上面可以看到在线存储的需求多样性, 并且对服务的可靠性要求各种不一样, 因此我们很难看到有一个在线存储能够统一满足所有的需求. 这也是为什么现在没有一个开源的在线存储服务能够像hdfs 那样的使用率. 因此一定是在不同的场景下面有不同的存储的解决方案&lt;/p&gt;

&lt;p&gt;可以看到Facebook infrastructure stack 里面就包含的各种的在线存储需求&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/LpZw633.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如里面包含了热的大对象存储Haystack, 一般热的大对象存储f4, 图数据库Tao. key-value 存储memcached 集群等等&lt;/p&gt;

&lt;p&gt;同样google 也会有不同的在线存储产品&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/aUTxFTN.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对应于Google 有MegaStore, Spanner 用于线上的SQL 类型的在线存储, BigTable 用于类似稀疏map 的key-value存储等等&lt;/p&gt;

&lt;p&gt;个人认为对于在线存储还是比较适合C++来做这一套东西, 因为比较在线存储一般对性能, 可靠性, 延迟的要求比较高.&lt;/p&gt;

&lt;p&gt;那么这些不同的存储一般都怎么实现呢?, 很多在线存储比如对象存储的实现一般都是基于底下的key-value进行封装来实现对象存储的接口. ceph 就是这方面这个做法的极致.&lt;/p&gt;

&lt;p&gt;ceph 底下的rados 本质是一个对象存储, 这里的对象存储跟s3 的对象存储还不一样, 只是提供了存储以为key 对应的value 是对象的形式.
然后基于上层基于librados 封装了librbd 就实现了块设备的协议, 那么就是一个块存储. 基于librados 实现了Rados Gateway 提供了s3 的对象存储的协议就封装成s3对象存储. 基于librados 实现了POSIX 文件系统的接口, 就封装成了分布式文件系统Ceph FS. (不过我认为ceph 底下的rados实现的还不够纯粹, 因为rados对应的value 是类似于一个对象文件. 比如在基于librados 实现librbd的时候很多对象属性的一些方法是用不上的)
&lt;img src=&quot;http://i.imgur.com/grsvIND.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同样google 的F1 是基于spanner 的key-value 接口实现了SQL了接口. 就封装成了NewSql&lt;/p&gt;

&lt;p&gt;因此其实我们也可以这么说对于这么多接口的实现, 其实后续都会转换成基于key-value 接口实现另一种接口的形式, 因为key-value 接口足够简单, 有了稳定的key-value 存储, 只需要在上层提供不同接口转换成key-value 接口的实现即可. 当然不同的接口实现难度还是不太一样, 比如实现SQL接口, POSIX文件系统接口, 图数据库肯定要比实现一个对象存储的接口要容易很多&lt;/p&gt;

&lt;p&gt;未来我们应该也在朝这个方向做吧&lt;/p&gt;

</description>
        <pubDate>Thu, 26 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//storage,%20opnion/2016/05/26/my-opnion-of-storage/</link>
        <guid isPermaLink="true">http://baotiao.github.io//storage,%20opnion/2016/05/26/my-opnion-of-storage/</guid>
      </item>
    
      <item>
        <title>pika introduction</title>
        <description>&lt;p&gt;今天主要向大家介绍一下pika&lt;/p&gt;

&lt;p&gt;pika 是360 DBA和基础架构组联合开发的类redis 存储系统, 完全支持Redis协议，用户不需要修改任何代码, 就可以将服务迁移至pika. 有维护redis 经验的DBA 维护pika 不需要学习成本&lt;/p&gt;

&lt;p&gt;pika 主要解决的是用户使用redis的内存大小超过50G, 80G 等等这样的情况, 会遇到比如启动恢复时间长,  一主多从代价大, 硬件成本贵, 缓冲区容易写满等等问题. pika 就下针对这些场景的一个解决方案&lt;/p&gt;

&lt;p&gt;pika 目前已经开源, github地址:
https://github.com/Qihoo360/pika&lt;/p&gt;

&lt;p&gt;重点:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;pika 的单线程的性能肯定不如redis, pika是多线程的结构, 因此在线程数比较多的情况下, 某些数据结构的性能可以优于redis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pika 肯定不是完全优于redis 的方案, 只是在某些场景下面更适合. 所以目前公司内部redis, pika 是共同存在的方案, DBA会根据业务的场景挑选合适的方案&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本次分享分成4个部分&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;大容量redis 容易遇到的问题&lt;/li&gt;
  &lt;li&gt;pika 整体架构&lt;/li&gt;
  &lt;li&gt;pika 具体实现&lt;/li&gt;
  &lt;li&gt;pika vs redis&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;redis 提供了丰富的多数据结构的接口, 在redis 之前, 比如memcache 都认为后端只需要存储kv的结构就可以, 不需要感知这个value 里面的内容. 用户需要使用的话通过json_encode, json_decode 等形式进行数据的读取就行. 但是其实redis 类似做了一个微创新, redis 提供了多数据结构的支持, 让前端写代码起来更加的方便了&lt;/p&gt;

&lt;p&gt;因此redis 在公司的使用率也是越来越广泛, 用户不知不觉把越来越多的数据存储在redis中, 随着用户的使用, DBA 发现有些redis 实例的大小也是越来越大. 在redis 实例内存使用比较大的情况下, 遇到的问题也会越来越多, 因此DBA和我们一起实现了大容量redis 的解决方案&lt;/p&gt;

&lt;p&gt;最近半年公司每天redis 的访问情况 
&lt;img src=&quot;http://i.imgur.com/dpHD828.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;redis 架构方案&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/plSfqUF.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;redis-&quot;&gt;大容量redis 遇到的问题&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;恢复时间长&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们线上的redis 一般同时开启rdb 和 aof.
我们知道aof的作用是实时的记录用户的写入操作, rdb 是redis 某一时刻数据的完整快照. 那么恢复的时候一般是通过 rdb + aof 的方式进行恢复, 根据我们线上的情况 50G redis 恢复时间需要差不多70分钟&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一主多从, 主从切换代价大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;redis 在主库挂掉以后, 从库升级为新的主库. 那么切换主库以后, 所有的从库都需要跟新主做一次全同步, 全量同步一次大容量的redis, 代价非常大.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;缓冲区写满问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了防止同步缓冲区被复写，dba给redis设置了2G的巨大同步缓冲区，这对于内存资源来讲代价很大. 当由于机房之间网络有故障, 主从同步出现延迟了大于2G以后, 就会触发全同步的过程. 如果多个从库同时触发全同步的过程, 那么很容易就将主库给拖死&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;内存太贵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们一般线上使用的redis 机器是 64G, 96G. 我们只会使用80% 的空间.&lt;/p&gt;

&lt;p&gt;如果一个redis 的实例是50G, 那么基本一台机器只能运行一个redis 实例. 因此特别的浪费资源&lt;/p&gt;

&lt;p&gt;总结: 可以看到在redis 比较小的情况下, 这些问题都不是问题, 但是当redis 容量上去以后. 很多操作需要的时间也就越来越长了&lt;/p&gt;

&lt;h3 id=&quot;pika-&quot;&gt;pika 整体架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/tm5ubVp.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要组成:
1. 网络模块 pink
2. 线程模块
3. 存储引擎 nemo
4. 日志模块 binlog&lt;/p&gt;

&lt;h3 id=&quot;pink-&quot;&gt;pink 网络模块&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;基础架构团队开发网络编程库, 支持pb, redis等等协议. 对网络编程的封装, 用户实现一个高性能的server 只需要实现对应的DealMessage() 函数即可&lt;/li&gt;
  &lt;li&gt;支持单线程模型, 多线程worker模型&lt;/li&gt;
  &lt;li&gt;github 地址: https://github.com/baotiao/pink&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;线程模块&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/FdaK0H5.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;pika 基于pink 对线程进行封装. 使用多个工作线程来进行读写操作，由底层nemo引擎来保证线程安全，线程分为11种：&lt;/p&gt;

&lt;p&gt;PikaServer：主线程&lt;/p&gt;

&lt;p&gt;DispatchThread：监听端口1个端口，接收用户连接请求&lt;/p&gt;

&lt;p&gt;ClientWorker：存在多个（用户配置），每个线程里有若干个用户客户端的连接，负责接收处理用户命令并返回结果，每个线程执行写命令后，追加到binlog中&lt;/p&gt;

&lt;p&gt;Trysync：尝试与master建立首次连接，并在以后出现故障后发起重连&lt;/p&gt;

&lt;p&gt;ReplicaSender：存在多个（动态创建销毁，本master节点挂多少个slave节点就有多少个），每个线程根据slave节点发来的同步偏移量，从binlog指定的偏移开始实时同步命令给slave节点&lt;/p&gt;

&lt;p&gt;ReplicaReceiver：存在1个（动态创建销毁，一个slave节点同时只能有一个master），将用户指定或当前的偏移量发送给master节点并开始接收执行master实时发来的同步命令，在本地使用和master完全一致的偏移量来追加binlog&lt;/p&gt;

&lt;p&gt;SlavePing：slave用来向master发送心跳进行存活检测&lt;/p&gt;

&lt;p&gt;HeartBeat：master用来接收所有slave发送来的心跳并恢复进行存活检测&lt;/p&gt;

&lt;p&gt;bgsave：后台dump线程&lt;/p&gt;

&lt;p&gt;scan：后台扫描keyspace线程&lt;/p&gt;

&lt;p&gt;purge：后台删除binlog线程&lt;/p&gt;

&lt;h3 id=&quot;nemo&quot;&gt;存储引擎 nemo&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Pika 的存储引擎, 基于Rocksdb 修改. 封装Hash, List, Set, Zset等数据结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们知道redis 是需要支持多数据结构的, 而rocksdb 只是一个kv的接口, 那么我们如何实现的呢?&lt;/p&gt;

&lt;p&gt;比如对于Hash 数据结构:&lt;/p&gt;

&lt;p&gt;对于每一个Hash存储，它包括hash键（key），hash键下的域名（field）和存储的值 （value）.&lt;/p&gt;

&lt;p&gt;nemo的存储方式是将key和field组合成为一个新的key，将这个新生成的key与所要存储的value组成最终落盘的kv键值对。同时，对于每一个hash键，nemo还为它添加了一个存储元信息的落盘kv，它保存的是对应hash键下的所有域值对的个数。&lt;/p&gt;

&lt;p&gt;每个hash键、field、value到落盘kv的映射转换 
&lt;img src=&quot;http://i.imgur.com/Tlu69Dk.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个hash键的元信息的落盘kv的存储格式
&lt;img src=&quot;http://i.imgur.com/ntsReMS.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如对于List 数据结构:&lt;/p&gt;

&lt;p&gt;顾名思义，每个List结构的底层存储也是采用链表结构来完成的。对于每个List键，它的每个元素都落盘为一个kv键值对，作为一个链表的一个节点，称为元素节点。和hash一样，每个List键也拥有自己的元信息。&lt;/p&gt;

&lt;p&gt;每个元素节点对应的落盘kv存储格式 
&lt;img src=&quot;http://i.imgur.com/20RrJdm.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个元信息的落盘kv的存储格式
&lt;img src=&quot;http://i.imgur.com/n9UC9Ky.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其他的数据结构实现的方式也类似, 通过将hash_filed 拼成一个key, 存储到支持kv的rocksdb 里面去. 从而实现多数据结构的结构&lt;/p&gt;

&lt;h3 id=&quot;binlog&quot;&gt;日志模块 binlog&lt;/h3&gt;

&lt;p&gt;Pika的主从同步是使用Binlog来完成的. 
binlog 本质是顺序写文件, 通过Index + offset 进行同步点检查.&lt;/p&gt;

&lt;p&gt;解决了同步缓冲区太小的问题&lt;/p&gt;

&lt;p&gt;支持全同步 + 增量同步&lt;/p&gt;

&lt;p&gt;master 执行完一条写命令就将命令追加到Binlog中，ReplicaSender将这条命令从Binlog中读出来发送给slave，slave的ReplicaReceiver收到该命令，执行，并追加到自己的Binlog中.&lt;/p&gt;

&lt;p&gt;当发生主从切换以后, slave仅需要将自己当前的Binlog Index + offset 发送给master，master找到后从该偏移量开始同步后续命令&lt;/p&gt;

&lt;p&gt;为了防止读文件中写错一个字节则导致整个文件不可用，所以pika采用了类似leveldb log的格式来进行存储，具体如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/x1H8loY.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;主要功能&lt;/h3&gt;

&lt;p&gt;pika 线上架构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/V4Ufgh1.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;主从架构&lt;/h3&gt;

&lt;p&gt;旁白: 为了减少用户的学习成本, 目前pika 的主从同步功能是和redis完全一样, 只需要slaveof 就可以实现主从关系的建立, 使用起来非常方便&lt;/p&gt;

&lt;p&gt;背景
1. Pika Replicate&lt;/p&gt;

&lt;p&gt;pika支持master/slave的复制方式，通过slave端的slaveof命令激发
salve端处理slaveof命令，将当前状态变为slave，改变连接状态
slave的trysync线程向master发起trysync，同时将要同步点传给master
master处理trysync命令，发起对slave的同步过程，从同步点开始顺序发送binlog或进行全同步&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Binlog&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pika同步依赖binlog
binlog文件会自动或手动删除
当同步点对应的binlog文件不存在时，需要通过全同步进行数据同步&lt;/p&gt;

&lt;p&gt;全同步&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;简介&lt;/p&gt;

    &lt;p&gt;需要进行全同步时，master会将db文件dump后发送给slave
 通过rsync的deamon模式实现db文件的传输&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;实现逻辑&lt;/p&gt;

    &lt;p&gt;slave在trysnc前启动rsync进程启动rsync服务
 master发现需要全同步时，判断是否有备份文件可用，如果没有先dump一份
 master通过rsync向slave发送dump出的文件
 slave用收到的文件替换自己的db
 slave用最新的偏移量再次发起trysnc
 完成同步&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/AvOKHHg.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Slave连接状态&lt;/p&gt;

    &lt;p&gt;No Connect：不尝试成为任何其他节点的slave
 Connect：Slaveof后尝试成为某个节点的slave，发送trysnc命令和同步点
 Connecting：收到master回复可以slaveof，尝试跟master建立心跳
 Connected: 心跳建立成功
 WaitSync：不断检测是否DBSync完成，完成后更新DB并发起新的slaveof&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/ffummqK.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;主从命令同步&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/YjYMsCd.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图1是一个主从同步的一个过程（即根据主节点数据库的操作日志，将主节点数据库的改变过程顺序的映射到从节点的数据库上），从图1中可以看出，每一个从节点在主节点下都有一个唯一对应的BinlogSenderThread。&lt;/p&gt;

&lt;p&gt;（为了说明方便，我们定一个“同步命令”的概念，即会改变数据库的命令，如set，hset，lpush等，而get，hget，lindex则不是）&lt;/p&gt;

&lt;p&gt;主要模块的功能：&lt;/p&gt;

&lt;p&gt;WorkerThread：接受和处理用户的命令；&lt;/p&gt;

&lt;p&gt;BinlogSenderThread：负责顺序地向对应的从节点发送在需要同步的命令；&lt;/p&gt;

&lt;p&gt;BinlogReceiverModule: 负责接受主节点发送过来的同步命令&lt;/p&gt;

&lt;p&gt;Binglog：用于顺序的记录需要同步的命令&lt;/p&gt;

&lt;p&gt;主要的工作过程：
1.当WorkerThread接收到客户端的命令，按照执行顺序，添加到Binlog里；&lt;/p&gt;

&lt;p&gt;2.BinglogSenderThread判断它所负责的从节点在主节点的Binlog里是否有需要同步的命令，若有则发送给从节点；&lt;/p&gt;

&lt;p&gt;3.BinglogReceiverModule模块则做以下三件事情：
    a. 接收主节点的BinlogSenderThread发送过来的同步命令；
    b. 把接收到的命令应用到本地的数据上；
    c. 把接收到的命令添加到本地Binlog里&lt;/p&gt;

&lt;p&gt;至此，一条命令从主节点到从节点的同步过程完成&lt;/p&gt;

&lt;p&gt;BinLogReceiverModule的工作过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/mgIB0P8.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图2是BinLogReceiverModule（在源代码中没有这个对象，这里是为了说明方便，抽象出来的）的组成，从图2中可以看出BinlogReceiverModule由一个BinlogReceiverThread和多个BinlogBGWorker组成。&lt;/p&gt;

&lt;p&gt;BinlogReceiverThread: 负责接受由主节点传送过来的命令，并分发给各个BinlogBGWorker，若当前的节点是只读状态（不能接受客户端的同步命令），则在这个阶段写Binlog&lt;/p&gt;

&lt;p&gt;BinlogBGWorker：负责执行同步命令；若该节点不是只读状态（还能接受客户端的同步命令），则在这个阶段写Binlog（在命令执行之前写）&lt;/p&gt;

&lt;p&gt;BinlogReceiverThread接收到一个同步命令后，它会给这个命令赋予一个唯一的序列号（这个序列号是递增的），并把它分发给一个BinlogBGWorker；而各个BinlogBGWorker则会根据各个命令的所对应的序列号的顺序来执行各个命令，这样也就保证了命令执行的顺序和主节点执行的顺序一致了&lt;/p&gt;

&lt;p&gt;之所以这么设计主要原因是：
        a. 配备多个BinlogBGWorker是可以提高主从同步的效率，减少主从同步的滞后延迟；
        b. 让BinlogBGWorker在执行执行之前写Binlog可以提高命令执行的并行度；
        c. 在当前节点是非只读状态，让BinglogReceiverThread来写Binlog，是为了让Binglog里保存的命令顺序和命令的执行顺序保持一致；&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;数据备份&lt;/h4&gt;

&lt;p&gt;不同于Redis，Pika的数据主要存储在磁盘中，这就使得其在做数据备份时有天然的优势，可以直接通过文件拷贝实现&lt;/p&gt;

&lt;p&gt;流程: 
    打快照：阻写，并在这个过程中或的快照内容
    异步线程拷贝文件：通过修改Rocksdb提供的BackupEngine拷贝快照中文件，这个过程中会阻止文件的删除&lt;/p&gt;

&lt;p&gt;快照内容&lt;/p&gt;

&lt;p&gt;当前db的所有文件名
manifest文件大小
sequence_number
同步点: binlog index + offset&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/mSkkqVY.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;key&quot;&gt;秒删大量的key&lt;/h3&gt;

&lt;p&gt;在我们大量的使用场景中. 对于Hash, zset, set, list这几种多数据机构，当member或者field很多的时候，用户有批量删除某一个key的需求, 那么这个时候实际删除的就是rocksdb 底下大量的kv结构, 如果只是单纯暴力的进行删key操作, 那时间肯定非常的慢, 难以接受. 那我们如何快速删除key？&lt;/p&gt;

&lt;p&gt;刚才的nemo 的实现里面我们可以看到, 我们在value 里面增加了version, ttl 字段, 这两个字段就是做这个事情.&lt;/p&gt;

&lt;p&gt;Solution 0：暴力删除每一个member，时间复杂度O(m) , m是member的个数；&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：易实现；
缺点：同步处理，会阻碍请求；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Solution 1: 启动后台线程，维护删除队列，执行删除，时间复杂度O（m)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：不会明显阻住server；
缺点：仍然要O(m)去删除members，可以优化删除的速度；

Redis 是怎么做的？

    旧版本的Del接口，在实际free大量内存的时候仍然会阻塞server；
    新版增加了lazy free,根据当前server的负载，多次动态free；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Solution 2: 不删除, 只做标记, 时间复杂度O(1)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：效率就够了；
缺点：需要改动下层rocksdb，一定程度破坏了rocksdb的封装，各个模块之间耦合起来；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;方案：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Key的元信息增加版本，表示当前key的有效版本；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;操作：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Put：查询key的最新版本，后缀到val；
Get：查询key的最新版本，过滤最新的数据；
Iterator： 迭代时，查询key的版本，过滤旧版本数据；

Compact：数据的实际删除是在Compact过程中，根据版本信息过滤；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;目前nemo 采用的就是第二种, 通过对rocksdb 的修改, 可以实现秒删的功能, 后续通过修改rocksdb compact的实现, 在compact 的过程中, 将历史的数据淘汰掉&lt;/p&gt;

&lt;h4 id=&quot;compact-&quot;&gt;数据compact 策略&lt;/h4&gt;

&lt;p&gt;rocksdb 的compact 策略是在写放大, 读放大, 空间放大的权衡.&lt;/p&gt;

&lt;p&gt;那么我们DBA经常会存在需求尽可能减少空间的使用, 因此DBA希望能够随时触发手动compact, 而又尽可能的不影响线上的使用, 而rocksdb 默认的手动compact 策略是最高优先级的, 会阻塞线上的正常流程的合并.&lt;/p&gt;

&lt;p&gt;rocksdb 默认的 manual compact 的限制&lt;/p&gt;

&lt;p&gt;a) 当manual compact执行时，会等待所有的自动compact任务结束, 然后才会执行本次manual compact；
b) manual执行期间，自动compact无法执行&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当manual执行很长时间，无法执行自动compact，导致线上新的写请求只能在memtable中；&lt;/li&gt;
  &lt;li&gt;当memtable个数超过设置的level0_slowdown_writes_trigger(默认20)，写请求会出被sleep；&lt;/li&gt;
  &lt;li&gt;再严重一些，当超过level0_stop_writes_trigger（默认24)，完全停写；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了避免这种情况，我们对compact的策略进行调整，使得自动compact一直优先执行，避免停写；&lt;/p&gt;

&lt;p&gt;总结:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;恢复时间长
  pika 的存储引擎是nemo, nemo 使用的是rocksdb,  我们知道 rocksdb 启动不需要加载全部数据, 只需要加载几M的log 文件就可以启动, 因此恢复时间非常快&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一主多从, 主从切换代价大
  在主从切换的时候, 新主确定以后, 从库会用当前的偏移量尝试与新主做一次部分同步, 如果部分同步不成功才做全同步. 这样尽可能的减少全同步次数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缓冲区写满问题
  pika 不适用内存buffer 进行数据同步, pika 的主从同步的操作记录在本地的binlog 上, binlog 会随着操作的增长进行rotate操作. 因此不会出现把缓冲区写满的问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内存昂贵问题
  pika 的存储引擎nemo 使用的是rocksdb, rocksdb 和同时使用内存和磁盘减少对内存的依赖. 同时我们尽可能使用SSD盘来存放数据, 尽可能跟上redis 的性能.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pika-vs-redis&quot;&gt;pika vs redis&lt;/h3&gt;

&lt;p&gt;pika相对于redis，最大的不同就是pika是持久化存储，数据存在磁盘上，而redis是内存存储，由此不同也给pika带来了相对于redis的优势和劣势&lt;/p&gt;

&lt;p&gt;优势:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小&lt;/li&gt;
  &lt;li&gt;加载db速度快：Pika 在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rbd或者aof，pika 重启不用重新加载数据到内存而是直接使用已经持久化在磁盘上的数据, 不需要任何数据回放操作，这大大降低了重启成本。&lt;/li&gt;
  &lt;li&gt;备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;劣势:&lt;/p&gt;

&lt;p&gt;由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。&lt;/p&gt;

&lt;p&gt;总结:&lt;/p&gt;

&lt;p&gt;从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。&lt;/p&gt;

&lt;p&gt;而在实际使用中，大多数场景下pika的性能大约是Redis的50%~80%，在某些特定场景下，例如range 500，pika的性能只有redis的20%，针对这些场景我们仍然在改进&lt;/p&gt;

&lt;p&gt;在360内部使用情况:&lt;/p&gt;

&lt;p&gt;粗略的统计如下：&lt;/p&gt;

&lt;p&gt;当前每天承载的总请求量超过100亿, 实例数超过100个&lt;/p&gt;

&lt;p&gt;当前承载的数据总量约3 TB&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;性能对比&lt;/h3&gt;

&lt;p&gt;Server Info:
    CPU: 24 Cores, Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    MEM: 165157944 kB
    OS: CentOS release 6.2 (Final)
    NETWORK CARD: Intel Corporation I350 Gigabit Network Connection&lt;/p&gt;

&lt;p&gt;测试过程, 在pika 中先写入150G 大小的数据. 写入Hash key 50个, field 1千万级别.
redis 写入5G 大小的数据&lt;/p&gt;

&lt;p&gt;Pika:
18个线程&lt;/p&gt;

&lt;p&gt;redis:
单线程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/4tFI6kq.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;结论: pika 的单线程的性能肯定不如redis, pika是多线程的结构, 因此在线程数比较多的情况下, 某些数据结构的性能可以优于redis&lt;/p&gt;

&lt;h3 id=&quot;wiki&quot;&gt;wiki&lt;/h3&gt;

&lt;p&gt;github 地址:&lt;/p&gt;

&lt;p&gt;https://github.com/Qihoo360/pika&lt;/p&gt;

&lt;p&gt;github wiki:&lt;/p&gt;

&lt;p&gt;https://github.com/Qihoo360/pika/wiki/pika介绍&lt;/p&gt;

&lt;h2 id=&quot;faq&quot;&gt;FAQ&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;如果我们想使用新DB, 那核心问题是如何进行数据迁移. 从redis迁移到pika需要经过几个步骤？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;开发需要做的：&lt;/p&gt;

&lt;p&gt;开发不需要做任何事，不用改代码、不用替换driver（pika使用原生redis的driver），什么都不用动，看dba干活就好&lt;/p&gt;

&lt;p&gt;dba需要做的：
    1.dba迁移redis数据到pika
    2.dba将redis的数据实时同步到pika，确保redis与pika的数据始终一致
    3.dba切换lvs后端ip，由pika替换redis&lt;/p&gt;

&lt;p&gt;迁移过程中需要停业务/业务会受到影响吗：
    然而并不会&lt;/p&gt;

&lt;p&gt;迁移是无缝且温和的吗：
    那当然&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个和你们公司内部的bada 有什么区别?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们之前在bada 上面支持过redis 的多数据结构, 并且兼容redis协议, 但是遇到了问题.&lt;/p&gt;

&lt;p&gt;在分布式系统里面, 对key 的hash 场景的通常是两种方案:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;以BigTable 为代表的, 支持range key 的hash 方案. 这个方案的好处是可以实现动态的扩展&lt;/li&gt;
  &lt;li&gt;以Dynamo 为代表的, 取模的hash 方案. 这个方案的好处是时间简单&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们bada 目前支持的是取模的hash 方案, 在实现redis 的多数据结构的时候, 比如hash 我们采用key取模找到对应的分片. 那么这样带来的问题是由于多数据结构里面key 不多, field 比较多的场景还是大部分的情况, 因此极容易照成分片的不均匀, 性能退化很明显.&lt;/p&gt;

&lt;p&gt;360基础架构组公众号:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Yk2A0NS.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 18 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//storage,%20redis/2016/05/18/pika-introduction/</link>
        <guid isPermaLink="true">http://baotiao.github.io//storage,%20redis/2016/05/18/pika-introduction/</guid>
      </item>
    
      <item>
        <title>谈谈paxos, multi-paxos, raft</title>
        <description>&lt;p&gt;本文假设你已经看过了paxos make simpe, paxos make live, 关于raft 你看过对应的paper, multi-paxos 其实我觉得介绍的最好的还是Diego Ongaro 为了对比raft 和multi-paxos 的学习的难易程度写的&lt;a href=&quot;https://www.youtube.com/watch?v=JEpsBg0AO6o&quot;&gt;视频&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;关于paxos, multi-paxos 的关系&lt;/p&gt;

    &lt;p&gt;其实paxos 是关于对某一个问题达成一致的一个协议. paxos make simple 花大部分的时间解释的就是这个一个提案的问题, 然后在结尾的Implementing a State Machine 的章节介绍了我们大部分的应用场景是对一堆连续的问题达成一致, 所以最简单的方法就是实现每一个问题独立运行一个Paxos 的过程, 但是这样每一个问题都需要Prepare, Accept 两个阶段才能够完成. 所以我们能不能把这个过程给减少. 那么可以想到的解决方案就是把Prepare 减少, 那么就引入了leader, 引入了leader 就必然有选leader 的过程. 才有了后续的事情, 这里可以看出其实lamport 对multi-paxos 的具体实现其实是并没有细节的指定的, 只是简单提了一下. 所以才有各种不同的multi-paxos 的实现&lt;/p&gt;

    &lt;p&gt;那么paxos make live 这个文章里面主要讲的是如何使用multi paxos 实现chubby 的过程, 以及实现过程中需要解决的问题, 比如需要解决磁盘冲突, 如何优化读请求, 引入了Epoch number等, 可以看成是对实现multi-paxos 的一些&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关于 multi-paxos 和 raft 的关系&lt;/p&gt;

    &lt;p&gt;从上面可以看出其实我们对比的时候不应该拿paxos 和 raft 对比, 因为paxos 是对于一个问题达成一致的协议, 而raft 本身是对一堆连续的问题达成一致的协议. 所以应该比较的是multi-paxos 和raft&lt;/p&gt;

    &lt;p&gt;那么multi-paxos 和 raft 的关系是什么呢?&lt;/p&gt;

    &lt;p&gt;raft 是基于对multi paxos 的两个限制形成的&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;发送的请求的是连续的, 也就是说raft 的append 操作必须是连续的. 而paxos 可以并发的. (其实这里并发只是append log 的并发提高, 应用的state machine 还是必须是有序的)&lt;/li&gt;
      &lt;li&gt;选主是有限制的, 必须有最新, 最全的日志节点才可以当选. 而multi-paxos 是随意的
 所以raft 可以看成是简化版本的multi paxos(这里multi-paxos 因为允许并发的写log, 因此不存在一个最新, 最全的日志节点, 因此只能这么做. 这样带来的麻烦就是选主以后, 需要将主里面没有的log 给补全, 并执行commit 过程)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;基于这两个限制, 因此raft 的实现可以更简单, 因为raft 的但是multi-paxos 的并发度理论上是更高的.&lt;/p&gt;

    &lt;p&gt;可以对比一下multi-paxos 和 raft 可能出现的日志&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;multi-paxos&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://i.imgur.com/SsIeodM.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;raft&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://i.imgur.com/2KO9khV.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;可以看出, raft 里面follower 的log 一定是leader log 的子集, 而raft 不做这个保证&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关于paxos, multi-paxos, raft 的关系&lt;/p&gt;

    &lt;p&gt;所以我觉得multi-paxos, raft 都是对一堆连续的问题达成一致的协议, 而paxos 是对一个问题达成一致的协议, 因此multi-paxos, raft 其实都是为了简化paxos 在多个问题上面达成一致的需要的两个阶段, 因此都简化了prepare 阶段, 提出了通过有leader 来简化这个过程. multi-paxos, raft 只是简化不一样, raft 让用户的log 必须是有序, 选主必须是有日志最全的节点, 而multi-paxos 没有这些限制. 因此raft 的实现会更简单.&lt;/p&gt;

    &lt;p&gt;因此从这个角度来看, Diego Ongaro 实现raft 这个论文实现的初衷应该是达到了, 让大家更容易理解这个paxos 这个东西&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关于lock service 和 consensus library 的对比&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;chubby 是根据multi-paxos 实现的一个global lock service, 为什么是lock service 而不是一个consensus service 或者 consensus library呢?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;首先是library 和 service 的对比&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;当用户需要一个consensus 的需求的时候, 一般是随着业务的增长才需要, 那么如果是一个library 的话, 需要对用户的代码改动比较大才能够需求, 而如果是一个service 的话, 那么需要的改动量就非常的小, 仅仅是从consensus service 获得这个服务的地址等等&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;lock service 和 consensus library 区别&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;比如在选主的场景下面, 
我们使用lock service 的做法就是其中的某一个process 去获得这个lock, 然后由这个获得lock 的process 进行选主操作, 这里选主主要涉及每一个process 的log.&lt;/p&gt;

&lt;p&gt;另一种是consensus library 的做法, 那么这个时候实现的过程就应该是任意一个process 都可以进行选举操作, 然后选举的过程通过consensus library 来进行.&lt;/p&gt;

&lt;p&gt;从这里可以看出 consensus library 的做法是一个业务的本质需求, 但是实现起来对consensus library 需要有深入的了解, consensus library 和上层的逻辑耦合比较高, 而使用lock service 则是一个更简单, 更清晰的做法&lt;/p&gt;

&lt;p&gt;最后推广一下我们实现的一个元信息管理模块 &lt;a href=&quot;https://github.com/baotiao/floyd&quot;&gt;floyd&lt;/a&gt;, 是一个Library, 而不是一个service. 提供consensus library, 也提供lock library&lt;/p&gt;

</description>
        <pubDate>Thu, 05 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//distribute,%20consensus/2016/05/05/paxos-raft/</link>
        <guid isPermaLink="true">http://baotiao.github.io//distribute,%20consensus/2016/05/05/paxos-raft/</guid>
      </item>
    
      <item>
        <title>epoll implementation</title>
        <description>&lt;h3 id=&quot;epoll-implementation&quot;&gt;epoll Implementation&lt;/h3&gt;

&lt;p&gt;epoll 在kernel 的具体实现主要在 fs/eventpoll.c include/linux/eventpoll.h 里面&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;主要的数据结构&lt;/h4&gt;

&lt;p&gt;eventpoll 是这里面最重要的结构, 在epoll_create 的时候就会生成这个eventpoll 结构, 后续对这个fd 的操作都是在这个eventpoll 这个结构下面的, 这个eventpoll 结构会被保存在file struct 的 private_data 这个结构体里面&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct eventpoll {
	/* Protect the this structure access */
	spinlock_t lock;

	/*
	 * This mutex is used to ensure that files are not removed
	 * while epoll is using them. This is held during the event
	 * collection loop, the file cleanup path, the epoll file exit
	 * code and the ctl operations.
	 */
	struct mutex mtx;

	/* Wait queue used by sys_epoll_wait() */
  /*
   * 这个wq 这个等待队列是在sys_epoll_wait 里面使用的,
   * 里面放入的进程应该只有执行epoll_wait 这个进程
   */
	wait_queue_head_t wq;

	/* Wait queue used by file-&amp;gt;poll() */
  /*
   * 因为eventpoll 本身也是一个file, 所以也会有poll 操作, 有poll
   * 操作肯定就会有一个对应的wait_queue_head_t 队列用来唤醒上面的进程或者函数
   * 就跟pipe_inode_info 里面会有  wait_queue_head_t wait; 一样
   *
   * 不过我们很少看到把一个epoll 的fd 再挂载到另外一个fd 下面
   *
   */
	wait_queue_head_t poll_wait;

	/* List of ready file descriptors */
  /*
   * 在epoll_wait 阶段, 如果有哪些fd 就绪, 会把就绪的fd 放在这个rdllist 里面
   * 这个rdllist 里面放的是epitem 这个结构
   */
	struct list_head rdllist;

	/* RB tree root used to store monitored fd structs */
	struct rb_root rbr;

	/*
	 * This is a single linked list that chains all the &quot;struct epitem&quot; that
	 * happened while transfering ready events to userspace w/out
	 * holding -&amp;gt;lock.
	 */
	struct epitem *ovflist;

	/* The user that created the eventpoll descriptor */
	struct user_struct *user;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;epitem 这个表示的是每一个加入到eventpoll 的结构里面的fd 的时候, 都会有一个epitem 这个结构体, 这个结构体是是连成一个红黑树挂载eventpoll 下面的, 后续查找某一个fd 是否有事件等等都是在这个epitem 上面进行操作&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/*
 * Each file descriptor added to the eventpoll interface will
 * have an entry of this type linked to the &quot;rbr&quot; RB tree.
 */
struct epitem {
	/* RB tree node used to link this structure to the eventpoll RB tree */
  /*
   * 这是这个fd 挂载的红黑树的节点
   */
	struct rb_node rbn;

	/* List header used to link this structure to the eventpoll ready list */
  /*
   * 这个是将这个epitem 连接到eventpoll 里面的rdllist 的时候list指针
   */
	struct list_head rdllink;

	/*
	 * Works together &quot;struct eventpoll&quot;-&amp;gt;ovflist in keeping the
	 * single linked chain of items.
	 */
	struct epitem *next;

	/* The file descriptor information this item refers to */
  /*
   * epoll 监听的fd
   */
	struct epoll_filefd ffd;

	/* Number of active wait queue attached to poll operations */
  /*
   * 因为一个epitem 可能会被多个eventpoll 监听, 那么就会对应生成多个eppoll_entry
   * 这里nwait 就是记录这个数目
   */
	int nwait;

	/* List containing poll wait queues */
	struct list_head pwqlist;

	/* The &quot;container&quot; of this item */
  /*
   * 当前这个epitem 所属于的eventpoll
   */
	struct eventpoll *ep;

	/* List header used to link this item to the &quot;struct file&quot; items list */
	struct list_head fllink;

	/* The structure that describe the interested events and the source fd */
	struct epoll_event event;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;eppoll_entry 
一个epitem 关联到一个eventpoll, 就会有一个对应的eppoll_entry&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/* Wait structure used by the poll hooks */
struct eppoll_entry {
	/* List header used to link this structure to the &quot;struct epitem&quot; */
  /*
   * 因为一个epitem 可以会被多个eventpoll 监听, 因为每一个进程打开的这个文件的fd
   * 和epitem 是一一对应的, 因此这里epitem 对应的是多个eppoll_entry,
   * 所以这个llink 会被连接到pwqlist 里面
   */
	struct list_head llink;

	/* The &quot;base&quot; pointer is set to the container &quot;struct epitem&quot; */
  /*
   * 对应的epitem
   */
	struct epitem *base;

	/*
	 * Wait queue item that will be linked to the target file wait
	 * queue head.
   * wait_queue_t 里面存的就是wait_queue_head_t 下面具体的内容
	 */
  /*
 struct __wait_queue {
     unsigned int flags;
  #define WQ_FLAG_EXCLUSIVE	0x01
  // 这里的这个private 一般指向某一个进程task_struct
  void *private;
  wait_queue_func_t func;
  struct list_head task_list;
  };
  */
	wait_queue_t wait;

	/* The wait queue head that linked the &quot;wait&quot; wait queue item */
	wait_queue_head_t *whead;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;epollcreate-&quot;&gt;epoll_create 的过程&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/*
 * Open an eventpoll file descriptor.
 */
SYSCALL_DEFINE1(epoll_create1, int, flags)
{
	int error;
	struct eventpoll *ep = NULL;

	/* Check the EPOLL_* constant for consistency.  */
	BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC);

	if (flags &amp;amp; ~EPOLL_CLOEXEC)
		return -EINVAL;
	/*
	 * Create the internal data structure (&quot;struct eventpoll&quot;).
   * 初始化建立这个主题的 eventpoll 这个结构
	 */
	error = ep_alloc(&amp;amp;ep);
	if (error &amp;lt; 0)
		return error;
	/*
	 * Creates all the items needed to setup an eventpoll file. That is,
	 * a file structure and a free file descriptor.
   *
   * 这个也是一个重要的过程, 将eventpoll 生成的fd绑定到匿名file上, 
   * 因为我们可以看到epoll_create 出来的也是一个文件fd. 那么这个fd
   * 绑定到一个file 以后, 那么这个epoll具体的内容就在这个struct file 上面的
   * private_data 上面
   *
   * 这里这个error 写的比较坑, 如果正常其实这里返回的就是epoll_create
   * 生成的fd
	 */

  // 这里这个ep 就是一直要传下去的epollevent, 最后这个ep 会被赋值到struct
  // file-&amp;gt;private_data 里面去
  // 可以看到这里代表着另外一种文件类型, 匿名文件类型需要建立一个fd的过程
  // 这里其实如果是socket 的话, 那么不一样的地方就是这里传入的不是ep,
  // 而是一个socket
  // 这也是linux 所有数据都是文件的一个体现
	error = anon_inode_getfd(&quot;[eventpoll]&quot;, &amp;amp;eventpoll_fops, ep,
				 flags &amp;amp; O_CLOEXEC);
	if (error &amp;lt; 0)
		ep_free(ep);

	return error;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;epollctl&quot;&gt;epoll_ctl&lt;/h4&gt;

&lt;p&gt;epoll_ctl 做的主要事情就是把某一个fd 要监听的事件过载到eventpoll 里面&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd,
		struct epoll_event __user *, event)
{
	int error;
	struct file *file, *tfile;
	struct eventpoll *ep;
	struct epitem *epi;
	struct epoll_event epds;

	error = -EFAULT;
  /*
   * 这里检查这次操作是否有这个操作, 并将用户空间传进来的epoll_event 拷贝到内核空间
   */
	if (ep_op_has_event(op) &amp;amp;&amp;amp;
	    copy_from_user(&amp;amp;epds, event, sizeof(struct epoll_event)))
		goto error_return;

	/* Get the &quot;struct file *&quot; for the eventpoll file */
	error = -EBADF;
  /*
   * 这里就是使用文件的好处了, 根据这个fd, fget 就可以获得当前这个进程fd
   * 号码是pdfd 的file, 然后就操作file 里面的内容, 虽然这里的file 不是正在的file
   * 而是一个匿名文件, 这样操作起来非常的方便
   */
	file = fget(epfd);
	if (!file)
		goto error_return;

	/* Get the &quot;struct file *&quot; for the target file */
  /*
   * 这里的epoll_ctl 要关注的那个文件的fd, 也一样根据这个fd 找到这个文件
   */
	tfile = fget(fd);
	if (!tfile)
		goto error_fput;

  // TODO 这里descriptoer support poll 是什么意思, 是不是有实现poll 函数就行
	/* The target file descriptor must support poll */
	error = -EPERM;
	if (!tfile-&amp;gt;f_op || !tfile-&amp;gt;f_op-&amp;gt;poll)
		goto error_tgt_fput;

	/*
	 * We have to check that the file structure underneath the file descriptor
	 * the user passed to us _is_ an eventpoll file. And also we do not permit
	 * adding an epoll file descriptor inside itself.
   * 这里可以看到如果把自己的epoll 的fd 添加到 epoll_ctl 里面的fd 是有问题的
	 */
	error = -EINVAL;
	if (file == tfile || !is_file_epoll(file))
		goto error_tgt_fput;

	/*
	 * At this point it is safe to assume that the &quot;private_data&quot; contains
	 * our own data structure.
	 */
	ep = file-&amp;gt;private_data;

	mutex_lock(&amp;amp;ep-&amp;gt;mtx);

	/*
	 * Try to lookup the file inside our RB tree, Since we grabbed &quot;mtx&quot;
	 * above, we can be sure to be able to use the item looked up by
	 * ep_find() till we release the mutex.
   * 根据这个fd 找出对应的epitem, 这里把所有的epitem 根据fd号挂载到红黑树上
	 */
	epi = ep_find(ep, tfile, fd);

	error = -EINVAL;
	switch (op) {
	case EPOLL_CTL_ADD:
		if (!epi) {
			epds.events |= POLLERR | POLLHUP;
			error = ep_insert(ep, &amp;amp;epds, tfile, fd);
		} else
			error = -EEXIST;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;那么接下来主要看ep_insert 的过程&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
/*
 * Must be called with &quot;mtx&quot; held.
 * 这里可以看到往这个队列里面加入一个epoll_event 的过程
 */
static int ep_insert(struct eventpoll *ep, struct epoll_event *event,
		     struct file *tfile, int fd)
{
	int error, revents, pwake = 0;
	unsigned long flags;
	struct epitem *epi;
	struct ep_pqueue epq;

	if (unlikely(atomic_read(&amp;amp;ep-&amp;gt;user-&amp;gt;epoll_watches) &amp;gt;=
		     max_user_watches))
		return -ENOSPC;
	if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL)))
		return -ENOMEM;

	/* Item initialization follow here ... */
	INIT_LIST_HEAD(&amp;amp;epi-&amp;gt;rdllink);
	INIT_LIST_HEAD(&amp;amp;epi-&amp;gt;fllink);
	INIT_LIST_HEAD(&amp;amp;epi-&amp;gt;pwqlist);
  /*
   * 这里会反向标记这个epitem 属于的eventpoll
   */
	epi-&amp;gt;ep = ep;
  /*
   * 这里就是去设定 epitem 里面的ffd 字段, 标记里面的ffd 字段
   * 就是初始化好file, fd 字段
   */
	ep_set_ffd(&amp;amp;epi-&amp;gt;ffd, tfile, fd);
	epi-&amp;gt;event = *event;
	epi-&amp;gt;nwait = 0;
	epi-&amp;gt;next = EP_UNACTIVE_PTR;

	/* Initialize the poll table using the queue callback */
	epq.epi = epi;
  /*
   * 这里是注册poll 里面有事件到达的时候的处理函数
   * 在ep_ptable_queue_proc 里面去添加事件到达的时候处理函数
   * init_waitqueue_func_entry(&amp;amp;pwq-&amp;gt;wait, ep_poll_callback);
   */
	init_poll_funcptr(&amp;amp;epq.pt, ep_ptable_queue_proc);

	/*
	 * Attach the item to the poll hooks and get current event bits.
	 * We can safely use the file* here because its usage count has
	 * been increased by the caller of this function. Note that after
	 * this operation completes, the poll callback can start hitting
	 * the new item.
	 */

  /* 
   *
   * 这里调用对应的fd 的poll 操作, 看是否有事件到达.
   * 并且注册事件到达的时候poll_table
   * 这里是调用用户关注的fd 的.poll()函数, 不是eventpoll 里面的
   * ep_eventpoll_poll
   */  
	revents = tfile-&amp;gt;f_op-&amp;gt;poll(tfile, &amp;amp;epq.pt);

	/*
	 * We have to check if something went wrong during the poll wait queue
	 * install process. Namely an allocation for a wait queue failed due
	 * high memory pressure.
	 */
	error = -ENOMEM;
	if (epi-&amp;gt;nwait &amp;lt; 0)
		goto error_unregister;

	/* Add the current item to the list of active epoll hook for this file */
	spin_lock(&amp;amp;tfile-&amp;gt;f_lock);
	list_add_tail(&amp;amp;epi-&amp;gt;fllink, &amp;amp;tfile-&amp;gt;f_ep_links);
	spin_unlock(&amp;amp;tfile-&amp;gt;f_lock);

	/*
	 * Add the current item to the RB tree. All RB tree operations are
	 * protected by &quot;mtx&quot;, and ep_insert() is called with &quot;mtx&quot; held.
   * 这里是具体把这个epitem 加入到这个eventpoll 的 rb tree 的过程
	 */
	ep_rbtree_insert(ep, epi);

	/* We have to drop the new item inside our item list to keep track of it */
	spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);

	/* If the file is already &quot;ready&quot; we drop it inside the ready list */
	if ((revents &amp;amp; event-&amp;gt;events) &amp;amp;&amp;amp; !ep_is_linked(&amp;amp;epi-&amp;gt;rdllink)) {
		list_add_tail(&amp;amp;epi-&amp;gt;rdllink, &amp;amp;ep-&amp;gt;rdllist);

		/* Notify waiting tasks that events are available */
		if (waitqueue_active(&amp;amp;ep-&amp;gt;wq))
			wake_up_locked(&amp;amp;ep-&amp;gt;wq);
		if (waitqueue_active(&amp;amp;ep-&amp;gt;poll_wait))
			pwake++;
	}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;那么到这里已经将这个fd 注册到对应的eventpoll上, 那么我们看一下这里注册的函数, 函数是&lt;/p&gt;

&lt;p&gt;init_poll_funcptr(&amp;amp;epq.pt, ep_ptable_queue_proc);
这个函数ep_ptable_queue_proc 里面又会包含对应的当有事件发生的时候的回调函数 ep_poll_callback&lt;/p&gt;

&lt;p&gt;那么接下来就是 ep_table_queue_proc 的实现&lt;/p&gt;

&lt;p&gt;在ep_table_queue_proc 里面将当前这个进程注册到了想要监听的fd 的唤醒队列里面, 这个唤醒的行数是 ep_poll_callback,&lt;/p&gt;

&lt;p&gt;其实唤醒的时候主要分两种类似
1. 唤醒注册时候的进程, 让注册的进程重新执行. 比如在epoll_wait 的时候对应的唤醒函数就是唤醒这个执行 epoll_wait 的这个进程
2. 唤醒的时候执行注册的某一个函数&lt;/p&gt;

&lt;p&gt;这里因为epoll 注册的是唤醒的时候执行注册的某一个函数, 这个函数就是ep_poll_callback&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
/*
 * This is the callback that is used to add our wait queue to the
 * target file wakeup lists.
 */
static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead,
				 poll_table *pt)
{
  /*
   * 从知道poll_table 的地址去获得这个对应的epitem的地址, 跟kernel 里面list的做法类似
   */
	struct epitem *epi = ep_item_from_epqueue(pt);


  /*
   * 这里eppoll_entry 是对应于每一个epitem 注册挂载到某一个eventpoll 都会有一个eppoll_entry
   */
	struct eppoll_entry *pwq;

	if (epi-&amp;gt;nwait &amp;gt;= 0 &amp;amp;&amp;amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) {
    /*
     * 这里就是把pwq-&amp;gt;wait 这个元素的callback 设置成 ep_poll_callback 这个函数
     * 然后初始化的时候一般把这个private 设置NULL 的原因是
     * 这里当要等待的这个队列被唤醒的时候, 并不在于哪一个进程,
     * 只要唤醒的时候执行指定的函数就可以了
     * 需要看一下唤醒的时候具体是怎么执行的,
     * 是不是唤醒的时候如果注册的是函数就执行指定的函数,
     * 如果是进程就执行指定的进程
     */
		init_waitqueue_func_entry(&amp;amp;pwq-&amp;gt;wait, ep_poll_callback);
		pwq-&amp;gt;whead = whead;
		pwq-&amp;gt;base = epi;
    // 这里就是将这个要等待的fd 添加到等待队列里面去了,
    // 这里如果这个要等待的fd是pipe, 那么这里这个whead就是pipe-&amp;gt;wait了
    // 这里要等待的fd 只有  wait_queue_head_t wait; 这个wait_queue_head,
    // 然后就是将这里epoll_entry 里面的wait_queue_t wait 连在一起,
    // 实际他们组合成了一个等待的队列, 然后想取得这个队列里面的元素, 跟kernel
    // list 一样, 需要根据struct 里面某一个元素的地址, 然后去获得这个元素
    // 比如这里想反向获得这个 epoll_entry 里面的epitem 就是
    //   struct epitem *epi = ep_item_from_wait(wait);
		add_wait_queue(whead, &amp;amp;pwq-&amp;gt;wait);
		list_add_tail(&amp;amp;pwq-&amp;gt;llink, &amp;amp;epi-&amp;gt;pwqlist);
		epi-&amp;gt;nwait++;
	} else {
		/* We have to signal that an error occurred */
		epi-&amp;gt;nwait = -1;
	}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ep_poll_callback&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/*
 * This is the callback that is passed to the wait queue wakeup
 * machanism. It is called by the stored file descriptors when they
 * have events to report.
 * 这里就是被static void __wake_up_common 这个函数下面进行循环调用的
 *
 * 也就是某一个fd 的等待队列里面注册的这个函数的callback,
 * 然后这个fd有事件发生了, 就会执行这个ep_poll_callback 函数了
 *
 * 这个key 参数是从 wake_up_interruptible_poll() 函数里面一直传进来的, 
 * 这里这个key 在这里表示的就是要监听的这个fd 有什么事件 
 *
 * 其实这里epitem 里面已经包含了发生的事件, 和这里的key 参数其实是一样了,
 * 因为并不是所有的device 都会把发生的事件都放在key 这个参数里面的
 *
 * 这个函数主要就是由监听的fd发生事件了, 然后触发这个回调函数, 
 * 然后这里会把触发的fd 添加到eventpoll 中的 rdllist
 *
 */
static int ep_poll_callback(wait_queue_t *wait, unsigned mode, int sync, void *key)
{
	int pwake = 0;
	unsigned long flags;
  /*
   * 因为之前王wait_queue_t 里面放的是epoll_entry 这个struct 里面的wait 元素,
   * 这里加入的地方是在eventpoll.c:ep_ptable_queue_proc
   * 这个函数里面的
   * add_wait_queue(whead, &amp;amp;pwq-&amp;gt;wait);
   * 在这个函数里面有详细的注释
   * 这样要做的事情就是根据struct 里面的某一个元素wait, 去获得这个struct
   * epoll_entry 里面的epitem
   * 到这里的时候, 我们已经知道是这个epitem 里面指定的fd 有时间发生,
   * 那么这个时候就去检查这个fd 里面发生了什么事件
   */
	struct epitem *epi = ep_item_from_wait(wait);


  /*
   * 这里由于需要记录这个epitem 是属于哪一个eventpoll, 因此epitem
   * 会保留这个反向的指向eventpoll 的指针
   */
	struct eventpoll *ep = epi-&amp;gt;ep;

	spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);

	/*
	 * If the event mask does not contain any poll(2) event, we consider the
	 * descriptor to be disabled. This condition is likely the effect of the
	 * EPOLLONESHOT bit that disables the descriptor when an event is received,
	 * until the next EPOLL_CTL_MOD will be issued.
	 */
	if (!(epi-&amp;gt;event.events &amp;amp; ~EP_PRIVATE_BITS))
		goto out_unlock;

	/*
	 * Check the events coming with the callback. At this stage, not
	 * every device reports the events in the &quot;key&quot; parameter of the
	 * callback. We need to be able to handle both cases here, hence the
	 * test for &quot;key&quot; != NULL before the event match test.
   * 这里其实key 有可能记录了当前这个fd的事件, 如果记录了,
   * 就判断key里面返回的事件和 这个fd关注的事件是否有重合
	 */
	if (key &amp;amp;&amp;amp; !((unsigned long) key &amp;amp; epi-&amp;gt;event.events))
		goto out_unlock;

	/*
	 * If we are trasfering events to userspace, we can hold no locks
	 * (because we&#39;re accessing user memory, and because of linux f_op-&amp;gt;poll()
	 * semantics). All the events that happens during that period of time are
	 * chained in ep-&amp;gt;ovflist and requeued later on.
	 */
  /*
   * 这里把这个epi 添加到ovflist
   */
	if (unlikely(ep-&amp;gt;ovflist != EP_UNACTIVE_PTR)) {
		if (epi-&amp;gt;next == EP_UNACTIVE_PTR) {
			epi-&amp;gt;next = ep-&amp;gt;ovflist;
			ep-&amp;gt;ovflist = epi;
		}
		goto out_unlock;
	}

	/* If this file is already in the ready list we exit soon */
  // 这个epitem 已经在rdllist 里面就不再添加
  // 这里只要判断这个epitem-&amp;gt;rdllink 是否有连接上, 也就是next
  // 指针是否为空就可以知道这个epitem 有没有被连接成一个List
	if (!ep_is_linked(&amp;amp;epi-&amp;gt;rdllink))
		list_add_tail(&amp;amp;epi-&amp;gt;rdllink, &amp;amp;ep-&amp;gt;rdllist);

	/*
	 * Wake up ( if active ) both the eventpoll wait list and the -&amp;gt;poll()
	 * wait list.
	 */
	if (waitqueue_active(&amp;amp;ep-&amp;gt;wq))
		wake_up_locked(&amp;amp;ep-&amp;gt;wq); // 这里的wake_up ep-&amp;gt;wq 就把等待在epoll_wait 里面的直接schedule_timeout()的那个函数给唤醒
  // 那么这个时候如果进程等待在epoll_wait 上面, 进程就会重新执行
	if (waitqueue_active(&amp;amp;ep-&amp;gt;poll_wait)) // 这里这个默认的pwake 初始化是0, 表示当前这个ep-&amp;gt;poll_wait 所等待的fd 里面有多少个已经wakeup了
    // 为什么这里需要把加这个pwake, 因为如果不加这个pwake, 那么每一个ep
    // 所等待的fd 醒来都去wakeup 一下这个ep这个线程,
    // 那么ep这个线程其实就被wakeup 了很多次
		pwake++;

out_unlock:
	spin_unlock_irqrestore(&amp;amp;ep-&amp;gt;lock, flags);

	/* We have to call this outside the lock */
	if (pwake)
		ep_poll_safewake(&amp;amp;ep-&amp;gt;poll_wait);

	return 1;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;epollwait&quot;&gt;epoll_wait&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
/*
 * Implement the event wait interface for the eventpoll file. It is the kernel
 * part of the user space epoll_wait(2).
 */
SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events,
		int, maxevents, int, timeout)
{
	int error;
	...
	error = ep_poll(ep, events, maxevents, timeout);

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;主要的执行逻辑在 ep_poll() 上&lt;/p&gt;

&lt;p&gt;ep_poll()&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events,
		   int maxevents, long timeout)
{
	int res, eavail;
	unsigned long flags;
	long jtimeout;
	wait_queue_t wait;

	/*
	 * Calculate the timeout by checking for the &quot;infinite&quot; value (-1)
	 * and the overflow condition. The passed timeout is in milliseconds,
	 * that why (t * HZ) / 1000.
	 */
	jtimeout = (timeout &amp;lt; 0 || timeout &amp;gt;= EP_MAX_MSTIMEO) ?
		MAX_SCHEDULE_TIMEOUT : (timeout * HZ + 999) / 1000;

retry:
	spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);

	res = 0;
	if (list_empty(&amp;amp;ep-&amp;gt;rdllist)) {
		/*
		 * We don&#39;t have any available event to return to the caller.
		 * We need to sleep here, and we will be wake up by
		 * ep_poll_callback() when events will become available.
     *
     * 由于ep_poll 是被epoll_wait 的时候被调用, 因此这里这个current
     * 进程就是调用epoll_wait 的那个进程
     *
     * 将这个触发当前进程执行的wait_queue_t wait 加入到ep-&amp;gt;wq wait_queue_head_t
     * 里面去, 那么下次这个wait_queue 有事件到达的时候, 就会触发当前这个wait
     * 里面的内容
		 */
		init_waitqueue_entry(&amp;amp;wait, current);
		wait.flags |= WQ_FLAG_EXCLUSIVE;
		__add_wait_queue(&amp;amp;ep-&amp;gt;wq, &amp;amp;wait);

    /*
     * 这里这个死循环的做法是将current 进程的状态改成TASK_INTERRUPTIBLE,
     * 然后最后重新陷入到执行schedule(),
     * 这里因为当前的进程的状态已经改成TASK_INTERRUPTIBLE了,
     * 因此肯定会切换到其他进程去执行
     */
		for (;;) {
			/*
			 * We don&#39;t want to sleep if the ep_poll_callback() sends us
			 * a wakeup in between. That&#39;s why we set the task state
			 * to TASK_INTERRUPTIBLE before doing the checks.
			 */
			set_current_state(TASK_INTERRUPTIBLE);
      /*
       * 这里可以看到如果有ep rdllist 里面有元素, 那么说明有时间已经出发了,
       * 那么就退出这个for 循环
       */
			if (!list_empty(&amp;amp;ep-&amp;gt;rdllist) || !jtimeout)
				break;
			if (signal_pending(current)) {
				res = -EINTR;
				break;
			}

			spin_unlock_irqrestore(&amp;amp;ep-&amp;gt;lock, flags);
      /*
       * 当前这个进程把CPU 交给其他的进程执行, 当切换回来的时候肯定eventpoll
       * 里面的内容应该会被修改了, 比如某一个事件触发的时候, 会往rdllist
       * 里面写入数据内容
       *
       * 这里就开始等待之前在epoll_insert
       * 注册的ep_poll_callback这个函数来把当前这个进程给唤醒,
       * 否则是sleep一段时间以后就返回了
       */
			jtimeout = schedule_timeout(jtimeout);
			spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);
		}
    /*
     * 当前这个进程已经被唤醒, 那么就从eventpoll 里面把这个进程删除掉
     */
		__remove_wait_queue(&amp;amp;ep-&amp;gt;wq, &amp;amp;wait);

    /*
     * 设置当前的进程的状态, 到这里我觉得进程已经正常运行了
     */
		set_current_state(TASK_RUNNING);
	}
	/* Is it worth to try to dig for events ? */
	eavail = !list_empty(&amp;amp;ep-&amp;gt;rdllist) || ep-&amp;gt;ovflist != EP_UNACTIVE_PTR;

	spin_unlock_irqrestore(&amp;amp;ep-&amp;gt;lock, flags);

	/*
	 * Try to transfer events to user space. In case we get 0 events and
	 * there&#39;s still timeout left over, we go trying again in search of
	 * more luck.
   * 到这里肯定从schedule_timeout 里面退出, 已经有事件发生并且传送过来了,
   * 这个就是就把这些事件传给用户进程
	 */
	if (!res &amp;amp;&amp;amp; eavail &amp;amp;&amp;amp;
	    !(res = ep_send_events(ep, events, maxevents)) &amp;amp;&amp;amp; jtimeout)
		goto retry;

	return res;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最后就是将发生的events 传递给用户空间&lt;/p&gt;

&lt;p&gt;ep_send_events-&amp;gt;ep_scan_ready_list-&amp;gt;ep_send_events_proc&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * ep_scan_ready_list - Scans the ready list in a way that makes possible for
 *                      the scan code, to call f_op-&amp;gt;poll(). Also allows for
 *                      O(NumReady) performance.
 *
 * @ep: Pointer to the epoll private data structure.
 * @sproc: Pointer to the scan callback.
 * @priv: Private opaque data passed to the @sproc callback.
 *
 * Returns: The same integer error code returned by the @sproc callback.
 */
static int ep_scan_ready_list(struct eventpoll *ep,
			      int (*sproc)(struct eventpoll *,
					   struct list_head *, void *),
			      void *priv)
{
	int error, pwake = 0;
	unsigned long flags;
	struct epitem *epi, *nepi;
	LIST_HEAD(txlist);

	/*
	 * We need to lock this because we could be hit by
	 * eventpoll_release_file() and epoll_ctl().
	 */
	mutex_lock(&amp;amp;ep-&amp;gt;mtx);

	/*
	 * Steal the ready list, and re-init the original one to the
	 * empty list. Also, set ep-&amp;gt;ovflist to NULL so that events
	 * happening while looping w/out locks, are not lost. We cannot
	 * have the poll callback to queue directly on ep-&amp;gt;rdllist,
	 * because we want the &quot;sproc&quot; callback to be able to do it
	 * in a lockless way.
	 */
	spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);

  // 这里将txlist 指向eventpoll 里面的rdllist, 那么接下来就会将txlist
  // 里面的内容也就是rdllist里面的内容拷贝给用户空间
  // 这个rdllist 是在ep_poll_callback 的时候添加进去的内容的
  // 这里执行完这个list_splice_init 以后, ep-&amp;gt;rdllist 就变成空的了
  // 那么接下来可以同时处理txllist 里面的内容, 也就是原先rdllist 里面的内容.
  // 也可以同时让新的元素往这个队里里面添加新的内容
  //
  // 这是一个很好的减少锁范围的例子
  // 相当于先生成一个队列, 然后后续要处理这个队列里面内容,
  // 同时又添加和删除操作的时候, 可以把这个添加操作放到一个新的队列上,
  // 那么这个时候就可以同时的添加和删除操作, 不用去竞争一个锁
  // NICE
	list_splice_init(&amp;amp;ep-&amp;gt;rdllist, &amp;amp;txlist);
	ep-&amp;gt;ovflist = NULL;
	spin_unlock_irqrestore(&amp;amp;ep-&amp;gt;lock, flags);

	/*
	 * Now call the callback function.
   * 这里的sproc 就是 ep_send_events_proc
	 */
	error = (*sproc)(ep, &amp;amp;txlist, priv);

	spin_lock_irqsave(&amp;amp;ep-&amp;gt;lock, flags);
	/*
	 * During the time we spent inside the &quot;sproc&quot; callback, some
	 * other events might have been queued by the poll callback.
	 * We re-insert them inside the main ready-list here.
	 */
	for (nepi = ep-&amp;gt;ovflist; (epi = nepi) != NULL;
	     nepi = epi-&amp;gt;next, epi-&amp;gt;next = EP_UNACTIVE_PTR) {
		/*
		 * We need to check if the item is already in the list.
		 * During the &quot;sproc&quot; callback execution time, items are
		 * queued into -&amp;gt;ovflist but the &quot;txlist&quot; might already
		 * contain them, and the list_splice() below takes care of them.
		 */
		if (!ep_is_linked(&amp;amp;epi-&amp;gt;rdllink))
			list_add_tail(&amp;amp;epi-&amp;gt;rdllink, &amp;amp;ep-&amp;gt;rdllist);
	}
	/*
	 * We need to set back ep-&amp;gt;ovflist to EP_UNACTIVE_PTR, so that after
	 * releasing the lock, events will be queued in the normal way inside
	 * ep-&amp;gt;rdllist.
	 */
	ep-&amp;gt;ovflist = EP_UNACTIVE_PTR;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ep_send_events_proc 函数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// 这里priv 就是用户传进来的events 的包装 ep_send_events_data
// 这里就是具体的把已经就绪的list copy 给用户空间
static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head,
			       void *priv)
{
  /*
   * 这里esed 里面的内容就是 ep-&amp;gt;rdllist 里面的内容
   */
	struct ep_send_events_data *esed = priv;
	int eventcnt;
	unsigned int revents;
	struct epitem *epi;
	struct epoll_event __user *uevent;

	/*
	 * We can loop without lock because we are passed a task private list.
	 * Items cannot vanish during the loop because ep_scan_ready_list() is
	 * holding &quot;mtx&quot; during this call.
	 */
	for (eventcnt = 0, uevent = esed-&amp;gt;events;
	     !list_empty(head) &amp;amp;&amp;amp; eventcnt &amp;lt; esed-&amp;gt;maxevents;) {
		epi = list_first_entry(head, struct epitem, rdllink);

    /*
     * 这里就是默认将这个有时间到达的epi从这个rdllist 里面删除掉了,
     * 下面可以看到如果是epoll LT 模式的话, 这个epi-&amp;gt;rdllink
     * 会重新被加入到这个rdllist 里面
     */
		list_del_init(&amp;amp;epi-&amp;gt;rdllink);

    /*
     * 返回当前这个监听的fd的事件 &amp;amp; 这个fd 我们关注的事件
     */
		revents = epi-&amp;gt;ffd.file-&amp;gt;f_op-&amp;gt;poll(epi-&amp;gt;ffd.file, NULL) &amp;amp;
			epi-&amp;gt;event.events;

		/*
		 * If the event mask intersect the caller-requested one,
		 * deliver the event to userspace. Again, ep_scan_ready_list()
		 * is holding &quot;mtx&quot;, so no operations coming from userspace
		 * can change the item.
		 */
    /*
     * 如果这个fd发生的事件有我们关注的事件,
     * 那么我们就把这个事件返回到用户空间去
     */
		if (revents) {
			if (__put_user(revents, &amp;amp;uevent-&amp;gt;events) ||
			    __put_user(epi-&amp;gt;event.data, &amp;amp;uevent-&amp;gt;data)) {
        /*
         * 这里是向用户空间拷贝函数失败的分支
         * 这里是如果失败, 那么直接返回当前有多少个事件
         * 如果一个事件也没用, 那么直接返回EFAULT
         */
				list_add(&amp;amp;epi-&amp;gt;rdllink, head);
				return eventcnt ? eventcnt : -EFAULT;
			}
			eventcnt++;
			uevent++;
      // 这里上面这个分支就是EPOLLET 的情况
			if (epi-&amp;gt;event.events &amp;amp; EPOLLONESHOT)
				epi-&amp;gt;event.events &amp;amp;= EP_PRIVATE_BITS;
			else if (!(epi-&amp;gt;event.events &amp;amp; EPOLLET)) {
        /*
         * 这里是EPOLLLT 的情况, EPOLLLT 是默认情况, 从这里看出, LT
         * 模式会将这个fd重新加入到这个rdllist 里面, 那么下次会再通知这个fd
         * 里面的事件. 那么问题来了, 什么时候才会从这个rdllist 里面删除呢?
         * 
         * 这个删除操作是默认都做的, 就在上面
         * list_del_init(&amp;amp;epi-&amp;gt;rdllink);
         *
         * 比如说pipe 写进来了5个byte 的内容, 第一次读取了2个字节, 然后就返回了,
         * 在下一次执行epoll_wai()的时候, 因为LT 模式默认又加入了rdllist里面,
         * 所有会再一次检查这个fd 里面的状态, 这个时候发现里面还是有数据,
         * 就再一次返回给用户这个状态是
         *
         * 如果是ET模式, 这里可以看到不会添加回去这个rdllist,
         * 那么只有等到这个pipe里面再写入数据的时候才会触发ep_poll_callback把这个fd添加到rdllist里面,
         *
         * 从这里可以看出EPOLL_LT模式是多做了一次的检查,
         * 因为每次完成以后又会加入到这个rdllist里面, 因此性能肯定不如ET模式,
         * 但是ET模式存在说如果一次读取fd没有都读完,
         * 那么必须等到这个fd再有事件过来, 才会通知这个fd
         *
         * 另外一个问题: 这里直接往rdllist 里面添加元素, 这里遍历这个txlist
         * 不会直接把这个元素给遍历到么? 因为这里正好添加到了这个list的尾部.
         * 注释里面为什么写着是下一次的 epoll_wait 在进行一次判断呢?
         *
         * 答: 这里是epoll 实现的时候对锁粒度的一个优化, 每一次有时间的epitem
         * 是存入到idllist 这个队列里面, 然后在进行要传给用户空间操作的时候
         * ep_send_events_proc, 在上面讲这个idllist 的指针传递给了txlist指针,
         * 那么接下来就可以同时往idllist 里面添加元素,
         * 又可以处理txlist(也就是原先的rdllist)上面的内容, 这里就不需要加锁了
         */
				/*
				 * If this file has been added with Level
				 * Trigger mode, we need to insert back inside
				 * the ready list, so that the next call to
				 * epoll_wait() will check again the events
				 * availability. At this point, noone can insert
				 * into ep-&amp;gt;rdllist besides us. The epoll_ctl()
				 * callers are locked out by
				 * ep_scan_ready_list() holding &quot;mtx&quot; and the
				 * poll callback will queue them in ep-&amp;gt;ovflist.
				 */
				list_add_tail(&amp;amp;epi-&amp;gt;rdllink, &amp;amp;ep-&amp;gt;rdllist);
			}
		}
	}

	return eventcnt;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;tips&quot;&gt;Tips:&lt;/h3&gt;

&lt;h5 id=&quot;fd&quot;&gt;如何唤醒监听的fd&lt;/h5&gt;

&lt;p&gt;这里加入我们有队列注册在某一个fd 上面, 那么当这个fd 有时间到达的时候, 是如何唤醒这个队列里面所有的进程呢&lt;/p&gt;

&lt;p&gt;比如具体的 socket 类型的文件, 那么当这个文件有事件到达的时候, 如何进行唤醒的呢?
这里比如tcp 调用的就是  tcp_prequeue 方法, 然后里面有 wake_up_interruptible_poll
这里wake_up_interruptible_poll 就是去调用一个唤醒队列的方法了
最后都会调用到kernel/sched.c:__wake_up_common 方法
这里就跟进程的调度模块比较相关了&lt;/p&gt;

&lt;h5 id=&quot;fileoperations-poll-&quot;&gt;对了file_operations 里面的poll 操作的解释&lt;/h5&gt;

&lt;p&gt;poll(file, poll_table)
Checks whether there is activity on a file and goes to sleep until something happens on it.
可以看上一个blog&lt;/p&gt;

&lt;h5 id=&quot;fd--&quot;&gt;当一个fd上面有事件发生的时候, 是会唤醒监听这个文件上等待的进程的. 这个是怎么做到的?&lt;/h5&gt;

&lt;p&gt;每一个设备在linux 看来都是一个文件, 那么对于文件操作来说, 每一个都需要实现file_operations 里面的poll 这个操作, 这个操作的意思是检查这个fd是否活动, 可以看上一篇blog 对应的pollc操作&lt;/p&gt;

&lt;p&gt;比如以 pipe 的实现举例子的话&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct pipe_inode_info {
  wait_queue_head_t wait;
  unsigned int nrbufs, curbuf;
  struct page *tmp_page;
  unsigned int readers;

这里有一个pipe_inode_info, 如果当这个pipe 有数据写入的时候
static ssize_t
pipe_read(struct kiocb *iocb, const struct iovec *_iov,
     unsigned long nr_segs, loff_t pos)
{
    if (do_wakeup) {
      wake_up_interruptible_sync(&amp;amp;pipe-&amp;gt;wait);
      kill_fasync(&amp;amp;pipe-&amp;gt;fasync_writers, SIGIO, POLL_OUT);
    }
}

最后的wake_up 函数其实最后会调用到
static void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
      int nr_exclusive, int wake_flags, void *key)

这个函数里面去了, 然后最后的调用是
    /*
     * 这里的func 默认会调用到default_wake_function, 因为在wait_queue_t
     * 初始化的时候回设置func = default_wake_function
     * 如果有注册函数就执行对应的注册函数
     */
    if (curr-&amp;gt;func(curr, mode, wake_flags, key) &amp;amp;&amp;amp;
        (flags &amp;amp; WQ_FLAG_EXCLUSIVE) &amp;amp;&amp;amp; !--nr_exclusive)
      break;
  }
就是执行注册的函数

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最后就会调用wake_up_interruptible_sync, 这个就把pipe_inode_info 上面的wait_queue_head_t 上面的等待进程队列唤醒, 那么这里pipe-&amp;gt;wait 上面的这个等待队列是什么时候加上去的呢?&lt;/p&gt;

&lt;p&gt;说明每一个文件都有这个文件的唤醒队列, 当这个文件有操作的时候, 会通过wake_up 操作来将这个唤醒队列的进程给唤醒,&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;那么一般是怎么加入到这个唤醒队列里面的呢?&lt;/h4&gt;

&lt;p&gt;首先是注册到这个fd 的wait_queue_t 里面&lt;/p&gt;

&lt;p&gt;过程是在epoll_insert 的时候会调用一下这个pipe fd的poll() 函数
这里在epoll 里面会调用&lt;/p&gt;

&lt;p&gt;revents = tfile-&amp;gt;f_op-&amp;gt;poll(tfile, &amp;amp;epq.pt);&lt;/p&gt;

&lt;p&gt;这个操作就是将当前的进程加入到tfile 这个fd 的唤醒队列里面去.&lt;/p&gt;

&lt;p&gt;对应于在pipe 里面的调用就是&lt;/p&gt;

&lt;p&gt;pipe_poll(struct file *filp, poll_table *wait)&lt;/p&gt;

&lt;p&gt;然后在pipe_poll 里面调到的最重要的是&lt;/p&gt;

&lt;p&gt;poll_wait(filp, &amp;amp;pipe-&amp;gt;wait, wait);&lt;/p&gt;

&lt;p&gt;poll_wait 本质到最后调用的是ep_ptable_queue_proc函数, 因为在epoll 调用tfile-&amp;gt;f_op-&amp;gt;poll 的时候已经注册了这个回调函数&lt;/p&gt;

&lt;p&gt;static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead,
         poll_table *pt)
{&lt;/p&gt;

&lt;h4 id=&quot;pollselect-&quot;&gt;为什么说 poll/select 的性能比较低&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;在poll/select 的实现里面, 如果监听多个fd, 只要其中有一个fd 有事件达到, 那么久遍历一个list 去检查到底是哪一个事件到达, 并没有像epoll 一样将这些fd 放在一个红黑树上&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
  /*
   * 程序在这里面schedule_timeout 中sleep, 如果有事件到达,
   * 从schedule_timeout中唤醒, 然后重新执行逻辑
   */
	for (;;) {
		unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp;

		inp = fds-&amp;gt;in; outp = fds-&amp;gt;out; exp = fds-&amp;gt;ex;
		rinp = fds-&amp;gt;res_in; routp = fds-&amp;gt;res_out; rexp = fds-&amp;gt;res_ex;

    /*
     * 这里检查监听的所有的fd 的状态, 如果这个fd 有事件, 就把对应的rinp, routp,
     * rexp 进行修改
     * 这里可以看到, 即使只有一个fd有事件到达, 这里也要把所有的fd 都遍历一遍,
     * 这就是性能很低的原因了
     */
		for (i = 0; i &amp;lt; n; ++rinp, ++routp, ++rexp) {

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;在进行select 的过程中, 是先将要监听的fd 从用户空间拷贝到内核空间, 然后在内核空间里面进行修改以后, 在拷贝回去给用户空间. 这里就设计到内核空间申请内存, 释放内存等等过程&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int core_sys_select(int n, fd_set __user *inp, fd_set __user *outp,
			   fd_set __user *exp, struct timespec *end_time)
{
	fd_set_bits fds;
	void *bits;
	int ret, max_fds;
	unsigned int size;
	struct fdtable *fdt;
  // 可以看到select 是先尝试分配空间在栈上, 下面代码可以看出加入这个需要监听的fd
  // 比较多, 那么就会去申请堆空间里面的内容
  // 这里SELECT_STACK_ALLOC 默认是 256, 那么也就是这个当监听的fd
  // 的个数小于256个的时候, 这里的空间实在栈上,
  // 如果大于256其实空间实在堆上面申请的
	/* Allocate small arguments on the stack to save memory and be faster */

	long stack_fds[SELECT_STACK_ALLOC/sizeof(long)];

	ret = -EINVAL;
	if (n &amp;lt; 0)
		goto out_nofds;

	/* max_fds can increase, so grab it once to avoid race */
	rcu_read_lock();
	fdt = files_fdtable(current-&amp;gt;files);
	max_fds = fdt-&amp;gt;max_fds;
	rcu_read_unlock();
	if (n &amp;gt; max_fds)
		n = max_fds;

	/*
	 * We need 6 bitmaps (in/out/ex for both incoming and outgoing),
	 * since we used fdset we need to allocate memory in units of
	 * long-words. 
	 */
	size = FDS_BYTES(n);
	bits = stack_fds;
	if (size &amp;gt; sizeof(stack_fds) / 6) {
		/* Not enough space in on-stack array; must use kmalloc */
		ret = -ENOMEM;
		bits = kmalloc(6 * size, GFP_KERNEL);
		if (!bits)
			goto out_nofds;
	}
  /*
   * 这里分别为in, out, ex, res_in, res_out, res_ex 初始化指针到对应的空间里面
   *
   * 我们经常说的select 需要拷贝这个fd 值得就是这里,
   * 就是将用户空间注册的要监听的fd inp, outp, exp 拷贝到fds.in, fds.out,
   * fds.ex. 然后这些fd 的事件的结果我们保存在 fds.res_in, fds.res_out,
   * fds.res_ex. 然后再将这里面的内容拷贝回去到用户空间 inp, outp, exp
   */
	fds.in      = bits;
	fds.out     = bits +   size;
	fds.ex      = bits + 2*size;
	fds.res_in  = bits + 3*size;
	fds.res_out = bits + 4*size;
	fds.res_ex  = bits + 5*size;

  /*
   * 这里就是我们经常说的select需要去用户空间拷贝内容的代码
   * 这里就是把存在inp 里面注册的内容拷贝到 fds.in 里面
   */
	if ((ret = get_fd_set(n, inp, fds.in)) ||
	    (ret = get_fd_set(n, outp, fds.out)) ||
	    (ret = get_fd_set(n, exp, fds.ex)))
		goto out;
	zero_fd_set(n, fds.res_in);
	zero_fd_set(n, fds.res_out);
	zero_fd_set(n, fds.res_ex);

  /*
   * 这里是最主要的select 的过程了
   * ret 返回的是当前有事件的fd 的个数
   */
	ret = do_select(n, &amp;amp;fds, end_time);

	if (ret &amp;lt; 0)
		goto out;
	if (!ret) {
		ret = -ERESTARTNOHAND;
		if (signal_pending(current))
			goto out;
		ret = 0;
	}

  /*
   * 这里就是讲内核空间fds.res_in, out, ex里面的内容拷贝回去到inp, outp, exp
   * 的过程
   */
	if (set_fd_set(n, inp, fds.res_in) ||
	    set_fd_set(n, outp, fds.res_out) ||
	    set_fd_set(n, exp, fds.res_ex))
		ret = -EFAULT;

out:
	if (bits != stack_fds)
		kfree(bits);
out_nofds:
	return ret;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Sun, 06 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20tech/2016/03/06/epoll_implementation/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20tech/2016/03/06/epoll_implementation/</guid>
      </item>
    
      <item>
        <title>kernel list</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;困惑点&lt;/h3&gt;
&lt;p&gt;之前看kernel list 的时候困惑的地方在于这个list里面居然没有指针指向这个list
对应的struct, 而是直接指向struct 里面的list 元素,
比如这样&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct my_cool_list{
  struct list_head list; /* kernel&#39;s list structure */
  int my_cool_data;
  void* my_cool_void;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;那么怎么返回这个实际包含这个list 里面的元素的struct 的结构体呢?&lt;/p&gt;

&lt;p&gt;答案: 其实最重要的一点就是有list_entry(ptr, type, member) 这个宏定义,
这个宏实现可以从一个struct 里面的一个元素, 然后返回这个struct 的地址,
这个是怎么做的呢?&lt;/p&gt;

&lt;p&gt;其实也很好实现, 就是把struct 里面的偏移量拿来加减就可以了, 比如
struct node {
  int a;
  int b;
}&lt;/p&gt;

&lt;p&gt;知道这个node.b 的地址, 那么很容易根据偏移量减去这个地址就可以了. 所以&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#define list_entry(ptr, type, member) \
        ((type *)((char *)(ptr)-(unsigned long)(&amp;amp;((type *)0)-&amp;gt;member)))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里ptr 就是这个b 的地址, 然后type 就是这个node 这个结构体, member 就是这个b.&lt;/p&gt;

&lt;p&gt;那么这里我们是怎么知道b 这个元素在这个结构体里面的偏移量呢?&lt;/p&gt;

&lt;p&gt;Now the question is how can we compute the offset of an element in a structure? Suppose you have a data structure struct foo_bar and you want to find the offset of element boo in it, this is how you do it:
(unsigned long)(&amp;amp;((struct foo_bar *)0)-&amp;gt;boo)&lt;/p&gt;

&lt;p&gt;这样就可以了
这里的做法就是用foo_bar 结构体指针指向这个0这个地址, -&amp;gt; boo的操作其实就是增加这个偏移量, 然后获得这个元素的地址了&lt;/p&gt;

&lt;p&gt;其他的地方就是普通的list 结构, 然后封装好了比较方便的操作了
&lt;img src=&quot;http://i.imgur.com/513DxAK.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kernel-list-&quot;&gt;kernel list 好在哪里呢?&lt;/h3&gt;

&lt;p&gt;我们平常自己实现的list 一般是这么实现的&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
struct my_list{
  void *myitem;
  struct my_list *next;
  struct my_list *prev;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里我们想要获得下一个list元素, 一般有一个对应struct 类型的指针 *next;&lt;br /&gt;
然后这个next 指针一般指向下一个my_list;&lt;/p&gt;

&lt;p&gt;然而kernel 里面的list 是这么实现&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct my_cool_list{
  struct list_head list; /* kernel&#39;s list structure */
  int my_cool_data;
  void* my_cool_void;
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里可以看到相比较于我们自己实现的list, kernel list 的优点有&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;直接把这个list_head 结构体放在一个struct 内部, 就可以让这个struct 实现一个list 结构, 不需要知道这个struct 的类型, 实现的非常的通用, 这里也可以在这个 把这个list 连接的不是这个my_cool_list 类型, 连接其他类型也是完全可以&lt;/li&gt;
  &lt;li&gt;可以放多个list_head 结构, 这样这个结构体就可以连成多个list, 虽然原生的方法也可以, 不过这样看上去非常的简洁&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个是list 的具体使用方法,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

#include &quot;list.h&quot;

struct kool_list{
  int to;
  struct list_head list;
  int from;
};

int main(int argc, char **argv){

  struct kool_list *tmp;
  struct list_head *pos, *q;
  unsigned int i;

  struct kool_list mylist;
  INIT_LIST_HEAD(&amp;amp;mylist.list);
  /* or you could have declared this with the following macro
  * LIST_HEAD(mylist); which declares and initializes the list
   */

  /* adding elements to mylist */
  for(i=5; i!=0; --i){
    tmp= (struct kool_list *)malloc(sizeof(struct kool_list));

    /* INIT_LIST_HEAD(&amp;amp;tmp-&amp;gt;list);
    *
    * this initializes a dynamically allocated list_head. we
    * you can omit this if subsequent call is add_list() or
    * anything along that line because the next, prev
    * fields get initialized in those functions.
     */
    printf(&quot;enter to and from:&quot;);
    scanf(&quot;%d %d&quot;, &amp;amp;tmp-&amp;gt;to, &amp;amp;tmp-&amp;gt;from);

    /* add the new item &#39;tmp&#39; to the list of items in mylist */
    list_add(&amp;amp;(tmp-&amp;gt;list), &amp;amp;(mylist.list));
    /* you can also use list_add_tail() which adds new items to
    * the tail end of the list
     */
  }
  printf(&quot;\n&quot;);

  /* now you have a circularly linked list of items of type struct kool_list.
  * now let us go through the items and print them out
   */

  /* list_for_each() is a macro for a for loop.
  * first parameter is used as the counter in for loop. in other words, inside the
  * loop it points to the current item&#39;s list_head.
  * second parameter is the pointer to the list. it is not manipulated by the macro.
   */
  printf(&quot;traversing the list using list_for_each()\n&quot;);
  list_for_each(pos, &amp;amp;mylist.list){

    /* at this point: pos-&amp;gt;next points to the next item&#39;s &#39;list&#39; variable and
    * pos-&amp;gt;prev points to the previous item&#39;s &#39;list&#39; variable. Here item is
    * of type struct kool_list. But we need to access the item itself not the
    * variable &#39;list&#39; in the item! macro list_entry() does just that. See &quot;How
    * does this work?&quot; below for an explanation of how this is done.
     */
    tmp= list_entry(pos, struct kool_list, list);

    /* given a pointer to struct list_head, type of data structure it is part of,
    * and it&#39;s name (struct list_head&#39;s name in the data structure) it returns a
    * pointer to the data structure in which the pointer is part of.
    * For example, in the above line list_entry() will return a pointer to the
    * struct kool_list item it is embedded in!
     */

    printf(&quot;to= %d from= %d\n&quot;, tmp-&amp;gt;to, tmp-&amp;gt;from);

  }
  printf(&quot;\n&quot;);
  /* since this is a circularly linked list. you can traverse the list in reverse order
  * as well. all you need to do is replace &#39;list_for_each&#39; with &#39;list_for_each_prev&#39;
  * everything else remain the same!
  *
  * Also you can traverse the list using list_for_each_entry() to iterate over a given
  * type of entries. For example:
   */
  printf(&quot;traversing the list using list_for_each_entry()\n&quot;);
  list_for_each_entry(tmp, &amp;amp;mylist.list, list)
    printf(&quot;to= %d from= %d\n&quot;, tmp-&amp;gt;to, tmp-&amp;gt;from);
  printf(&quot;\n&quot;);

  /* now let&#39;s be good and free the kool_list items. since we will be removing items
  * off the list using list_del() we need to use a safer version of the list_for_each()
  * macro aptly named list_for_each_safe(). Note that you MUST use this macro if the loop
  * involves deletions of items (or moving items from one list to another).
   */
  printf(&quot;deleting the list using list_for_each_safe()\n&quot;);
  list_for_each_safe(pos, q, &amp;amp;mylist.list){
    tmp= list_entry(pos, struct kool_list, list);
    printf(&quot;freeing item to= %d from= %d\n&quot;, tmp-&amp;gt;to, tmp-&amp;gt;from);
    list_del(pos);
    free(tmp);
  }

  return 0;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Sun, 28 Feb 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20tech/2016/02/28/kernel-list/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20tech/2016/02/28/kernel-list/</guid>
      </item>
    
      <item>
        <title>kernel file poll operations</title>
        <description>&lt;h4 id=&quot;fileoperations--poll-&quot;&gt;在file_operations 里面, poll 这个操作到底是什么意思&lt;/h4&gt;

&lt;p&gt;在ulk 里面poll 操作的解释是&lt;/p&gt;

&lt;p&gt;Checks whether there is activity on a file and goes to sleep until something happens on it.&lt;/p&gt;

&lt;p&gt;然后我看了kernel(2.6.32) 里面的实现, 其实并没有sleep的过程&lt;/p&gt;

&lt;p&gt;看不同kernel 里面fd 的poll 实现可以发现其实poll 操作做的事情主要是两个&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;注册这个唤醒队列的回调函数, 也就是设置当这个fd 有事件到达的时候的执行函数&lt;/li&gt;
  &lt;li&gt;返回当前这个fd 的事件状态, 比如这里pipe 的状态就是根据 nrbufs 里面的内容的多少来返回这个当前fd的状态, tcp的判断就更加复杂一些&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;比如这个是pipe 上面的 poll 操作 pipe_poll()&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
/* No kernel lock held - fine */
static unsigned int
pipe_poll(struct file *filp, poll_table *wait)
{
  unsigned int mask;
  struct inode *inode = filp-&amp;gt;f_path.dentry-&amp;gt;d_inode;
  struct pipe_inode_info *pipe = inode-&amp;gt;i_pipe;
  int nrbufs;

  poll_wait(filp, &amp;amp;pipe-&amp;gt;wait, wait);

  /* Reading only -- no need for acquiring the semaphore.  */
  nrbufs = pipe-&amp;gt;nrbufs;
  mask = 0;
  if (filp-&amp;gt;f_mode &amp;amp; FMODE_READ) {
    // 这里nrbufs &amp;gt; 0, 说明这个pipe里面是有内容的, 因此这个fd 有可读事件
    mask = (nrbufs &amp;gt; 0) ? POLLIN | POLLRDNORM : 0;
    if (!pipe-&amp;gt;writers &amp;amp;&amp;amp; filp-&amp;gt;f_version != pipe-&amp;gt;w_counter)
      mask |= POLLHUP;
  }

  if (filp-&amp;gt;f_mode &amp;amp; FMODE_WRITE) {
    // 只要nrbufs &amp;lt; PIPE_BUFFERS, 说明这个pipe 还没被写满, 那么这个fd 就是可写的
    mask |= (nrbufs &amp;lt; PIPE_BUFFERS) ? POLLOUT | POLLWRNORM : 0;
    /*
     * Most Unices do not set POLLERR for FIFOs but on Linux they
     * behave exactly like pipes for poll().
     */
    if (!pipe-&amp;gt;readers)
      mask |= POLLERR;
  }

  return mask;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对应的tcp 里面是否有时间到达的poll 函数是 tcp_poll()&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;unsigned int tcp_poll(struct file *file, struct socket *sock, poll_table *wait)
{
  unsigned int mask;
  struct sock *sk = sock-&amp;gt;sk;
  struct tcp_sock *tp = tcp_sk(sk);
  sock_poll_wait(file, sk-&amp;gt;sk_sleep, wait);
  if (sk-&amp;gt;sk_state == TCP_LISTEN)
    return inet_csk_listen_poll(sk);

  /* Socket is not locked. We are protected from async events
   * by poll logic and correct handling of state changes
   * made by other threads is impossible in any case.
   */

  mask = 0;
  if (sk-&amp;gt;sk_err)
    mask = POLLERR;

...
  if (sk-&amp;gt;sk_shutdown == SHUTDOWN_MASK || sk-&amp;gt;sk_state == TCP_CLOSE)
    mask |= POLLHUP;
  if (sk-&amp;gt;sk_shutdown &amp;amp; RCV_SHUTDOWN)
    mask |= POLLIN | POLLRDNORM | POLLRDHUP;

  /* Connected? */
  if ((1 &amp;lt;&amp;lt; sk-&amp;gt;sk_state) &amp;amp; ~(TCPF_SYN_SENT | TCPF_SYN_RECV)) {
    int target = sock_rcvlowat(sk, 0, INT_MAX);

    if (tp-&amp;gt;urg_seq == tp-&amp;gt;copied_seq &amp;amp;&amp;amp;
        !sock_flag(sk, SOCK_URGINLINE) &amp;amp;&amp;amp;
        tp-&amp;gt;urg_data)
      target--;

    /* Potential race condition. If read of tp below will
     * escape above sk-&amp;gt;sk_state, we can be illegally awaken
     * in SYN_* states. */
    if (tp-&amp;gt;rcv_nxt - tp-&amp;gt;copied_seq &amp;gt;= target)
      mask |= POLLIN | POLLRDNORM;

    if (!(sk-&amp;gt;sk_shutdown &amp;amp; SEND_SHUTDOWN)) {
      if (sk_stream_wspace(sk) &amp;gt;= sk_stream_min_wspace(sk)) {
        mask |= POLLOUT | POLLWRNORM;
      } else {  /* send SIGIO later */
        set_bit(SOCK_ASYNC_NOSPACE,
          &amp;amp;sk-&amp;gt;sk_socket-&amp;gt;flags);
        set_bit(SOCK_NOSPACE, &amp;amp;sk-&amp;gt;sk_socket-&amp;gt;flags);
    /* Potential race condition. If read of tp below will
     * escape above sk-&amp;gt;sk_state, we can be illegally awaken
     * in SYN_* states. */
    if (tp-&amp;gt;rcv_nxt - tp-&amp;gt;copied_seq &amp;gt;= target)
      mask |= POLLIN | POLLRDNORM;

    }

    if (tp-&amp;gt;urg_data &amp;amp; TCP_URG_VALID)
      mask |= POLLPRI;
  }
  return mask;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里可以看到, tcp 的tcp_poll() 里面也是同样调用socket_poll_wait, 然后socket_poll_wait 调用poll_wait来注册当有时间发生的时候的回调函数.&lt;/p&gt;

&lt;p&gt;然后这里tcp 这个是否有时间到达需要进行的判断就比pipe 要复杂的多, 比如这里需要判断socket 的是否shut_down, 需要判断tp-&amp;gt;rcv_nxt 等等, 最后才能获得这个fd 上面的事件的内容&lt;/p&gt;
</description>
        <pubDate>Sun, 28 Feb 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//kernel,%20tech/2016/02/28/kernel-file-poll-operations/</link>
        <guid isPermaLink="true">http://baotiao.github.io//kernel,%20tech/2016/02/28/kernel-file-poll-operations/</guid>
      </item>
    
      <item>
        <title>Haystack object storage</title>
        <description>&lt;h3 id=&quot;haystack&quot;&gt;HayStack&lt;/h3&gt;
&lt;p&gt;HayStack 是facebook 的一个针对图片存储的object storage. 以下大概是HayStack设计&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;图片大部分的应用场景是 只写一次, 然后经常读取, 以及从来不会对图片进行修改. 并且极其少的可能去修改这个图片&lt;/li&gt;
  &lt;li&gt;Haystack 主要包含Haystack Directory, Haystack Cache, Haystack Store. 那么读写的流程分别是
&lt;img src=&quot;http://i.imgur.com/Xa1E5zg.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Hjn71u5.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出这里Haystack Directory 里面应该保存的是数据的元信息&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Haystack Store 可以说自己实现了一套存取图片的引擎. 如果只是用操作系统的文件系统, 存在的问题是.
    &lt;ul&gt;
      &lt;li&gt;某一个目录下面存放大量的图片的文件, 那么由于文件系统里面目录也是跟保存在一个block里面, 那么就会造成这个目录的node下面的data block的内容过大, 那么为了取到这个目录的meta信息, 就需要读取多个block 才能读取得到需要的内容&lt;/li&gt;
      &lt;li&gt;只是用文件系统来保存图片的话, 为了读取到一次图片, 我们需要首先读取对应的目录的inode数据, 然后是目录的data block, 然后从里面找到我们需要的文件, 然后读取这个文件的inode, 然后是读取这个文件的data block. 从这里可以看出, 我们为了找到一个文件, 需要经过多次的磁盘IO最终才能找到这个数据.&lt;/li&gt;
      &lt;li&gt;如果我们存的图片不大, 那么就会找出大量的小文件的情况发生&lt;/li&gt;
      &lt;li&gt;通过后续的计算可以看出,比如在xfs系统下面建立一个文件xfs inode 信息大小是536 byte, 而如果可以通过自己实现我们需要的元信息的的大小可以做到40 bytes&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;那么Haystack Store 的主要的一个事情就是建立一个大文件, 然后在这个大文件头建立SuperBlock的信息, 然后底下的数据模块具体放文件的内容. 那么在这个大文件里面找到某一个文件的信息就需要一个Index 的信息
&lt;img src=&quot;http://i.imgur.com/Hyowus5.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个是Index File 的信息, Index File 里面needle 的数据的顺序必须严格和数据文件的needle 一致
&lt;img src=&quot;http://i.imgur.com/OyAWZOt.png&quot; alt=&quot;Imgur&quot; /&gt;
Since index records do not reflect deleted photos, a Store machine may retrieve a photo that has in fact been deleted. To address this issue, after a Store machine reads the entire needle for a photo, that machine can then inspect the deleted flag. If a needle is marked as deleted the Store machine updates its in-memory map- ping accordingly and notifies the Cache that the object was not found.&lt;/p&gt;

&lt;p&gt;所以从这里可以看出来, 具体的文件是否被删除的信息是存放在volume file里面的, 我有一个疑惑? 为什么不直接将这个文件是否被删除的flag存放在index file 里面呢&lt;/p&gt;

&lt;p&gt;总结: HayStack Store的核心其实是自己来分配这个磁盘空间, 就是memcache 一样, 因为作为应用层, 我自己对我当前的应用的需求更加的了解, 而kernel的内存分配规则是针对通用的应用的需求. 因此memcache的做法就是自己提前申请一块大内存, 然后在这块大内存上面自己进行内存分配. 那么HayStack Store 的做法就是自己提前申请一块大的磁盘空间, 然后在这个大的磁盘空间上面进行空间分配, 因为HayStack Store 对这个磁盘的需求的理解是由于kernel的&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Haystack 的优化也主要在于会对文件进行compact, 这里的compact指的是将这个volume file里面标记成删除的文件删除掉, 还有一个是尽可能的减少一个文件需要的inode信息的大小&lt;/li&gt;
  &lt;li&gt;Haystack 的思想和 log struct file system 很像, 就是顺序写入到磁盘, 然后大部分的读取是会命中cache的, 这样读的时候虽然需要查找多次才能读到数据, 由于cache的命中率高. 所以还是可以接受的. 并且Haystack 由于应用的场景是图片. 所以这种场景对于写入的数据修改的情况就更少了.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 25 Dec 2015 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//tech/2015/12/25/facebook-haystack/</link>
        <guid isPermaLink="true">http://baotiao.github.io//tech/2015/12/25/facebook-haystack/</guid>
      </item>
    
  </channel>
</rss>
