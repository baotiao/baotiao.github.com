<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>baotiao</title>
    <description>做有积累的事情</description>
    <link>http://baotiao.github.io//</link>
    <atom:link href="http://baotiao.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>talk about event based concurrency</title>
        <description>&lt;p&gt;&lt;strong&gt;比如像redis 单线程基于epoll 这种模型, node.js 这种模型都可以归结为Event-base Concurrency, 那么这种模型和multi-thread 对比有什么区别呢?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从调度角度来看multi-thread 是kernel 来决定下一个要调度处理的thread 是哪一个. 而kernel cpu scheduler 又是一个很大的模块, 很难肯定下一个要调度的thread 是哪一个.&lt;/p&gt;

&lt;p&gt;event-based 是当要监听的fd 有事情到达的时候, 由当前这个thread 来决定下一个要执行的event 是谁, 也就是说event-based 是可以实现用户自己决定下一个要执行的任务是谁. 比如简单的可以记录我这次到达的fd里面哪些是优先级高的fd即可.&lt;/p&gt;

&lt;p&gt;因为multi-thread 会考虑到每一个thread 的优先级等等, 而且如果thread 数目过多那么肯定会影响到具体的调度.虽然kernel scheduler 能够做到O(1) 的级别. 对比event-base, 切换线程需要切换上下文, 因此肯定会有性能的损耗.&lt;/p&gt;

&lt;p&gt;而在event-base 里面, 所有的event 的优先级都是一样的, 然后在处理event 的handler 里面决定先处理哪一个event. 但是同样有一个问题就是如果这个event-base 里面event 比较多, 那么性能肯定也会下来.&lt;/p&gt;

&lt;p&gt;那么event-base 缺点也有, 如果要使用多核的cpu的时候, 想要同时并行的运行多个event server 的时候, 需要用lock 进行同步的问题又来了.&lt;/p&gt;

&lt;p&gt;另外其实有些系统调用并不能支持异步, 比如如果一个处理 event handler 访问内存的时候触发了page fault, 那么这个时候是并不能把这个event handler 切换出去了, 必须等待这个page fault 执行完才可以. 所以kernel 还是不能做到全异步话, 还是有一些逻辑同步的.&lt;/p&gt;

&lt;p&gt;pink 里面的设计, 其实是综合上面考虑的结果, 不是一个纯 multi-thread, 也不是一个纯even based. 会有多个work thread, 然后每一个work thread 内部是event-base concurrency.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/XXfibpV.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 26 Nov 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/11/26/concurrency/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/11/26/concurrency/</guid>
      </item>
    
      <item>
        <title>将this 指针传给子类的问题</title>
        <description>&lt;h3 id=&quot;this-&quot;&gt;将this 指针传给子类的一些问题&lt;/h3&gt;

&lt;p&gt;最近实现代码的时候经常会遇到这种问题需要大量的将this指针传给类底下的成员变量, 因为成员变量需要用到父类里面的成员. 抽象出来是这种情况&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里A 类的两个子类 B, C 都会使用到A类里面的成员 d_, e_, str_. 所以我们经常要初始化的时候去给两个子类去传这个变量, 那么这个时候经常为了方便就直接将this 指针往下传, 变成这种&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ceph 的代码里面就大量的这种将this 指针往下传的代码, 比如FileStore 里面sync_thread, op_wq 就是这种关系.&lt;/p&gt;

&lt;h4 id=&quot;this--1&quot;&gt;直接传this 指针有什么不好呢?&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;父类和子类互相依赖, 封装的不是很好&lt;/li&gt;
  &lt;li&gt;由于子类需要访问父类里面的成员, 常见的做法就是把这些变量做成public, 或者将B, C作为A类的friend 类, 这样就违反的封装的原则. 第一版floyd 就是这个做法&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RaftConsensus&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeaderDiskThread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;LeaderDiskThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RaftConsensus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raft_con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeaderDiskThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;virtual&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ThreadMain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;RaftConsensus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raft_con_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;LeaderDiskThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leader_disk_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;friend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeaderDiskThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;friend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ElectLeaderThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;friend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PeerThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最简单的做法就是将B, C 类里面的内容往外提, 那么B, C类里面的内容就可以直接访问d_, e_, str_这些内容了, 但是更多的情况是 B, C 类是从其他类继承的, 这个时候就不能把B, C 类里面的内容往外提&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section&quot;&gt;那么比较好的解决方法是什么样子的呢?&lt;/h4&gt;

&lt;p&gt;我觉得leveldb 里面的Options 这个封装就比较好, Options 将需要访问的公共的成员变量都放在一个对象里面, 然后将Options 这个对象往子类传, 比如&lt;/p&gt;

&lt;p&gt;DBImpl 这个对象里面有 options, env_&lt;/p&gt;

&lt;p&gt;DBImpl 底下的TableCache, VersionSet 也需要这个options, env_ 这两个对象, 那么Leveldb 的做法就是将子类都需要访问的内容放在一起, 然后将这个对象以指针的形式往下传, 因为通常如果子类对这些对象进行了修改以后, 其他对象应该也是要能够看到的.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DBImpl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DB&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Env&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InternalKeyComparator&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;internal_comparator_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InternalFilterPolicy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;internal_filter_policy_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// options_.comparator == &amp;amp;internal_comparator_
&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// table_cache_ provides its own synchronization
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TableCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_cache_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;VersionSet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;versions_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;TableCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TableCache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dbname_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;options_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cache_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewLRUCache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;VersionSet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VersionSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;TableCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InternalKeyComparator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dbname_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;options_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;table_cache_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;icmp_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;所以比较好的解决方法是把这些要把子类访问的对象放在一个struct 里面, 比如Options 这种, 或者像Env 这种里面都是一些Public的方法, 然后传给子类的对象自己去.&lt;/p&gt;

&lt;p&gt;这样写以后代码就清晰多了, 但是做的也就更细了&lt;/p&gt;

&lt;p&gt;所以还是看到一个东西是这个样子不重要, 最重要的应该是了解这个东西为什么是现在这个样子.&lt;/p&gt;
</description>
        <pubDate>Thu, 24 Nov 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/11/24/cpp-pass-this/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/11/24/cpp-pass-this/</guid>
      </item>
    
      <item>
        <title>cache policy</title>
        <description>&lt;h3 id=&quot;cache-policy&quot;&gt;cache policy&lt;/h3&gt;

&lt;p&gt;近期在做ceph cache-tier 相关的事情, 在cache-tier 里面cache有多种更新策略&lt;/p&gt;

&lt;p&gt;其实更缓存相关的系统里面, 都存在这几种策略, 比如操作系统的page cache,
业务层使用memcache, redis 作为后端数据库的缓存的时候,
也都要考虑缓存和后端存储的数据一致性问题. 其实就是更新操作的时候,
什么时候去更新缓存, 什么时候去更新后端存储的问题?&lt;/p&gt;

&lt;p&gt;那么这个时候一般会有3种策略&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;no-write&lt;/li&gt;
  &lt;li&gt;write-through&lt;/li&gt;
  &lt;li&gt;write-back&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;no-write&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;no-write 的实现方式是写入数据的时候是直接将数据写入到后端存储, 并且标记cache 中的数据是无效的, 那么后续的某一次读取发现无效以后, 会发起一次读取请求, 将后端存储中的数据更新到cache 中, 并且标记有效&lt;/p&gt;

&lt;p&gt;这个策略其实很少使用&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;write-through&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;write-through 实现方式是写入的时候将cache 和 后端存储的数据一起更新, 这种方法最能够保证cache 数据的一致性. 并且也是简单的方法, 但也是性能最低的一个方法&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;write-back&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;write-back 也是linux page cache采用的方式, 我觉得也是最通用的一种方式, 在write-back 策略里面, 写入操作是直接更新到cache 里面的,  后端存储不会马上更新. 然后这些需要更新的page 会被标记成dirty, 放到一个dirty list 里面, 然后周期性的有pdflush(2.6.32 以后就是flush per device)进行将cache 里面的数据刷回后端存储,  然后这些page 就不在标记dirty.&lt;/p&gt;

&lt;p&gt;write-back 方案可以看成是write-through 的一个优化版本,  其实就是通过lazy write 一次写入比较大的数据来提高这个写入的性能, 但是带来的问题可能就是缓存中的数据有可能丢失了. 所以在linux 里面可以通过fsync 来强制某一次的写入写到磁盘, 也就是从write-back 变成write-through了&lt;/p&gt;

</description>
        <pubDate>Wed, 14 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/09/14/cache-policy/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/09/14/cache-policy/</guid>
      </item>
    
      <item>
        <title>talk about kernel process descriptor</title>
        <description>&lt;h3 id=&quot;taskstruct-threadstruct-tssstruct-threadinfo-&quot;&gt;task_struct, thread_struct, tss_struct, thread_info 他们之间的关系是什么&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;task_struct&lt;/p&gt;

    &lt;p&gt;就是一个process descriptor&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task_struct&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;	&lt;span class=&quot;cm&quot;&gt;/* -1 unrunnable, 0 runnable, &amp;gt;0 stopped */&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/*
   * 这个stack 里面存的内容就是内核空间的栈的内容
   * 内核空间的栈的内容包含两个部分
   * 1. thread_info
   * 2. kernel 里面的内核栈空间的内容
   *
   * 这个stack 的初始化是在fork.c:dup_task_struct:alloc_thread_info() 里面的
   * struct thread_info *ti;
   * tsk-&amp;gt;stack = ti;
   * 可以看出这个stack 指向的是一个thread_info 结构体
   *
   *  struct thread_info {
   *   struct task_struct	*task;		
   *   ...
   *   }
   *
   * task_thread_info(p)-&amp;gt;task = p;
   * 从这里又可以看出 这个thread_info-&amp;gt;task 又指向了这个task_struct
   * 也就是这两个结构体task_struct, thread_info是互相指向的
   * 为什么要这样做呢?
   * 因为cpu 里面的esp寄存器指向的就是kernel stack里面的内容, 然后通过kernel
   * stack 就可以获得thread_info 这个结构体(因为kernel stack 和 thread_info
   * 是保存在连续的8k 的空间上的),
   * 然后根据thread_info-&amp;gt;task就可以找到当前正在运行task_struct 了.
   */&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/* CPU-specific state of this task */&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/*
   * thread_struct 里面保留了大部分的cpu 寄存器的信息
   * 那么在context switch 的时候这个process 的cpu register
   * 等信息会被保存在这个thread_struct 里面
   */&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread_struct&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;tss_struct&lt;/p&gt;

    &lt;p&gt;是定义的Task State Segment, 也就是 TSS 段, 这个段的主要用在就是存 process context switch 上下文切换的时候的hardware context. 这个 tss_struct 保存在GDT(global descriptor table) 里面. 这个结构并不在task_struct 里面.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tss_struct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;per_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init_tss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;从上面可以看出tss_struct 是每一个cpu 有一个这样的结构体&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;thread_struct&lt;/p&gt;

    &lt;p&gt;这个是 process context switch 的时候, 将 hardware context 主要保留在的地方, 每一个线程都包含一份 thread_struct. 当然还有一部分包含在 kernel mode stack 里面, 比如(eax, ebx 等等)&lt;/p&gt;

    &lt;p&gt;这里tss_struct 和 thread_struct 的关系是task_struct-&amp;gt;thread_struct 主要保留的是 context switch 后, 不在cpu中间运行的process的内容, 然后tss_struct 里面的内容是不是就是直接从task_struct-&amp;gt;thread_struct 里面的内容加载进来的呢? 确实是这样的&lt;/p&gt;

    &lt;p&gt;这里也可以看出在做process switch 的时候, 是先获得了要运行的下一个process 的task_struct, 然后从task_struct 里面的thread_struct 加载到GDT里面,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;thread_info&lt;/p&gt;

    &lt;p&gt;thread_info 用来保存一些需要知道的固定变量, 类似写程序里面的全局变量&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;kernel mode stack&lt;/p&gt;

    &lt;p&gt;kernel mode stack 就是跟我们写程序的user mode stack 一样, 存的是一些临时变量, 和thread_info 相比, thread_info 更类似存全局变量&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kernel-process--taskstruct-&quot;&gt;kernel 如何获得当前运行process 的 task_struct 的&lt;/h3&gt;

&lt;p&gt;这个就主要通过当前运行的process task_struct 里面的stack 来获得.&lt;/p&gt;

&lt;p&gt;在stack 里面是这样的一个结构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/1fAYzia.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出这个stack 底下是一个thread_info 的结构体, 然后stack 的底部是在最上面, 这一部分就是kernel stack 的内容, esp 指针指向着当前的kernel stack 的头部. 那么这个时候想要获得当前运行process 的task_struct 就比较方便. 因为&lt;/p&gt;

&lt;p&gt;The close association between the thread_info structure and the Kernel Mode stack just described offers a key benefit in terms of efficiency: the kernel can easily obtain the address of the thread_info structure of the process currently running on a CPU from the value of the esp register.&lt;/p&gt;

&lt;p&gt;就是说可以通过esp 很容易获得thread_info 这个结构体的位置, 然后thread_info-&amp;gt;task 里面又保留了这个process descriptor 的指针就可以获得对应的task_struct 的位置了&lt;/p&gt;

&lt;h3 id=&quot;stack--threadinfo-page-&quot;&gt;为什么要把stack 和 thread_info 放在一个page 里面&lt;/h3&gt;

&lt;p&gt;Another advantage of storing the process descriptor with the stack emerges on multi-processor systems: the correct current process for each hardware processor can be derived just by checking the stack, as shown previously.&lt;/p&gt;

&lt;p&gt;Earlier versions of Linux did not store the kernel stack and the process descriptor together.&lt;/p&gt;

&lt;p&gt;因为kernel stack 上面永远放着esp指针, 那么因为esp 肯定在这个page里面, 通过取模很容易就可以获得当前这个thread_info 所在的地址, 通过thread_info 就可以很容易获得task_struct 的地址了&lt;/p&gt;

</description>
        <pubDate>Mon, 29 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/08/29/process-descriptor/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/08/29/process-descriptor/</guid>
      </item>
    
      <item>
        <title>how to read a book</title>
        <description>&lt;h3 id=&quot;how-to-read-a-book&quot;&gt;How to read a book&lt;/h3&gt;

&lt;p&gt;这是university of Michigan 大学的一个教授写的如何看一本书, 当然也可以用来看论文, 看资料等等, 但是这种方法肯定不适合用来看小说. 我觉得里面讲的一些方法其实我有在做, 有些方法我没做到. 下面介绍一下里面的方法, 当然这里的读书指的是非常功利的读书, 不是读小说. &lt;a href=&quot;http://pne.people.si.umich.edu/PDF/howtoread.pdf&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;整体&lt;/h4&gt;

&lt;p&gt;读书的目的是为了学会, 了解书上讲的知识. 并且尽可能的花更少的时间去达到这个目标.&lt;/p&gt;

&lt;p&gt;整体的方法就是带着问题来读书, 所以你绝对不能从头读到尾的方式读书, 应该是跳来跳去, 按照自己的目的去发现, 去理解, 去记住那些你想要的知识, 这样就可以在尽可能短的时候获得你想要的知识点.&lt;/p&gt;

&lt;p&gt;我自己的经验就是比如我读csapp的时候, 刚开始读的比较吃力就是因为从头开始往后读, 因为一开始就将cpu的体系结构, 其实看起来很懵逼. 但是从后往前度, 从Application =&amp;gt; os =&amp;gt; Architecture 就顺很多的. 比如读ulk 的时候, 最早也是按照书上的章节读, 后来发现讲内存, 下一章又开始讲锁, cpu调度, 进程等等发现了解的也不是深刻. 后来使用的方法就是把内存相关的章节一起看了, 比如2, 8, 9 然后对内存有了解了, 再去看cpu 相关, 再去看设备相关的, 自我感觉还是比之前的方法好&lt;/p&gt;

&lt;p&gt;那么如何跳来跳去的看书呢, 肯定不是一开始就可以跳来跳去的看的.&lt;/p&gt;

&lt;h5 id=&quot;section-1&quot;&gt;具体做法&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;通读全文&lt;/p&gt;

    &lt;p&gt;整体把握重点比深入细节要来的重要, 因为无论你看的多认真, 很多时候细节还是需要回头再看的. 但是你知道整个书的主要的问题, 很多细节当需要的时候再去差就行. 比如看ulk 的内存相关的时候, 你知道在kernel 内部, 内存申请的方法有3种,kmalloc, slab, vmalloc. 具体有问题需要你排查的时候, 你再去深入去看slab细节, 这个时候你会记得更清楚&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;决定你打算花多长时间在这本书上&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;带着问题去读书&lt;/p&gt;

    &lt;p&gt;带着问题去看书会让你对想要了解的问题记得更加清楚&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;多个别人交流&lt;/p&gt;

    &lt;p&gt;不要一个人看,  多和别人交流.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;了解这个书的作者或者这个组织&lt;/p&gt;

    &lt;p&gt;这点其实我一直没做到. 作者和正常人一样, 她的观点一定是形成一定是受的教育, 他的工作, 她的以前生活, 他的经历所形成的. 具体的做技术书籍就是他之前做过什么, 主要解决哪些领域的问题等等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;了解知识背景&lt;/p&gt;

    &lt;p&gt;我觉的这个和了解作者类似, 就跟看文献的时候一定要看背景介绍一样, 不然不知道要解决什么问题就开始看会懵逼&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;好书读三遍&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;这个是重点, 那就写三遍. 这个也是我自己的切身体会&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;好书读三遍&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;好书读三遍&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;好书读三遍&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;整体快速通读.&lt;/p&gt;

        &lt;p&gt;这个时间占用读整个文章的10%,  快读了解这个文章的主要内容. 通读重要的标题, 段落. 对应于我们经常的读文献, 我喜欢的做法就是看第一节Introduce, 第二节整体实现, 然后直接看最后一节conclusion 这样就大概知道这个文献讲什么&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;细读.&lt;/p&gt;

        &lt;p&gt;在第一遍的基础上细读, 这时候你再去细读文章, 因为有了整体的脉络, 不过看到具体结构设计的时候很懵逼, 这一遍就是要掌握这文献的主要内容了&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;复读并且记笔记&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;记笔记和划重点还是不一样的&lt;/strong&gt;, &lt;strong&gt;记笔记和划重点是不一样的&lt;/strong&gt;,&lt;strong&gt;记笔记和划重点是不一样的&lt;/strong&gt;.&lt;/p&gt;

        &lt;p&gt;因为记笔记使用你自己的语言结合你自己已知的内容框架把作者的观点吸收到你的框架里面. 所以要尽可能用你自己的语言. 直接把作者写的内容拷贝粘贴过来肯定是效果不好的. 一般来说100页的书, 这个时候之下来只需要1-3页的内容. 太多了也不好&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;时间&lt;/p&gt;

    &lt;p&gt;一般来说我们的注意力在1个小时以后就会不集中, 因此连续看书3个小时的效果是不如3个分开的一小时来得好. 并且读书消化也是需要时间, 分开时间会在下一次开始的时候逼迫自己去想上次的1个小时读的内容, 加深印象&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关注重点内容&lt;/p&gt;

    &lt;p&gt;一般来说目录表, 图, 图表, 标题包含更多的重要内容. 一般来说一个文献都是漏斗结构, 也就是我们常说的总-分-总结构, 因此开始和结尾总会包含观点, 中间的一般是具体的验证, 实现过程&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;多做标记, 但不要标记太多&lt;/p&gt;

    &lt;p&gt;我现在看pdf 一般用skim, 然后里面的高亮标记功能还是很不错的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;用各种方式回顾你学到的内容&lt;/p&gt;

    &lt;p&gt;因为读, 写, 说, 听, 想象是脑海中的各种部分. 尽可能使用各种方法回顾你学到的内容&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不断练习, 不断练习, 不断练习…&lt;/p&gt;

</description>
        <pubDate>Mon, 15 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/08/15/how-to-read/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/08/15/how-to-read/</guid>
      </item>
    
      <item>
        <title>page reclaim wartermark</title>
        <description>&lt;p&gt;首先我们知道操作系统的物理页主要被两部分使用, 一部分是实际使用的物理内存, 也叫anonymous page, 另一部分是 page cache. 同时我们还有 swap 区, 用来在内存不够的时候将 anonymous page 里面的页面置换到 swap 上.&lt;/p&gt;

&lt;p&gt;那么kernel 什么时候认为内存是不够的, 需要做 page reclaim呢?&lt;/p&gt;

&lt;p&gt;我们通过 cat /proc/zoneinfo 可以看到这样的信息&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Node 1, zone   Normal
  pages free     19387934
        min      11289
        low      14111
        high     16933
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里这几个 min, low, high 又是什么意思?&lt;/p&gt;

&lt;p&gt;首先需要了解的一个概念是The Pool of Reserved Page Frames. 意思是每一个 zone 都需要保留一些 page frame. 为什么每一个 zone 都需要保留一些 page frames 呢? 我们知道操作系统在内存不够的时候, 可以直接进行 direct page reclaim, 回收部分的page frame, 那为什么还需要保留一些 page frames 呢?&lt;/p&gt;

&lt;p&gt;因为在 kernel 内部有一些操作是不允许切换的, 比如在处理一个中断的时候或者执行代码的某一临界区域. 在这个时候kernel 的内存申请操作必须是 atomic 的(这个在内存申请的 flag 里面有GFP_ATOMIC). 为了满足这个 atomic 内存申请的需求, 因此我们必须在每个 zone 保留一定数目的 page. 所以低于这个数目的 free pages frame 以后, kernel 就认为自己处于 low_memory 状态了. 我们管这个数叫 min_free_bytes. 那么这个数是怎么算的?&lt;/p&gt;

&lt;p&gt;每一个 zone 的初始化的时候都需要执行&lt;/p&gt;

&lt;p&gt;mm/wmark_alloc:init_per_zone_wmark_min()&lt;/p&gt;

&lt;p&gt;在init_per_zone_wmark_min 里面主要初始化设置了 min_free_kbytes&lt;/p&gt;

&lt;p&gt;The amount of the reserved memory (in kilobytes) is stored in the min_free_kbytes variable. Its initial value is set during kernel initialization and depends on the amount of physical memory that is directly mapped in the kernel’s fourth gigabyte of linear addresses—that is, it depends on the number of page frames included in the ZONE_DMA and ZONE_NORMAL memory zones:&lt;/p&gt;

&lt;p&gt;min_free_kbytes = int_sqrt(16 × directly mapped memory)     (kilobytes)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 这里 lowmem_kbytes 就是映射在操作系统的实际物理内存上面的 physical memory 的 page 数, 其实就是 ZONE_DMA + ZONE_NORMAL 的 page
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowmem_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nr_free_buffer_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wmark_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;min_free_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int_sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowmem_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;However, initially min_free_kbytes cannot be lower than 128 and greater than 65,536.&lt;/p&gt;

&lt;p&gt;这个min_free_kbytes 最大64M 最小128k,  所以一般 kernel 里面为 atomic 操作留的 page 数有几十 M. 这个 min_free_kbytes 是对于全部的 zone 而言,  因为希望满足 kernel 的 atomic 类型的内存申请操作肯定是对于全部的物理内存而言的&lt;/p&gt;

&lt;p&gt;有了这个概念以后, 我们就知道每一个 zone 里面的 wmark_min, wmark_low, wmark_high 这些 watermark 数值是什么意思了&lt;/p&gt;

&lt;p&gt;然后接下来设置wmark_min, wmark_low, wmark_high 这几个watermark 主要在setup_per_zone_wmarks() 这个函数里面&lt;/p&gt;

&lt;p&gt;那么具体的计算 wmark_min, wmark_low, wmark_high 过程&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pages_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_free_kbytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PAGE_SHIFT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* Calculate total number of !ZONE_HIGHMEM pages */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;for_each_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_highmem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;present_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;for_each_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;spin_lock_irqsave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pages_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;present_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;do_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowmem_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_MIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_LOW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_wmark_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watermark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WMARK_HIGH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_wmark_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出这里每一个 zone 的 wmark_min 的根据自己的内存大小比例分配对应百分比的 min_free_kbytes. 也就是所有 zone 的 wmark_min 加起来就是这个 min_free_kbytes&lt;/p&gt;

&lt;p&gt;wmark_low = 5/4 * wmark_min&lt;/p&gt;

&lt;p&gt;wmark_high = 3/2 * wmark_min&lt;/p&gt;

&lt;p&gt;每一个zone 还有一个reserve page, 用来限制在 high level zone 满足不了请求的情况下, low level zone 自己需要保留的page数.具体的初始化在&lt;/p&gt;

&lt;p&gt;setup_per_zone_lowmem_reserve()&lt;/p&gt;

&lt;p&gt;那么这里来理解一下设置这些wmark_min, wmark_low, wmark_high 的目的了.&lt;/p&gt;

&lt;p&gt;这里min_free_kbytes 主要是kernel 为了留给&lt;code class=&quot;highlighter-rouge&quot;&gt;__GFP_ATOMIC&lt;/code&gt; 类型的内存申请操作, 因为在操作系统里面有一些内存申请操作是不允许切换的,也就是不能在这个时候把当前这个 cpu 交给别的进程, 比如handling an interrupt or executing code inside an critical region. 那么这时候肯定也是希望kernel 内存申请操作应该是非阻塞的. 因此希望系统至少能够留下 min_free_kbytes 的空间用户&lt;code class=&quot;highlighter-rouge&quot;&gt;__GFP_ATOMIC&lt;/code&gt; 类型的内存申请操作.&lt;/p&gt;

&lt;p&gt;wmark_min 是说当前的这个空闲的 page frame 已经极地了, 当有内存申请操作的时候, 如果是非内核的内存申请操作, 那么就返回失败, 如果申请操作来自kernel, 比如调用的是 __alloc_pages_high_priority() 的时候, 就可以返回内存&lt;/p&gt;

&lt;p&gt;wmark_low 是用来唤醒 kswap 进程, 当我们某一个__alloc_pages 的时候发现 free page fram 小于 wmark_low 的时候, 就会唤醒这个kswapd 进程, 进行 page reclaim&lt;/p&gt;

&lt;p&gt;wmark_high 是当 kswapd 这个进程进行 page reclaim 了以后, 什么时候停止的标志, 只有当 page frame 大于这个 pagh_high 的时候, kswapd 进程才会停止, 继续sleep
&lt;img src=&quot;http://i.imgur.com/iAj7rWj.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以其实wmark_min, wmark_low, wmark_high 都是为了kernel 能够允许atomic 类型的申请操作成功服务的&lt;/p&gt;

&lt;p&gt;注: 代码都是基于 linux2.6.32版本&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/06/02/page-reclaim/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/06/02/page-reclaim/</guid>
      </item>
    
      <item>
        <title>swappiness 是否需要设置成0</title>
        <description>&lt;p&gt;在我们的线上机器里面, 为了避免内存对性能的影响, 经常会将 swappiness 设置成0.  这个 swappiness 具体含义是什么? 这里就能够完全避免 swap 么? 这样做好么?&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;结论:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;swappiness 的具体含义是当物理内存不够的时候, 有两种选项&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;将一部分 anonymous page 置换到 swap区&lt;/li&gt;
  &lt;li&gt;将 page cache 里面的数据刷回到磁盘, 或者直接清理掉&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这两种选项里面, 置换到swap 的权重, 但不是 swap 和 page cache 的比例, 比如 swappiness = 100 意思是swappiness 和 page cache 的比例是相同的. swappiness = 20 就是 swappiness 和 page cache 比例是1:9, 当然具体 kernle 还做的更细. 具体的计算公式就是,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;anon_prio = sc-&amp;gt;swappiness;
file_prio = 200 - sc-&amp;gt;swappiness;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;这样不能避免swap, 当内存不够的时候还是会 swap. 需要执行 swapoff -a 才是完全关闭 swap 的方法&lt;/li&gt;
  &lt;li&gt;不建议线上将 swappiness 设置成0, 因为kernel 对于该 reclaim 的页还是做了很多工作, 选择的是最不活跃的页, 而且 kernel 还会比较每一次 reclaim 的效果.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section-1&quot;&gt;具体分析&lt;/h4&gt;

&lt;p&gt;这个问题主要涉及到操作系统是如何做 page reclaim 的&lt;/p&gt;

&lt;p&gt;首先我们知道操作系统的物理页主要被两部分使用, 一部分是实际使用的物理内存, 也叫anonymous page, 另一部分是 page cache. 同时我们还有 swap 区, 用来在内存不够的时候将 anonymous page 里面的页面置换到 swap 上.&lt;/p&gt;

&lt;p&gt;那么在操作系统内存不够(下一篇文章介绍, 什么时候是内存不够的时候)的时候, 有两个选择. 一个是将 page cache里面的脏页刷回到磁盘, 将干净的页直接丢弃掉. 一个是将实际使用的物理内存里面的不常用的页刷回到 swap 区. 那么操作系统怎么做选择的?&lt;/p&gt;

&lt;p&gt;这里最重要的需要判断是否需要swap 的在 get_scan_ratio 这个函数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 这里可以看到如果把swap 给关闭了, 那么确实就不会进行swap 这个操作了
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;所以这里想把&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;完全关闭的方法应该是&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;swapoff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;  
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;may_swap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nr_swap_pages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;noswap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;get_scan_ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;那么在这个get_scan_radio 里面, 就是计算这次 swap 和 page cache 的比例的时候了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;cm&quot;&gt;/*
 * 首先获得anon 页的个数 和 page cache页的个数
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anon&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_nr_lru_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LRU_ACTIVE_ANON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;zone_nr_lru_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LRU_INACTIVE_ANON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_nr_lru_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LRU_ACTIVE_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;zone_nr_lru_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LRU_INACTIVE_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scanning_global_lru&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_page_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NR_FREE_PAGES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/* If we have very few page cache pages,
     force-scan anon pages. */&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/*
   * 这里就是如果我们的page cache page 和我们的 free
   * page数小于high_wmark_pages, 也就是3/2 的min_free_pages 的时候, 那么这个时候即使swapiness是0
   * 也是强制的让这次都走这个swapiness, 也就是swapiness 被设置成100
   *
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlikely&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;free&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high_wmark_pages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.....&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
 * With swappiness at 100, anonymous and file have the same priority.
 * This scanning priority is essentially the inverse of IO cost.
 * 这里可以看到 swappiness 设成100的时候, 意思是从匿名页释放 page 和从 page
 * cache 里面释放 page 是相同的比例 
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anon_prio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swappiness&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file_prio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swappiness&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
 * 这里从获得了 anon 和 file 的比例以后继续的优化, 根据的是历史的 scanned 和
 * rotated page 的比例, 来计算这些 page 是否有效
 *
 * 这里比如我再 anon 区域扫描了100个 page, 然后 rotated 就是从 swap
 * 里面又置换到内存里面50 个 page, 另外我在 page cache 区域里面扫描了100个 page,
 * 又置换了10个 page, 这说明在 anon 区域里面的内容是比较经常访问的,
 * 换出去了以后又要换回内存, 所以应该尽量不要让 anno 区域里面的 page 换出 
 */&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
 *   80 * 100 / 50 = 160
 *   120 * 100 / 10 = 1200
 *   percent[0] = 100 * 160 / 1360 = 11
 *   percent[1] = 89
 * 
 *   如果没有经过这一步, percent 应该是
 *   percent[0] = 80 / (80 + 120)  * 100 = 40
 *   percent[1] = 60
 * 
 *   这样可以看出这样就再一次减少了从 anon 区域 reclaim 的比例, 因为 anan里面的 page 是更经常访问的 
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anon_prio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reclaim_stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recent_scanned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reclaim_stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recent_rotated&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_prio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reclaim_stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recent_scanned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reclaim_stat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recent_rotated&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* Normalize to percentages */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 01 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/06/01/swappiness-zero/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/06/01/swappiness-zero/</guid>
      </item>
    
      <item>
        <title>xfs kmalloc failure problem</title>
        <description>&lt;p&gt;记录一次线上实体机的xfs kmem_alloc 操作一直失败排查&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;问题现象&lt;/h3&gt;

&lt;p&gt;线上有些实体机dmesg出现xfs 报错&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Apr 29 21:54:31 w-openstack86 kernel: XFS: possible memory allocation deadlock &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;kmem_alloc &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;mode:0x250&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Apr 29 21:54:33 w-openstack86 kernel: XFS: possible memory allocation deadlock &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;kmem_alloc &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;mode:0x250&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Apr 29 21:54:34 w-openstack86 kernel: INFO: task qemu-system-x86:6902 blocked &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;more than 120 seconds.
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;s2&quot;&gt;&quot;echo 0 &amp;gt; /proc/sys/kernel/hung_task_timeout_secs&quot;&lt;/span&gt; disables this message.
Apr 29 21:54:34 w-openstack86 kernel: qemu-system-x86 D ffff88105065e800     0  6902      1 0x00000080
Apr 29 21:54:34 w-openstack86 kernel: ffff880155c63778 0000000000000086 ffff88099719d080 ffff880155c63fd8
Apr 29 21:54:34 w-openstack86 kernel: ffff880155c63fd8 ffff880155c63fd8 ffff88099719d080 ffff88099719d080
Apr 29 21:54:34 w-openstack86 kernel: ffff88081018de10 ffffffffffffffff ffff88081018de18 ffff88105065e800
Apr 29 21:54:34 w-openstack86 kernel: Call Trace:
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff8163a879&amp;gt;] schedule+0x29/0x70
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff8163c235&amp;gt;] rwsem_down_read_failed+0xf5/0x170
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa0256a30&amp;gt;] ? xfs_ilock_data_map_shared+0x30/0x40 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff81301764&amp;gt;] call_rwsem_down_read_failed+0x14/0x30
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff81639a90&amp;gt;] ? down_read+0x20/0x30
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa02569bc&amp;gt;] xfs_ilock+0xdc/0x120 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa0256a30&amp;gt;] xfs_ilock_data_map_shared+0x30/0x40 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f4f4&amp;gt;] __xfs_get_blocks+0x94/0x4b0 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff810654f2&amp;gt;] ? get_user_pages_fast+0x122/0x1a0
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f944&amp;gt;] xfs_get_blocks_direct+0x14/0x20 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff8121d704&amp;gt;] do_blockdev_direct_IO+0x13f4/0x2620
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff8121e985&amp;gt;] __blockdev_direct_IO+0x55/0x60
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f210&amp;gt;] ? xfs_finish_ioend_sync+0x30/0x30 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023e5ca&amp;gt;] xfs_vm_direct_IO+0xda/0x180 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f930&amp;gt;] ? xfs_get_blocks+0x20/0x20 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa023f210&amp;gt;] ? xfs_finish_ioend_sync+0x30/0x30 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff8116afed&amp;gt;] generic_file_direct_write+0xcd/0x190
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa027f1fc&amp;gt;] xfs_file_dio_aio_write+0x1f3/0x232 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa024bd2d&amp;gt;] xfs_file_aio_write+0x13d/0x150 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff811ddde9&amp;gt;] do_sync_readv_writev+0x79/0xd0
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff811df3be&amp;gt;] do_readv_writev+0xce/0x260
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffffa024bbf0&amp;gt;] ? xfs_file_buffered_aio_write+0x260/0x260 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xfs]
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff811ddca0&amp;gt;] ? do_sync_read+0xd0/0xd0
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff810e506e&amp;gt;] ? do_futex+0xfe/0x5b0
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff811df5e5&amp;gt;] vfs_writev+0x35/0x60
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff811df9e2&amp;gt;] SyS_pwritev+0xc2/0xf0
Apr 29 21:54:34 w-openstack86 kernel: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;ffffffff816458c9&amp;gt;] system_call_fastpath+0x16/0x1b
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;进而导致虚拟机因为文件系统的内存申请操作出现了问题, 导致这个虚拟机挂掉&lt;/p&gt;

&lt;p&gt;解决办法:&lt;/p&gt;

&lt;p&gt;sync &amp;amp;&amp;amp; echo 3 &amp;gt; /proc/sys/vm/drop_caches&lt;/p&gt;

&lt;p&gt;将page cache 里面的内容清空, 那么就不再报错. 但是为什么简单的清空page cache 就可以解决这个问题, 如果系统被page cache 占用着难道不应该申请内存操作的时候将一部分page cache 里面的内存刷回, 然后让出部分空闲空间么?&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;看了一下代码, 出现这个报错在xfs module里面, 这个错误是在kmalloc 失败以后就会报出来, 并且会重试100次, 如果100 次以后还是失败, 就直接return error. 那么为什么kmalloc 会失败呢?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;kmem_alloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xfs_km_flags_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gfp_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lflags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmem_flags_convert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lflags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KM_MAYFAIL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KM_NOSLEEP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;retries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;xfs_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;possible memory allocation deadlock in %s (mode:0x%x)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;__func__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lflags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;congestion_wait&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BLK_RW_ASYNC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HZ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里首先我们必须知道如果一个操作kmalloc() 是向slab allocator 申请具体的小块的内存, 而slab allocator 是想buddy system 通过&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 去申请连续的内存. 那么肯定就是在&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 申请内存的时候失败了, 那为什么进行&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 操作的时候会失败呢? 即使实际物理内存里面还有page cache页以及swap 空间还没占满&lt;/p&gt;

&lt;p&gt;从出现问题的机器上面我们可以看到, 机器的状态大概是这个样子&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;chenzongzhi@w-openstack86 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;free -m
              total        used        free      shared  buff/cache   available
Mem:          64272       26298        4379         129       33595       37051
Swap:         32255           0       32255
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里我们同时看一下机器的内存碎片状态&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;这里并不是现场的机器, 只是另一台线上内存用的差不多的机器 
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;chenzongzhi@w-openstack81 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;cat /proc/buddyinfo
Node 0, zone      DMA      0      0      0      1      2      1      1      0      1      1      3
Node 0, zone    DMA32   2983   2230   1037    290    121     63     47     61     16      0      0
Node 0, zone   Normal  13707   1126    285    268    291    160     64     21     11      0      0
Node 1, zone   Normal  10678   5041   1167    705    316    158     61     22      0      0      0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到这里比较大块的连续的page 是基本没有的. 因为在xfs 的申请内存操作里面我们看到有这种连续的大块的内存申请的操作的请求,  比如:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;6000:   map &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; kmem_alloc&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;subnex &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; sizeof&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;map&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, KM_MAYFAIL | KM_NOFS&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;因此比较大的可能是线上虽然有少量的空闲内存, 但是这些内存非常的碎片, 因此只要有一个稍微大的的连续内存的请求都无法满足. 但是为什么不使用page cache呢?&lt;/p&gt;

&lt;p&gt;到这里. 我们可以看到整个系统的内存基本全部被使用, 有少量的空闲. 但是这里面包含了大量的page cache. 理论上page cache 里面只会包含几M的需要刷回磁盘的内容, 大量的page cache 只是为了加快读, 里面的内容应该可以随时清空掉. 所以在kmalloc申请内存的时候应该能够把page cache 里面的内容清空, 然后给kernel 留出空闲的连续的大内存空间才是. 那么为什么这次申请内存操作&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt;的时候不把page cache 里面的内容清空一部分, 然后给这次&lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 预留出来空间呢?&lt;/p&gt;

&lt;p&gt;这里xfs 的申请内存操作因为是文件系统的申请内存操作, 所以一般带上GFP_NOFS 这个参数, 这个参数的意思是&lt;/p&gt;

&lt;p&gt;GFP_NOFS&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;These flags function like GFP_KERNEL, but they add restrictions on what the kernel can do to satisfy the request. A GFP_NOFS allocation is not allowed to perform any filesystem calls, while GFP_NOIO disallows the initiation of any I/O at all. They are used primarily in the filesystem and virtual memory code where an allocation may be allowed to sleep, but recursive filesystem calls would be a bad idea.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;也就是说如果带上这个GFP_NOFS的flag, 那么本次 &lt;code class=&quot;highlighter-rouge&quot;&gt;__alloc_pages()&lt;/code&gt; 是不允许有任何的filesystem calls的操作的, 那么如果物理内存不够了, 也就是不能触发这个page_reclaim 的操作. 具体的实现是在page reclaim 的 do_try_to_free_pages 里面shrink_page_list 的时候会判断这次的scan_control 里面有没有这个 __GFP_FS flag, 如果是没有GFP_FS flag, 就不会就行这个page_reclaim&lt;/p&gt;

&lt;p&gt;为什么要这样, 因为如果在文件系统申请内存的时候, 你又触发了一次文件系统相关的操作, 比如把page cache 里面的内容刷会到文件, 那么刷会到文件这个操作必然又会有内存申请相关的操作, 这样就进入是循环了. kernel 为了避免这样的死循环尝试, 所以在文件系统相关的内存申请就不允许有任何filesystem calls. 也就是这个原因导致kernel 本身kmalloc 一直失败&lt;/p&gt;

&lt;p&gt;那么接下来 sync &amp;amp;&amp;amp; echo 3 &amp;gt; /proc/sys/vm/drop_caches 操作为什么能够成功, 并且后续就不会有报错了呢?&lt;/p&gt;

&lt;p&gt;因为drop_caches 这个操作属于外部操作, 不属于文件系统本身的操作, 因此没有GFP_NOFS这个flag, 因此可以很轻松的就把page cache 里面的内容清空, 让Kernel 有足够多的连续的大内存. 线上自然就不报错了&lt;/p&gt;

</description>
        <pubDate>Fri, 27 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/05/27/xfs-kmalloc-failure/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/05/27/xfs-kmalloc-failure/</guid>
      </item>
    
      <item>
        <title>我对存储的一些看法</title>
        <description>&lt;p&gt;其实计算机主要分成两个部分 计算 + 存储, 存储应该是计算的基石&lt;/p&gt;

&lt;p&gt;那么存储其实又主要分成两个部分 在线存储 + 离线存储&lt;/p&gt;

&lt;p&gt;离线存储的需求很统一, 就是离线数据分析, 产生报表等等. 也因为这统一的需求, 所以目前hdfs 为首的离线存储基本统一了离线存储这个平台. 离线存储最重要的就是吞吐, 以及资源的利用率. 对性能, 可靠性的要求其实并不多. (所以这也是为什么java系在离线存储这块基本一统的原因, java提供的大量的基础库, 包等等. 而离线存储又对性能, 可靠性没有比较高的要求, 因此java GC等问题也不明显)&lt;/p&gt;

&lt;p&gt;所以我们可以看到虽然现在离线的分析工具一直在变, 有hadoop, spark, storm 等等, 但是离线的存储基本都没有变化. 还是hdfs 一统这一套. 所以我认为未来离线存储这块不会有太大的变化&lt;/p&gt;

&lt;p&gt;在线存储&lt;/p&gt;

&lt;p&gt;指的是直接面向用户请求的存储类型. 由于用户请求的多样性, 因此在线存储通常需要满足各种不同场景的需求.&lt;/p&gt;

&lt;p&gt;比如用户系统存储是提供对象的服务, 能够直接通过HTTP接口来访问, 那么自然就诞生了对象存储这样的服务&lt;/p&gt;

&lt;p&gt;比如用户希望所存储的数据是关系性数据库的模型, 能够以SQL 的形式来访问, 那么其实就是mysql, 或者现在比较火热的NewSql&lt;/p&gt;

&lt;p&gt;比如用户只希望访问key, value的形式, 那么我们就可以用最简单的kv接口, 那么就有Nosql, bada, cassandra 等等就提供这样的服务&lt;/p&gt;

&lt;p&gt;当然也有多数据结构的请求, hash, list 等等就有了redis, 有POSIX文件系统接口了请求, 那么就有了CephFs. 有了希望提供跟磁盘一样的iSCSI 这样接口的块设备的需求, 就有了块存储, 就是ceph.&lt;/p&gt;

&lt;p&gt;从上面可以看到和离线存储对比, 在线存储的需求更加的复杂, 从接口类型, 从对访问延期的需求, 比如对于kv的接口, 我们一般希望是2ms左右, 那么对于对象存储的接口我们一般在10ms~20ms. 对于SQL, 我们的容忍度可能更高一些, 可以允许有100 ms. 处理延迟的需求, 我们还会有数据可靠性的不同, 比如一般在SQL 里面我们一般需要做到强一致. 但是在kv接口里面我们一般只需要做到最终一致性即可. 同样对于资源的利用也是不一样, 如果存储的是稍微偏冷的数据, 一定是EC编码, 然后存在大的机械盘. 对于线上比较热的数据, 延迟要求比较高. 一定是3副本, 存在SSD盘上&lt;/p&gt;

&lt;p&gt;从上面可以看到在线存储的需求多样性, 并且对服务的可靠性要求各种不一样, 因此我们很难看到有一个在线存储能够统一满足所有的需求. 这也是为什么现在没有一个开源的在线存储服务能够像hdfs 那样的使用率. 因此一定是在不同的场景下面有不同的存储的解决方案&lt;/p&gt;

&lt;p&gt;可以看到Facebook infrastructure stack 里面就包含的各种的在线存储需求&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/LpZw633.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如里面包含了热的大对象存储Haystack, 一般热的大对象存储f4, 图数据库Tao. key-value 存储memcached 集群等等&lt;/p&gt;

&lt;p&gt;同样google 也会有不同的在线存储产品&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/aUTxFTN.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对应于Google 有MegaStore, Spanner 用于线上的SQL 类型的在线存储, BigTable 用于类似稀疏map 的key-value存储等等&lt;/p&gt;

&lt;p&gt;个人认为对于在线存储还是比较适合C++来做这一套东西, 因为比较在线存储一般对性能, 可靠性, 延迟的要求比较高.&lt;/p&gt;

&lt;p&gt;那么这些不同的存储一般都怎么实现呢?, 很多在线存储比如对象存储的实现一般都是基于底下的key-value进行封装来实现对象存储的接口. ceph 就是这方面这个做法的极致.&lt;/p&gt;

&lt;p&gt;ceph 底下的rados 本质是一个对象存储, 这里的对象存储跟s3 的对象存储还不一样, 只是提供了存储以为key 对应的value 是对象的形式.
然后基于上层基于librados 封装了librbd 就实现了块设备的协议, 那么就是一个块存储. 基于librados 实现了Rados Gateway 提供了s3 的对象存储的协议就封装成s3对象存储. 基于librados 实现了POSIX 文件系统的接口, 就封装成了分布式文件系统Ceph FS. (不过我认为ceph 底下的rados实现的还不够纯粹, 因为rados对应的value 是类似于一个对象文件. 比如在基于librados 实现librbd的时候很多对象属性的一些方法是用不上的)
&lt;img src=&quot;http://i.imgur.com/grsvIND.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同样google 的F1 是基于spanner 的key-value 接口实现了SQL了接口. 就封装成了NewSql&lt;/p&gt;

&lt;p&gt;因此其实我们也可以这么说对于这么多接口的实现, 其实后续都会转换成基于key-value 接口实现另一种接口的形式, 因为key-value 接口足够简单, 有了稳定的key-value 存储, 只需要在上层提供不同接口转换成key-value 接口的实现即可. 当然不同的接口实现难度还是不太一样, 比如实现SQL接口, POSIX文件系统接口, 图数据库肯定要比实现一个对象存储的接口要容易很多&lt;/p&gt;

&lt;p&gt;未来我们应该也在朝这个方向做吧&lt;/p&gt;

</description>
        <pubDate>Thu, 26 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/05/26/my-opnion-of-storage/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/05/26/my-opnion-of-storage/</guid>
      </item>
    
      <item>
        <title>pika introduction</title>
        <description>&lt;p&gt;今天主要向大家介绍一下pika&lt;/p&gt;

&lt;p&gt;pika 是360 DBA和基础架构组联合开发的类redis 存储系统, 完全支持Redis协议，用户不需要修改任何代码, 就可以将服务迁移至pika. 有维护redis 经验的DBA 维护pika 不需要学习成本&lt;/p&gt;

&lt;p&gt;pika 主要解决的是用户使用redis的内存大小超过50G, 80G 等等这样的情况, 会遇到比如启动恢复时间长,  一主多从代价大, 硬件成本贵, 缓冲区容易写满等等问题. pika 就下针对这些场景的一个解决方案&lt;/p&gt;

&lt;p&gt;pika 目前已经开源, github地址:&lt;/p&gt;

&lt;p&gt;https://github.com/Qihoo360/pika&lt;/p&gt;

&lt;p&gt;重点:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;pika 的单线程的性能肯定不如redis, pika是多线程的结构, 因此在线程数比较多的情况下, 某些数据结构的性能可以优于redis&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pika 肯定不是完全优于redis 的方案, 只是在某些场景下面更适合. 所以目前公司内部redis, pika 是共同存在的方案, DBA会根据业务的场景挑选合适的方案&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本次分享分成4个部分&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;大容量redis 容易遇到的问题&lt;/li&gt;
  &lt;li&gt;pika 整体架构&lt;/li&gt;
  &lt;li&gt;pika 具体实现&lt;/li&gt;
  &lt;li&gt;pika vs redis&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;redis 提供了丰富的多数据结构的接口, 在redis 之前, 比如memcache 都认为后端只需要存储kv的结构就可以, 不需要感知这个value 里面的内容. 用户需要使用的话通过json_encode, json_decode 等形式进行数据的读取就行. 但是其实redis 类似做了一个微创新, redis 提供了多数据结构的支持, 让前端写代码起来更加的方便了&lt;/p&gt;

&lt;p&gt;因此redis 在公司的使用率也是越来越广泛, 用户不知不觉把越来越多的数据存储在redis中, 随着用户的使用, DBA 发现有些redis 实例的大小也是越来越大. 在redis 实例内存使用比较大的情况下, 遇到的问题也会越来越多, 因此DBA和我们一起实现了大容量redis 的解决方案&lt;/p&gt;

&lt;p&gt;最近半年公司每天redis 的访问情况 
&lt;img src=&quot;http://i.imgur.com/dpHD828.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;redis 架构方案&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/plSfqUF.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;redis-&quot;&gt;大容量redis 遇到的问题&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;恢复时间长&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们线上的redis 一般同时开启rdb 和 aof.
我们知道aof的作用是实时的记录用户的写入操作, rdb 是redis 某一时刻数据的完整快照. 那么恢复的时候一般是通过 rdb + aof 的方式进行恢复, 根据我们线上的情况 50G redis 恢复时间需要差不多70分钟&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一主多从, 主从切换代价大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;redis 在主库挂掉以后, 从库升级为新的主库. 那么切换主库以后, 所有的从库都需要跟新主做一次全同步, 全量同步一次大容量的redis, 代价非常大.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;缓冲区写满问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了防止同步缓冲区被复写，dba给redis设置了2G的巨大同步缓冲区，这对于内存资源来讲代价很大. 当由于机房之间网络有故障, 主从同步出现延迟了大于2G以后, 就会触发全同步的过程. 如果多个从库同时触发全同步的过程, 那么很容易就将主库给拖死&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;内存太贵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们一般线上使用的redis 机器是 64G, 96G. 我们只会使用80% 的空间.&lt;/p&gt;

&lt;p&gt;如果一个redis 的实例是50G, 那么基本一台机器只能运行一个redis 实例. 因此特别的浪费资源&lt;/p&gt;

&lt;p&gt;总结: 可以看到在redis 比较小的情况下, 这些问题都不是问题, 但是当redis 容量上去以后. 很多操作需要的时间也就越来越长了&lt;/p&gt;

&lt;h3 id=&quot;pika-&quot;&gt;pika 整体架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/tm5ubVp.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要组成:
1. 网络模块 pink
2. 线程模块
3. 存储引擎 nemo
4. 日志模块 binlog&lt;/p&gt;

&lt;h3 id=&quot;pink-&quot;&gt;pink 网络模块&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;基础架构团队开发网络编程库, 支持pb, redis等等协议. 对网络编程的封装, 用户实现一个高性能的server 只需要实现对应的DealMessage() 函数即可&lt;/li&gt;
  &lt;li&gt;支持单线程模型, 多线程worker模型&lt;/li&gt;
  &lt;li&gt;github 地址: https://github.com/baotiao/pink&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;线程模块&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/FdaK0H5.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;pika 基于pink 对线程进行封装. 使用多个工作线程来进行读写操作，由底层nemo引擎来保证线程安全，线程分为11种：&lt;/p&gt;

&lt;p&gt;PikaServer：主线程&lt;/p&gt;

&lt;p&gt;DispatchThread：监听端口1个端口，接收用户连接请求&lt;/p&gt;

&lt;p&gt;ClientWorker：存在多个（用户配置），每个线程里有若干个用户客户端的连接，负责接收处理用户命令并返回结果，每个线程执行写命令后，追加到binlog中&lt;/p&gt;

&lt;p&gt;Trysync：尝试与master建立首次连接，并在以后出现故障后发起重连&lt;/p&gt;

&lt;p&gt;ReplicaSender：存在多个（动态创建销毁，本master节点挂多少个slave节点就有多少个），每个线程根据slave节点发来的同步偏移量，从binlog指定的偏移开始实时同步命令给slave节点&lt;/p&gt;

&lt;p&gt;ReplicaReceiver：存在1个（动态创建销毁，一个slave节点同时只能有一个master），将用户指定或当前的偏移量发送给master节点并开始接收执行master实时发来的同步命令，在本地使用和master完全一致的偏移量来追加binlog&lt;/p&gt;

&lt;p&gt;SlavePing：slave用来向master发送心跳进行存活检测&lt;/p&gt;

&lt;p&gt;HeartBeat：master用来接收所有slave发送来的心跳并恢复进行存活检测&lt;/p&gt;

&lt;p&gt;bgsave：后台dump线程&lt;/p&gt;

&lt;p&gt;scan：后台扫描keyspace线程&lt;/p&gt;

&lt;p&gt;purge：后台删除binlog线程&lt;/p&gt;

&lt;h3 id=&quot;nemo&quot;&gt;存储引擎 nemo&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Pika 的存储引擎, 基于Rocksdb 修改. 封装Hash, List, Set, Zset等数据结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们知道redis 是需要支持多数据结构的, 而rocksdb 只是一个kv的接口, 那么我们如何实现的呢?&lt;/p&gt;

&lt;p&gt;比如对于Hash 数据结构:&lt;/p&gt;

&lt;p&gt;对于每一个Hash存储，它包括hash键（key），hash键下的域名（field）和存储的值 （value）.&lt;/p&gt;

&lt;p&gt;nemo的存储方式是将key和field组合成为一个新的key，将这个新生成的key与所要存储的value组成最终落盘的kv键值对。同时，对于每一个hash键，nemo还为它添加了一个存储元信息的落盘kv，它保存的是对应hash键下的所有域值对的个数。&lt;/p&gt;

&lt;p&gt;每个hash键、field、value到落盘kv的映射转换 
&lt;img src=&quot;http://i.imgur.com/Tlu69Dk.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个hash键的元信息的落盘kv的存储格式
&lt;img src=&quot;http://i.imgur.com/ntsReMS.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如对于List 数据结构:&lt;/p&gt;

&lt;p&gt;顾名思义，每个List结构的底层存储也是采用链表结构来完成的。对于每个List键，它的每个元素都落盘为一个kv键值对，作为一个链表的一个节点，称为元素节点。和hash一样，每个List键也拥有自己的元信息。&lt;/p&gt;

&lt;p&gt;每个元素节点对应的落盘kv存储格式 
&lt;img src=&quot;http://i.imgur.com/20RrJdm.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个元信息的落盘kv的存储格式
&lt;img src=&quot;http://i.imgur.com/n9UC9Ky.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其他的数据结构实现的方式也类似, 通过将hash_filed 拼成一个key, 存储到支持kv的rocksdb 里面去. 从而实现多数据结构的结构&lt;/p&gt;

&lt;h3 id=&quot;binlog&quot;&gt;日志模块 binlog&lt;/h3&gt;

&lt;p&gt;Pika的主从同步是使用Binlog来完成的. 
binlog 本质是顺序写文件, 通过Index + offset 进行同步点检查.&lt;/p&gt;

&lt;p&gt;解决了同步缓冲区太小的问题&lt;/p&gt;

&lt;p&gt;支持全同步 + 增量同步&lt;/p&gt;

&lt;p&gt;master 执行完一条写命令就将命令追加到Binlog中，ReplicaSender将这条命令从Binlog中读出来发送给slave，slave的ReplicaReceiver收到该命令，执行，并追加到自己的Binlog中.&lt;/p&gt;

&lt;p&gt;当发生主从切换以后, slave仅需要将自己当前的Binlog Index + offset 发送给master，master找到后从该偏移量开始同步后续命令&lt;/p&gt;

&lt;p&gt;为了防止读文件中写错一个字节则导致整个文件不可用，所以pika采用了类似leveldb log的格式来进行存储，具体如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/x1H8loY.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;主要功能&lt;/h3&gt;

&lt;p&gt;pika 线上架构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/V4Ufgh1.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;主从架构&lt;/h3&gt;

&lt;p&gt;旁白: 为了减少用户的学习成本, 目前pika 的主从同步功能是和redis完全一样, 只需要slaveof 就可以实现主从关系的建立, 使用起来非常方便&lt;/p&gt;

&lt;p&gt;背景
1. Pika Replicate&lt;/p&gt;

&lt;p&gt;pika支持master/slave的复制方式，通过slave端的slaveof命令激发
salve端处理slaveof命令，将当前状态变为slave，改变连接状态
slave的trysync线程向master发起trysync，同时将要同步点传给master
master处理trysync命令，发起对slave的同步过程，从同步点开始顺序发送binlog或进行全同步&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Binlog&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pika同步依赖binlog
binlog文件会自动或手动删除
当同步点对应的binlog文件不存在时，需要通过全同步进行数据同步&lt;/p&gt;

&lt;p&gt;全同步&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;简介&lt;/p&gt;

    &lt;p&gt;需要进行全同步时，master会将db文件dump后发送给slave
 通过rsync的deamon模式实现db文件的传输&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;实现逻辑&lt;/p&gt;

    &lt;p&gt;slave在trysnc前启动rsync进程启动rsync服务
 master发现需要全同步时，判断是否有备份文件可用，如果没有先dump一份
 master通过rsync向slave发送dump出的文件
 slave用收到的文件替换自己的db
 slave用最新的偏移量再次发起trysnc
 完成同步&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/AvOKHHg.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Slave连接状态&lt;/p&gt;

    &lt;p&gt;No Connect：不尝试成为任何其他节点的slave
 Connect：Slaveof后尝试成为某个节点的slave，发送trysnc命令和同步点
 Connecting：收到master回复可以slaveof，尝试跟master建立心跳
 Connected: 心跳建立成功
 WaitSync：不断检测是否DBSync完成，完成后更新DB并发起新的slaveof&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/ffummqK.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;主从命令同步&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/YjYMsCd.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图1是一个主从同步的一个过程（即根据主节点数据库的操作日志，将主节点数据库的改变过程顺序的映射到从节点的数据库上），从图1中可以看出，每一个从节点在主节点下都有一个唯一对应的BinlogSenderThread。&lt;/p&gt;

&lt;p&gt;（为了说明方便，我们定一个“同步命令”的概念，即会改变数据库的命令，如set，hset，lpush等，而get，hget，lindex则不是）&lt;/p&gt;

&lt;p&gt;主要模块的功能：&lt;/p&gt;

&lt;p&gt;WorkerThread：接受和处理用户的命令；&lt;/p&gt;

&lt;p&gt;BinlogSenderThread：负责顺序地向对应的从节点发送在需要同步的命令；&lt;/p&gt;

&lt;p&gt;BinlogReceiverModule: 负责接受主节点发送过来的同步命令&lt;/p&gt;

&lt;p&gt;Binglog：用于顺序的记录需要同步的命令&lt;/p&gt;

&lt;p&gt;主要的工作过程：
1.当WorkerThread接收到客户端的命令，按照执行顺序，添加到Binlog里；&lt;/p&gt;

&lt;p&gt;2.BinglogSenderThread判断它所负责的从节点在主节点的Binlog里是否有需要同步的命令，若有则发送给从节点；&lt;/p&gt;

&lt;p&gt;3.BinglogReceiverModule模块则做以下三件事情：
    a. 接收主节点的BinlogSenderThread发送过来的同步命令；
    b. 把接收到的命令应用到本地的数据上；
    c. 把接收到的命令添加到本地Binlog里&lt;/p&gt;

&lt;p&gt;至此，一条命令从主节点到从节点的同步过程完成&lt;/p&gt;

&lt;p&gt;BinLogReceiverModule的工作过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/mgIB0P8.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图2是BinLogReceiverModule（在源代码中没有这个对象，这里是为了说明方便，抽象出来的）的组成，从图2中可以看出BinlogReceiverModule由一个BinlogReceiverThread和多个BinlogBGWorker组成。&lt;/p&gt;

&lt;p&gt;BinlogReceiverThread: 负责接受由主节点传送过来的命令，并分发给各个BinlogBGWorker，若当前的节点是只读状态（不能接受客户端的同步命令），则在这个阶段写Binlog&lt;/p&gt;

&lt;p&gt;BinlogBGWorker：负责执行同步命令；若该节点不是只读状态（还能接受客户端的同步命令），则在这个阶段写Binlog（在命令执行之前写）&lt;/p&gt;

&lt;p&gt;BinlogReceiverThread接收到一个同步命令后，它会给这个命令赋予一个唯一的序列号（这个序列号是递增的），并把它分发给一个BinlogBGWorker；而各个BinlogBGWorker则会根据各个命令的所对应的序列号的顺序来执行各个命令，这样也就保证了命令执行的顺序和主节点执行的顺序一致了&lt;/p&gt;

&lt;p&gt;之所以这么设计主要原因是：
        a. 配备多个BinlogBGWorker是可以提高主从同步的效率，减少主从同步的滞后延迟；
        b. 让BinlogBGWorker在执行执行之前写Binlog可以提高命令执行的并行度；
        c. 在当前节点是非只读状态，让BinglogReceiverThread来写Binlog，是为了让Binglog里保存的命令顺序和命令的执行顺序保持一致；&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;数据备份&lt;/h4&gt;

&lt;p&gt;不同于Redis，Pika的数据主要存储在磁盘中，这就使得其在做数据备份时有天然的优势，可以直接通过文件拷贝实现&lt;/p&gt;

&lt;p&gt;流程: 
    打快照：阻写，并在这个过程中或的快照内容
    异步线程拷贝文件：通过修改Rocksdb提供的BackupEngine拷贝快照中文件，这个过程中会阻止文件的删除&lt;/p&gt;

&lt;p&gt;快照内容&lt;/p&gt;

&lt;p&gt;当前db的所有文件名
manifest文件大小
sequence_number
同步点: binlog index + offset&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/mSkkqVY.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;key&quot;&gt;秒删大量的key&lt;/h3&gt;

&lt;p&gt;在我们大量的使用场景中. 对于Hash, zset, set, list这几种多数据机构，当member或者field很多的时候，用户有批量删除某一个key的需求, 那么这个时候实际删除的就是rocksdb 底下大量的kv结构, 如果只是单纯暴力的进行删key操作, 那时间肯定非常的慢, 难以接受. 那我们如何快速删除key？&lt;/p&gt;

&lt;p&gt;刚才的nemo 的实现里面我们可以看到, 我们在value 里面增加了version, ttl 字段, 这两个字段就是做这个事情.&lt;/p&gt;

&lt;p&gt;Solution 0：暴力删除每一个member，时间复杂度O(m) , m是member的个数；&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：易实现；
缺点：同步处理，会阻碍请求；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Solution 1: 启动后台线程，维护删除队列，执行删除，时间复杂度O（m)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：不会明显阻住server；
缺点：仍然要O(m)去删除members，可以优化删除的速度；

Redis 是怎么做的？

    旧版本的Del接口，在实际free大量内存的时候仍然会阻塞server；
    新版增加了lazy free,根据当前server的负载，多次动态free；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Solution 2: 不删除, 只做标记, 时间复杂度O(1)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;优点：效率就够了；
缺点：需要改动下层rocksdb，一定程度破坏了rocksdb的封装，各个模块之间耦合起来；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;方案：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Key的元信息增加版本，表示当前key的有效版本；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;操作：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Put：查询key的最新版本，后缀到val；
Get：查询key的最新版本，过滤最新的数据；
Iterator： 迭代时，查询key的版本，过滤旧版本数据；

Compact：数据的实际删除是在Compact过程中，根据版本信息过滤；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;目前nemo 采用的就是第二种, 通过对rocksdb 的修改, 可以实现秒删的功能, 后续通过修改rocksdb compact的实现, 在compact 的过程中, 将历史的数据淘汰掉&lt;/p&gt;

&lt;h4 id=&quot;compact-&quot;&gt;数据compact 策略&lt;/h4&gt;

&lt;p&gt;rocksdb 的compact 策略是在写放大, 读放大, 空间放大的权衡.&lt;/p&gt;

&lt;p&gt;那么我们DBA经常会存在需求尽可能减少空间的使用, 因此DBA希望能够随时触发手动compact, 而又尽可能的不影响线上的使用, 而rocksdb 默认的手动compact 策略是最高优先级的, 会阻塞线上的正常流程的合并.&lt;/p&gt;

&lt;p&gt;rocksdb 默认的 manual compact 的限制&lt;/p&gt;

&lt;p&gt;a) 当manual compact执行时，会等待所有的自动compact任务结束, 然后才会执行本次manual compact；
b) manual执行期间，自动compact无法执行&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当manual执行很长时间，无法执行自动compact，导致线上新的写请求只能在memtable中；&lt;/li&gt;
  &lt;li&gt;当memtable个数超过设置的level0_slowdown_writes_trigger(默认20)，写请求会出被sleep；&lt;/li&gt;
  &lt;li&gt;再严重一些，当超过level0_stop_writes_trigger（默认24)，完全停写；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了避免这种情况，我们对compact的策略进行调整，使得自动compact一直优先执行，避免停写；&lt;/p&gt;

&lt;p&gt;总结:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;恢复时间长
  pika 的存储引擎是nemo, nemo 使用的是rocksdb,  我们知道 rocksdb 启动不需要加载全部数据, 只需要加载几M的log 文件就可以启动, 因此恢复时间非常快&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一主多从, 主从切换代价大
  在主从切换的时候, 新主确定以后, 从库会用当前的偏移量尝试与新主做一次部分同步, 如果部分同步不成功才做全同步. 这样尽可能的减少全同步次数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缓冲区写满问题
  pika 不适用内存buffer 进行数据同步, pika 的主从同步的操作记录在本地的binlog 上, binlog 会随着操作的增长进行rotate操作. 因此不会出现把缓冲区写满的问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内存昂贵问题
  pika 的存储引擎nemo 使用的是rocksdb, rocksdb 和同时使用内存和磁盘减少对内存的依赖. 同时我们尽可能使用SSD盘来存放数据, 尽可能跟上redis 的性能.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pika-vs-redis&quot;&gt;pika vs redis&lt;/h3&gt;

&lt;p&gt;pika相对于redis，最大的不同就是pika是持久化存储，数据存在磁盘上，而redis是内存存储，由此不同也给pika带来了相对于redis的优势和劣势&lt;/p&gt;

&lt;p&gt;优势:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;容量大：Pika没有Redis的内存限制, 最大使用空间等于磁盘空间的大小&lt;/li&gt;
  &lt;li&gt;加载db速度快：Pika 在写入的时候, 数据是落盘的, 所以即使节点挂了, 不需要rbd或者aof，pika 重启不用重新加载数据到内存而是直接使用已经持久化在磁盘上的数据, 不需要任何数据回放操作，这大大降低了重启成本。&lt;/li&gt;
  &lt;li&gt;备份速度快：Pika备份的速度大致等同于cp的速度（拷贝数据文件后还有一个快照的恢复过程，会花费一些时间），这样在对于百G大库的备份是快捷的，更快的备份速度更好的解决了主从的全同步问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;劣势:&lt;/p&gt;

&lt;p&gt;由于Pika是基于内存和文件来存放数据, 所以性能肯定比Redis低一些, 但是我们一般使用SSD盘来存放数据, 尽可能跟上Redis的性能。&lt;/p&gt;

&lt;p&gt;总结:&lt;/p&gt;

&lt;p&gt;从以上的对比可以看出, 如果你的业务场景的数据比较大，Redis 很难支撑， 比如大于50G，或者你的数据很重要，不允许断电丢失，那么使用Pika 就可以解决你的问题。&lt;/p&gt;

&lt;p&gt;而在实际使用中，大多数场景下pika的性能大约是Redis的50%~80%，在某些特定场景下，例如range 500，pika的性能只有redis的20%，针对这些场景我们仍然在改进&lt;/p&gt;

&lt;p&gt;在360内部使用情况:&lt;/p&gt;

&lt;p&gt;粗略的统计如下：&lt;/p&gt;

&lt;p&gt;当前每天承载的总请求量超过100亿, 实例数超过100个&lt;/p&gt;

&lt;p&gt;当前承载的数据总量约3 TB&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;性能对比&lt;/h3&gt;

&lt;p&gt;Server Info:
    CPU: 24 Cores, Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    MEM: 165157944 kB
    OS: CentOS release 6.2 (Final)
    NETWORK CARD: Intel Corporation I350 Gigabit Network Connection&lt;/p&gt;

&lt;p&gt;测试过程, 在pika 中先写入150G 大小的数据. 写入Hash key 50个, field 1千万级别.
redis 写入5G 大小的数据&lt;/p&gt;

&lt;p&gt;Pika:
18个线程&lt;/p&gt;

&lt;p&gt;redis:
单线程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/4tFI6kq.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;结论: pika 的单线程的性能肯定不如redis, pika是多线程的结构, 因此在线程数比较多的情况下, 某些数据结构的性能可以优于redis&lt;/p&gt;

&lt;h3 id=&quot;wiki&quot;&gt;wiki&lt;/h3&gt;

&lt;p&gt;github 地址:&lt;/p&gt;

&lt;p&gt;https://github.com/Qihoo360/pika&lt;/p&gt;

&lt;p&gt;github wiki:&lt;/p&gt;

&lt;p&gt;https://github.com/Qihoo360/pika/wiki/pika介绍&lt;/p&gt;

&lt;h2 id=&quot;faq&quot;&gt;FAQ&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;如果我们想使用新DB, 那核心问题是如何进行数据迁移. 从redis迁移到pika需要经过几个步骤？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;开发需要做的：&lt;/p&gt;

&lt;p&gt;开发不需要做任何事，不用改代码、不用替换driver（pika使用原生redis的driver），什么都不用动，看dba干活就好&lt;/p&gt;

&lt;p&gt;dba需要做的：
    1.dba迁移redis数据到pika
    2.dba将redis的数据实时同步到pika，确保redis与pika的数据始终一致
    3.dba切换lvs后端ip，由pika替换redis&lt;/p&gt;

&lt;p&gt;迁移过程中需要停业务/业务会受到影响吗：
    然而并不会&lt;/p&gt;

&lt;p&gt;迁移是无缝且温和的吗：
    那当然&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个和你们公司内部的bada 有什么区别?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们之前在bada 上面支持过redis 的多数据结构, 并且兼容redis协议, 但是遇到了问题.&lt;/p&gt;

&lt;p&gt;在分布式系统里面, 对key 的hash 场景的通常是两种方案:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;以BigTable 为代表的, 支持range key 的hash 方案. 这个方案的好处是可以实现动态的扩展&lt;/li&gt;
  &lt;li&gt;以Dynamo 为代表的, 取模的hash 方案. 这个方案的好处是时间简单&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们bada 目前支持的是取模的hash 方案, 在实现redis 的多数据结构的时候, 比如hash 我们采用key取模找到对应的分片. 那么这样带来的问题是由于多数据结构里面key 不多, field 比较多的场景还是大部分的情况, 因此极容易照成分片的不均匀, 性能退化很明显.&lt;/p&gt;

&lt;p&gt;360基础架构组公众号:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Yk2A0NS.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 18 May 2016 00:00:00 +0800</pubDate>
        <link>http://baotiao.github.io//2016/05/18/pika-introduction/</link>
        <guid isPermaLink="true">http://baotiao.github.io//2016/05/18/pika-introduction/</guid>
      </item>
    
  </channel>
</rss>
