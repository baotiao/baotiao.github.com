<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>baotiao</title>
    <description>做有积累的事情</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>PolarDB-CloudJump：优化基于云存储服务的云数据库(发表于VLDB 2022)</title>
        <description>&lt;p&gt;云数据库实现计算存储分离，支持计算与存储的独立扩展，其用户还可以享受按量付费等特性。这使得基于云数据库的系统更加高效、灵活。因此，构建并使用云原生数据库的势头愈演愈烈。另一方面，云化存储服务已经是云的标准能力，存储侧提供兼容通用的文件接口，并且不对外暴露持久化、容错处理等复杂细节，其易用性和规模化带来的高性价比使得云存储成为了云上系统的第一选择。在通用云存储服务上构建云数据库，无疑是一种既能够享受规模化云存储红利，又能够通过可靠云存储服务实现降低维护成本、加速数据库开发周期的方案。&lt;/p&gt;

&lt;p&gt;然而，考虑到云存储和本地存储之间的特性差异，在将本地数据库迁移到云上构建云数据库时，如何有效使用云存储面临了许多挑战。对此，我们在论文里分析了基于B-tree和LSM-tree的存储引擎在云存储上部署时面临的挑战，并提出了一个优化框架CloudJump，以希望能够帮助数据库开发人员在基于云存储构建数据库时使系统更为高效。我们以云原生数据库PolarDB为案例，展示了一系列针对性优化，并将部分工作扩展应用到基于云存储的RocksDB上，以此来演示CloudJump的可用性。&lt;/p&gt;

&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;我们讨论的云存储主要基于弹性分布式块存储，云中其他类型的存储服务，例如基于对象的存储，不在本文的讨论范围内。共享云存储（如分布式块存储服务加分布式文件系统）可以作为多个计算节点的共享存储层，提供QoS（服务质量）保证、大容量、弹性和按量付费定价模型。对于大多数云厂商和云用户来说，拥有云存储服务比构建和维护裸机SSD集群更有吸引力。因此，与其为云本机数据库构建和优化专用存储服务，不如利用现有云存储服务构建云本机数据库，这是一种非常可行的选择。此外，随着云存储服务几乎实现了标准化，相应的开发、迁移变得更加快速。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f1.png&quot; alt=&quot;f1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图1展示了本地数据库（不含备份）与shared-storage云原生数据库的系统结构，AWS Aurora首先引导了这种从本地数据库向shared-storage云原生数据库的迁移。它将数据库分为存储层和计算层，并可以独立扩展每一层。为了消除了传输数据页中产生的沉重的网络开销，它进一步定制了存储层，在数据页上应用重做日志，从而不再需要在两层之间传输数据页。无疑这种设计在云中提供了一种非标准存储服务，只能由Aurora的计算层使用。&lt;/p&gt;

&lt;p&gt;另一种方案是依赖标准化接口的云存储服务迁移或构建获得云数据库，这也是本文的研究目标。前面已经提到过，这样做的优势主要在于的可以实现系统的快速开发、平滑迁移、收纳标准化规模化存储服务的原有优势等。此外，特别是在我们项目（PolarDB）的硬件环境、已有背景下，兼顾服务可靠性和开发迭代需求，针对进行云存储服务特性进行性能优化是最迫切的第一步。&lt;/p&gt;

&lt;h3 id=&quot;挑战与分析&quot;&gt;挑战与分析&lt;/h3&gt;

&lt;p&gt;云存储和本地SSD存储在带宽、延迟、弹性、容量等方面存在巨大差异，例如图2展示了在稳态条件下本地SSD与云存储I/O延时、带宽与工作线程关系，它们对数据库等设计有着巨大影响。此外，共享存储的架构特性也会对云存储带来影响，如多个节点之间的数据一致性增加了维护cache一致性开销&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f2.png&quot; alt=&quot;f2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过系统实验、总结分析等，我们发现CloudJump面临以下技术挑战：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;远程分布式存储集群的访问导致云存储服务的I/O延迟高；&lt;/li&gt;
  &lt;li&gt;通常聚合I/O带宽未被充分利用；&lt;/li&gt;
  &lt;li&gt;在具有本地存储的单机上运行良好但需要适应云存储而导致特性改变的传统设计，例如文件cache缓存；&lt;/li&gt;
  &lt;li&gt;长链路导致各种数据库I/O操作之间的隔离度较低（例如，日志刷写与大量数据I/O的竞争）；&lt;/li&gt;
  &lt;li&gt;云用户允许且可能使用非常大的单表文件（例如数十TB）而不进行数据切分，这加剧了I/O问题的影响。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;针对不同的数据存储引擎，如基于B-tree和LSM-tree的存储引擎，这些特性差异会带来不同的性能差异，表1归纳总结了这些挑战及其对数据库设计的影响。其中有共性问题，如WAL路径写入变慢、共享存储（分布式文件系统）cache一致性代价等；也有个性问题，如B-tree结构在独占资源情况下做远程I/O、远程加剧I/OLSM-tree读放大影响等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f3.png&quot; alt=&quot;f3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;优化原则&quot;&gt;优化原则&lt;/h3&gt;

&lt;p&gt;CloudJump针对上述挑战，提出7条优化准则：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Thread-level Parallelism&lt;/strong&gt;：例如依据I/O特性实验，采用（更）多线程的日志、数据I/O线程及异步I/O模型，将数据充分打散到多个存储节点上。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Task-level Parallelism&lt;/strong&gt;：例如对集中Log buffer按Page Partition分片，实现并行写入并基于分片进行并行Recovery。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reduce remote read and Prefetching&lt;/strong&gt;：例如通过收集并聚合原分散meta至统一的superblock，将多个I/O合一实现fast validating；通过预读利用聚合读带宽、减少读任务延时；通过压缩、filter过滤减少读取数据量。与本地SSD上相比，这些技术在云存储上更能获得收益。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fine-grained Locking and Lock-free Data Structures&lt;/strong&gt;：云存储中较长的I/O延迟放大了同步开销，主要针对Update-in-place系统，实现无锁刷脏、无锁SMO等。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scattering among Distributed Nodes&lt;/strong&gt;：在云存储中，多个节点之间的分散访问可以利用更多的硬件资源，例如将单个大I/O并发分散至不同存储节点 ，充分利用聚合带宽。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bypassing Caches&lt;/strong&gt;：通过Bypassing Caches来避免分布式文件系统的cache coherence，并在DB层面优化I/O格式匹配存储最佳request格式。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scheduling Prioritized I/O Tasks&lt;/strong&gt;：由于访问链路更长（如路径中存在更多的排队情况），不填I/O请求间的隔离性相对本地存储更低，因此需要在DB层面对不同I/O进行打标、调度优先级，例：优先WAL、预读分级。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;实践案例&quot;&gt;实践案例&lt;/h3&gt;
&lt;h4 id=&quot;实践案例polardb&quot;&gt;实践案例：PolarDB&lt;/h4&gt;
&lt;p&gt;PolarDB构建基于具有兼容Posix接口的分布式文件系统PolarFS，与Aurora一样采用计算存储分离架构，借助高速RDMA网络以及最新的块存储技术实现超低延迟和高可用能力能力。在PolarDB上，我们做了许多适配于分布式存储特性、符合CloudJump准则的性能优化，大幅提升了云原生数据库PolarDB的性能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f4.png&quot; alt=&quot;f4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. WAL写入优化&lt;/strong&gt;
WAL（Write ahead log）写入是用于一致性和持久性的关键路径，事务的写入性能对log I/O的延迟非常敏感。原生InnoDB以MTR（Mini-Transaction）的粒度组织日志，并保有一个全局redo日志缓冲区。 当一个MTR被提交时，它缓存的所有日志记录被追加到全局日志缓冲区，然后集中的顺序刷盘以保证持久化特性。这一传统集中日志模式在本地盘上工作良好，但使用云存储时，集中式日志的写入性能随着远程I/O时延变高而下降，进而影响事务写入性能。基于云存储的特性，我们提出了两个优化来提升WAL的写入性能：日志分片和（大）I/O任务并行打散。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f5.png&quot; alt=&quot;f5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Redo日志分片&lt;/em&gt;：InnoDB的redo采用的是Physiological Logging的方式，大部分MTR针对单个的数据页（除部分特殊），页之间基本相互独立。如图5（左），我们将redo日志、redo缓冲区等按其修改的page进行分片（partition），分别写入不同的文件中，来支持并发写log（以及并发Recovery，并发物理复制等），从而在并发写友好的分布式文件系统上的获得写入性能优势。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I/O任务并行打散&lt;/em&gt;：在云存储中，一个文件由多个chunk组成，根据chunk的分配策略，不同chunk很可能位于不同的存储节点中。我们将每个redo分片（partition）的文件进一步拆分为多个物理分片（split），如图5（右）所示，对于单个大log I/O任务（如group commit、BLOB record等），log writer会将I/O按lsn切片并且并发的分发I/O请求至不同split。通过这种方式，可以将大延时的log I/O任务拆分，并利用分布式存储高分布写特性来减少整体I/O时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 快速恢复&lt;/strong&gt;
为了实现快速恢复，我们提出了两个优化：快速（启动）验证和全并行恢复。
&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f6.png&quot; alt=&quot;f6&quot; /&gt;
在InnoDB的原有恢复过程中，InnoDB首先在启动期间会打开所有文件读取元信息（如文件名、表ID等）并验证正确性，然后通过ARIES风格的恢复算法重做未checkpoint的数据。为了加速启动，快速验证方法不会扫描所有文件，而是在数据库的生命周期中记录和集中必要的元信息，并在创建、修改文件时将必要的元信息集中记录在一个superblock中，在启动时仅扫描元数据块文件。因此，减少了启动扫描过程中的远程I/O访问开销。其次，依赖于Redo日志分片，我们将log file按page拆分成多个文件，在恢复阶段（可以进一步划分为parse、redo、undo三个阶段），可以天然的支持并发parse和redo（undo阶段在后台进行），通过并发任务充分调动CPU和I/O资源加速恢复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. 预读取&lt;/strong&gt;
在云存储环境下，读I/O延时大大增加，当用户任务访问数据发生cache miss的情况下，而有效的预读取能够充分利用聚合读带宽来减少读任务延时。InnoDB中有线性预读和非线性预读两种原生的物理预读方法，我们进一步引入了逻辑预读策略（由于无序的插入和更新，索引在物理上不一定是顺序的）。例如对于主索引扫描，当任务线程从起始键顺序扫描索引超过一定阈值时，逻辑预读会在主索引上按逻辑顺序触发异步预读，提前读取一定量的顺序页。又如对于具有二级索引和非索引列回表操作的扫描，在对二级索引进行扫描同时批量收集相关命中的主键，积累一定批数据后触发异步任务预读对应主索引数据（此时剩余的二级索引扫描可能仍在进行中）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. 同步（锁）优化&lt;/strong&gt;
相关背景可以先查阅&lt;a href=&quot;https://zhuanlan.zhihu.com/p/151397269&quot;&gt;《InnoDB btree latch 优化历程》&lt;/a&gt;这篇文章。
&lt;em&gt;无锁刷脏&lt;/em&gt;：原生InnoDB在刷脏时需要持有当前page的sx锁，导致I/O期间当前page的写入被完全阻塞。而在云存储上I/O延迟更高，阻塞时间更久。我们采用shadow page的方式，首先对当前page构建内存副本，构建好内存副本后原有page的sx锁被释放，然后用这个shadow page内容去做刷脏及相关刷写信息更新。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SMO加锁优化&lt;/em&gt;：在InnoDB 里面, 依然有一个全局的index latch, 由于全局的index latch 存在会导致同一时刻在Btree 中只有一个SMO 能够发生, index latch 依然会成为全局的瓶颈点。上述index latch不仅是计算瓶颈，而从另一方面考虑，锁同步期间index上其他可能I/O操作无法并行，存储带宽利用率较低。相关实现可以参考文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/374000358&quot;&gt;《路在脚下, 从BTree 到Polar Index》&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. 多I/O任务队列适配&lt;/strong&gt;
针对云存储具有I/O隔离性低的挑战，同时为了避免云存储无法识别DB层存储内核的I/O语义，而造成优先级低的I/O请求（如page刷脏、低优先级预读）影响关键I/O路径的性能，在数据库内核中提供合理的I/O调度模型是很重要的。在 PolarDB 中，我们在数据库内核层为不同类型的I/O请求进行调度，实现根据当前I/O压力实现数据库最优的性能，每个I/O请求都具有 DB 层的语义标签，如 WAL 读/写，Page 读/写。
&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f7.png&quot; alt=&quot;f7&quot; /&gt;
我们为数据库的异步I/O请求建立了多个支持并发写入的生产者 / 消费者队列，并且其存在三种不同特性的队列，分别为 Private 队列，Priority 队列，以及 General 队列，不同队列的数量是根据当前云存储的I/O能力决定的。&lt;/p&gt;

&lt;p&gt;正常情况下，WAL 的写入只通过其 Private 队列，当写入量增大时，其I/O请求也会转发至 Priority 队列，此时 Priority 队列会优先执行 WAL 的写入，并且后续Page写入的I/O不会进入 Priority 队列。基于这种I/O模型，我们保证了一定部分的I/O资源时预留给WAL写入，保证事务提交的写入性能，充分利用云存储的高聚合带宽。此外，I/O任务队列的长度和数目也进行了拓展以一步匹配云存储高吞吐、大带宽但时延较高且波动大的特性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. 格式化I/O请求&lt;/strong&gt;
云存储和本地存储在I/O格式上具有显著的不同，例如 Block 大小，I/O请求的发起方式。在大多数分布式的云存储中，在实现多个计算节点的共享时，为了避免维护计算节点 cache 一致性的问题，不存在 page cache，此时采用原先本地存储的I/O格式在云上会造成例如 read-on-write 和逻辑与物理位置映射的问题，造成性能下降。在 PolarDB中，我们为WAL I/O和 Page I/O匹配了适应云存储的请求I/O格式以尽可能降低单个I/O的延时。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WAL I/O对齐&lt;/em&gt;：文件是通过固定大小的 block 进行读写的。云存储具有更大的 block size （4-128 KB），传统的 log 对齐策略不适合云存储上的 stripe boundary。我们在 log 数据进行提交的时候，将I/O请求的长度和偏移与云存储的 block size进行对齐。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Data I/O对齐&lt;/em&gt;：例如当前存在两种类型的数据页：常规页和压缩页，常规页为16 KB，可以很容易与云存储的 Block size 进行对齐，但是压缩页会造成后续大量的不对齐I/O。以PolarDB 中对于压缩页的对齐为例。首先，我们读取时保证以最小单位（如PolarFS的4 KB）读取。而在写入时，对于所有小于最小访问单元的压缩页数据，我们会拓展到最小单位再进行写入，以保证存储上的页数据都是最小单位对齐的。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;去除 Data I/O合并&lt;/em&gt;：在本地数据库中，数据页的I/O会被合并来形成大的I/O实现连续地顺序写入。在云存储中，并发地向不同存储节点写入具有更高的性能，因此在云存储的数据库上，可以无需数据页的I/O合并操作。&lt;/p&gt;

&lt;p&gt;受篇幅所限，我们在本文中只简单介绍所提优化方法的大致实现逻辑，具体实现细节请读者查阅论文及相关文章。&lt;/p&gt;

&lt;p&gt;为了验证我们的优化效果, 我们对比了为针对云存储优化的MySQL 分别运行在PolarStore 和 Local Disk, 以及我们优化以后的PolarDB, 从下图可以看到PolarDB 在CPU-bound, IO-bound sysbench, TPCC 等各个场景下都表现除了明显的性能优势.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/image-20220623203947797.png&quot; alt=&quot;image-20220623203947797&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同时, 为了证明我们的优化效果不仅仅对于我们自己的云存储PolarStore 有收益, 对于所有的云存储应该都有收益, 因此我们将针对云存储优化的PolarDB 运行在 StorageX, ESSD 等其他云存储上,  我们发现均能获得非常好的性能提升, 从而说明我们的优化对于大部分云存储都是有非常大的收益&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/image-20220623204635224.png&quot; alt=&quot;image-20220623204635224&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;实践案例rocksdb&quot;&gt;实践案例：RocksDB&lt;/h4&gt;

&lt;p&gt;我们还将CloudJump的分析框架和部分优化方法拓展到基于云存储的RocksDB上，同样获得了预计的性能收益。
&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f8.png&quot; alt=&quot;f8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Log I/O任务并行打散&lt;/strong&gt;
RocksDB同样使用集中WAL来保证进程崩溃的一致性，集中日志收集多个column family的日志记录并持久化至单个日志文件。考虑到LSM-Tree只需要恢复尾部append-only的数据块，我们采用在上一个案例中提到的&lt;em&gt;log I/O并行打散&lt;/em&gt;的方法在log writer中切分批日志并且并行分发到不同文件分片中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 数据访问加速&lt;/strong&gt;
在RocksDB中有许多加速数据访问的技术，主要有prefetching, filtering 和compression机制。考虑到云存储的特性，这些技术（经过适当改造）在云存储环境中更有价值。经过分析和实验，我们提出了以下建议：1）预读机制能加速部分查询和compaction操作，建议compaction操作开启预读并设定合理的预读I/O任务优先级，并将单个预读操作的大小对齐存储粒度，对于查询操作预读应由用户场景确定；2）在云存储上建议开启bloom filters，并且将filter的meta和常规数据分离，将filter信息并集中管理；3）采用块压缩来减小数据访问的整体用时，如下表展示了数据量和PolarFS访问延时，表中存储基于RDMA，在延迟更高的存储环境中，压缩收益更高，引入压缩后数据访问的整体延时（特别是读延时）下降。
&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/f9.png&quot; alt=&quot;f9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. 多I/O任务队列及适配&lt;/strong&gt;
在多核硬件环境中，我们引入了一个多队列I/O模型并在RocksDB中拆分I/O任务和工作任务（例如压缩作业和刷新作业）。这是因为我们通过调整I/O线程的数量来控制较好吞吐和延迟关系。由于将I/O任务与后台刷写作业分离，因此无需进一步增加刷写线程的数量，刷写线程只会对齐I/O请求并进行调度分发。RocksDB本身提供了基于线程角色的优先级调度方案，而我们的调度方法这里是基于I/O标签。&lt;/p&gt;

&lt;p&gt;我们根据云存储调整I/O请求和数据组织（例如block和SST）的大小，并进行更精确的控制，以使SST文件过滤器的块大小也正确对齐。以PolarFS为例，存储的最小请求大小为4 KB（表示最小的处理单元），理想的请求大小为16 KB的倍数（不造成read-on-write），元数据存储粒度为4 MB。SST大小和块大小分别严格对齐存储粒度和理想请求大小的倍数。原生RocksDB也有对齐策略，我们在此需要进行存储参数适配并且对压缩数据块也进行对齐。&lt;/p&gt;

&lt;p&gt;我们不会向多队列I/O模型传递小于最小请求大小的I/O请求，而是对齐最小I/O大小，并将未对齐的后缀缓存在内存中以供后续对齐使用。其次，我们不会下发单个大于存储粒度的I/O请求，而是通过多队列I/O模型执行并行任务（例如一个6 MB的I/O会分散成4 MB加1 MB的两个任务）。这不仅可以将数据尽可能分散在不同的存储节点上，还可以最大限度地提高并行性以充分利用带宽。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. I/O对齐&lt;/strong&gt;
在所有日志和数据I/O请求排入队列前，对其的大小和起始offset进行对齐。对于WAL写入路径，类似于PolarDB的log I/O对齐。对于数据写入路径，在采用数据压缩时，LSM树结构可能会有大量未对齐的数据块。例如要刷写从1 KB开始的2 KB日志数据时，它将从内存缓存的数据中填充前1 KB（对于append-only结构通过保存尾部数据缓存实现，这是与update-in-place结构直接拓展原生页至最小单位的不同之处），并在3-4 KB中附加零，然后从0 KB起始发送一个4 KB的I/O。&lt;/p&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;在这项论文工作中，我们分析了云存储的性能特征，将它们与本地SSD存储进行了比较，总结了它们对B-tree和LSM-tree类数据库存储引擎设计的影响，并推导出了一个框架CloudJump来指导本地存储引擎迁移到云存储的适配和优化。 并通过PolarDB, RocksDB 两个具体Case 展示优化带来的收益.&lt;/p&gt;

&lt;p&gt;更详细的内容请参阅论文《CloudJump: Optimizing Cloud Database For Cloud Storage》。&lt;/p&gt;

&lt;p&gt;感谢数据库产品事业部架构师团队, 感谢 POLARDB 团队全体同学.&lt;/p&gt;
</description>
        <pubDate>Mon, 04 Jul 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2022/07/04/polardb-innodb/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/07/04/polardb-innodb/</guid>
      </item>
    
      <item>
        <title>MySQL unique key check issue</title>
        <description>&lt;h3 id=&quot;innodb-unique-check-的问题&quot;&gt;InnoDB unique check 的问题&lt;/h3&gt;

&lt;p&gt;unique secondary index 是客户经常使用的场景, 用来保证index 上的record 的唯一性. 但是大量的客户在使用unique secondary index 以后会发现偶尔会有死锁或者不应该锁等待的时候却发生锁等待的情况. 也有很多客户来问我们这个问题.&lt;/p&gt;

&lt;p&gt;理论上PolarDB 默认使用read-commit isolation level,  在rc 隔离级别下绝大部分场景不会使用GAP lock, 因此死锁的概率应该是比较低的. 这又是为什么呢?&lt;/p&gt;

&lt;p&gt;关于InnoDB 事务锁介绍可以看这个&lt;a href=&quot;http://mysql.taobao.org/monthly/2016/01/01/&quot;&gt;InnoDB lock sys&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;其实这个问题是已经有十年历史的老问题, 也是官方一直没解决的问题.&lt;/p&gt;

&lt;p&gt;https://bugs.mysql.com/bug.php?id=68021&lt;/p&gt;

&lt;p&gt;我们用这个bug issue 里面的case 描述一下这个问题&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Prepare test data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;`ti`&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;`session_ref_id`&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bigint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AUTO_INCREMENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;`customer_id`&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bigint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;`client_id`&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;7&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;`app_id`&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;smallint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`session_ref_id`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;UNIQUE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;`uk1`&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`customer_id`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`client_id`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`app_id`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ENGINE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InnoDB&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CHARSET&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utf8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ti&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session_ref_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ti&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session_ref_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4090&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ti&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session_ref_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ti&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session_ref_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;session 1 删除这一行(4090, 9000, 10, 5); 然后再insert 一个二级索引一样的一行 (5000, 9000, 10, 5);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;-- session 1
session1 &amp;gt; start transaction;
Query OK, 0 rows affected (0.00 sec)

session1 &amp;gt; DELETE FROM ti WHERE session_ref_id = 4090;
Query OK, 1 row affected (0.00 sec)

session1 &amp;gt; INSERT INTO ti (session_ref_id, customer_id, client_id, app_id) VALUES (5000, 9000, 10, 5);
Query OK, 1 row affected (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来问题出现了.&lt;/p&gt;

&lt;p&gt;可以看到插入 (NULL, 8001, 10, 5) 这一行的时候出现了锁等待, 理论上不应该有锁等待的, 因为pk 是自增, 而二级索引(8001, 10, 5) 并没有和任何record 冲突, 为什么会这样呢?&lt;/p&gt;

&lt;p&gt;而插入 (NULL, 7999, 10, 5) 却没有问题, 二级索引(7999, 10, 5) 同样也没有和任何二级索引冲突&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;-- session 2
session2 &amp;gt; set innodb_lock_wait_timeout=1;
Query OK, 0 rows affected (0.00 sec)

session2 &amp;gt; start transaction;
Query OK, 0 rows affected (0.00 sec)

session2 &amp;gt; INSERT INTO ti (session_ref_id, customer_id, client_id, app_id) VALUES (NULL, 8001, 10, 5);
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction

session2 &amp;gt; INSERT INTO ti (session_ref_id, customer_id, client_id, app_id) VALUES (NULL, 7999, 10, 5);
Query OK, 1 row affected (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看事务锁信息可以看到&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;mysql&amp;gt; select ENGINE_TRANSACTION_ID, index_name, lock_type, lock_mode, LOCK_STATUS, lock_data  from performance_schema.data_locks;
+-----------------------+------------+-----------+------------------------+-------------+--------------+
| ENGINE_TRANSACTION_ID | index_name | lock_type | lock_mode              | LOCK_STATUS | lock_data    |
+-----------------------+------------+-----------+------------------------+-------------+--------------+
|              99537179 | NULL       | TABLE     | IX                     | GRANTED     | NULL         |
|              99537179 | uk1        | RECORD    | X,GAP,INSERT_INTENTION | WAITING     | 9000, 10, 5  |
|              99537176 | NULL       | TABLE     | IX                     | GRANTED     | NULL         |
|              99537176 | PRIMARY    | RECORD    | X,REC_NOT_GAP          | GRANTED     | 4090         |
|              99537176 | uk1        | RECORD    | X,REC_NOT_GAP          | GRANTED     | 9000, 10, 5  |
|              99537176 | uk1        | RECORD    | S                      | GRANTED     | 9000, 10, 5  |
|              99537176 | uk1        | RECORD    | S                      | GRANTED     | 10000, 10, 5 |
|              99537176 | uk1        | RECORD    | S,GAP                  | GRANTED     | 9000, 10, 5  |
+-----------------------+------------+-----------+------------------------+-------------+--------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;session1 在uk1 上持有(10000, 10, 5), (9000, 10, 5) 上面的next-key lock.&lt;/p&gt;

&lt;p&gt;session2 插入(8001, 10, 5) 这一行记录的时候, 走的是正常的insert 逻辑, 最后在插入的时候需要申请insert record 的下一个key 上面的GAP| insert_intention lock.  和trx1 上面持有的(9000, 10, 5) next-key lock 冲突了, 所以需要等待.&lt;/p&gt;

&lt;p&gt;而如果插入的记录是(7999, 10, 5) 需要申请的insert record 下一个key 是(8000, 10, 5) 的 GAP | insert_intention lock, 那么自然没有冲突, 那么就能够插入成功.&lt;/p&gt;

&lt;p&gt;那么为什么session1 需要持有 next-key lock, 我们需要先了解二级索引的unique check 的流程是怎样的?&lt;/p&gt;

&lt;p&gt;以下是 pseudocode&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    find the B-tree page in the secondary index you want to insert the value to
    assert the B-tree page is latched
    equal-range = the range of records in the secondary index which conflict with your value 
    if(equal-range is not empty){
      release the latches on the B-tree and start a new mini-transaction
      for each record in equal-range
        lock gap before it, and the record itself (this is what LOCK_S does)
      also lock the gap after the last(equal-range)
      also (before Bug #32617942 was fixed) lock the record after last(equal-range)
      once you are done with all of the above, find the B-tree page again and latch it again
    }
    insert the record into the page and release the latch on the B-tree page.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到在二级唯一索引插入record 的时候, 分成了两个阶段&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;判断当前的物理记录上是否有冲突的record(delete-marked 是不冲突)&lt;/li&gt;
  &lt;li&gt;如果没有冲突, 那么可以执行插入操作&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里在阶段1 和 阶段2 之间必须有锁来保证(可以是lock, 也可以是latch), 否则阶段1 判断没有冲突可以插入的时候, 但是在阶段1和阶段2 之间另外一个事务插入了一个冲突的record, 那么阶段2 再插入的时候其实是冲突了.&lt;/p&gt;

&lt;p&gt;所以当前的实现如果gap 上存在至少一个相同的record, 大概率是delete-marked record, 那么需要给整个range 都加上gap X lock, 加了gap X lock 以后就可以禁止其他事务在这个gap 区间插入数据, 也就是通过lock 来保证阶段1和阶段2的原子性.&lt;/p&gt;

&lt;p&gt;如果gap 上没有相同的record, 那么就不需要进任何gap lock.&lt;/p&gt;

&lt;p&gt;比如只包含pk, sk 的一个table.&lt;/p&gt;

&lt;p&gt;已经存在的二级索引记录 &amp;lt;1, 1&amp;gt;, &amp;lt;4, 2&amp;gt;, &amp;lt;10(delete-mark), 3&amp;gt;, &amp;lt;10(d), 8&amp;gt;, &amp;lt;10(d), 11&amp;gt;, &amp;lt;10(d), 21&amp;gt;, &amp;lt;15, 9&amp;gt;  需要插入二级索引&amp;lt;10, 6&amp;gt;, 那么就需要给&amp;lt;10, 3&amp;gt;, &amp;lt;10, 8&amp;gt;,&amp;lt;10,11&amp;gt;,&amp;lt;10,21&amp;gt;, &amp;lt;15, 9&amp;gt; 都加上next-key lock.&lt;/p&gt;

&lt;p&gt;注意: 这里&amp;lt;15, 9&amp;gt;也需要加上next-key lock, 为的是保证像&amp;lt;10, 100&amp;gt; 这样的record 也不允许插入的. 但是如果这里&amp;lt;15, 9&amp;gt; 是&amp;lt;15000, 9&amp;gt; 那么这里被锁住的gap 区间就非常非常大了, 也是上述issue 遇到的问题.&lt;/p&gt;

&lt;p&gt;具体实现在row_ins_scan_sec_index_for_duplicate() 中.&lt;/p&gt;

&lt;p&gt;如果把这个next-key lock 去掉会有什么问题?&lt;/p&gt;

&lt;p&gt;其实官方做过这个改动, 但是这个改动带来了严重的 &lt;a href=&quot;https://bugs.mysql.com/bug.php?id=73170&quot;&gt;bug#73170&lt;/a&gt;, 会导致二级索引的唯一性约束有问题, 出现unique-index 上面出现了相同的record. 所以官方后来快速把这个fix 又revert掉了, 这个问题也就一直没解决了. 为什么会这样呢?&lt;/p&gt;

&lt;p&gt;我们简化一下上述的二级索引, 把(9000, 10, 5) 简化成9000, 因为(10, 5) 都是一样的. 下图是二级索引在page 上的一个简化结构.&lt;/p&gt;

&lt;p&gt;红色表示record 已经被删除, 蓝色表示未被删除.&lt;/p&gt;

&lt;p&gt;那么如果像官方一样把next-key lock 改成 record lock 以后, 如果这个时候插入两个record (99, 13000), (120, 13000).&lt;/p&gt;

&lt;p&gt;第一个record 在unique check 的时候对 (13000, 100), (13000, 102), (13000, 108)..(13000, 112) 所有的二级索引加record S lock, insert 的时候对 (13000, 100) 加GAP | insert_intention lock.&lt;/p&gt;

&lt;p&gt;第二个 record 在unique check 的时候对(13000, 100), (13000, 102), (13000, 108)..(13000, 112) 所有的二级索引加record S lock. insert 的时候对 (13000, 112)加 GAP | inser_intention lock.&lt;/p&gt;

&lt;p&gt;那么这时候这两个record 都可以同时插入成功, 就造成了unique key 约束失效了.&lt;/p&gt;

&lt;p&gt;具体的mtr case 可以看&lt;a href=&quot;https://bugs.mysql.com/bug.php?id=68021&quot;&gt;bug#68021&lt;/a&gt; 上面我写的mtr.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/uPic/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那官方打算如何修复这个问题呢?&lt;/p&gt;

&lt;p&gt;主要是两个思路&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;我们知道InnoDB 的lock 必须遵守2PL 的原则, 也就是这个原因这里next-key lock 用于做Unique check 判断完成以后不能马上释放, 必须等到事务结束才能够释放. 因此官方希望区分真正的用于事务的lock 和 用于Unique check 的lock, 这两种类型的lock 的生命周期应该是不一样的, 前者需要等到事务结束才能够释放, 后者可以在当前STATEMENT 结束以后就可以释放, 当然就像issue 里面Fungo 提出理论上应该昨晚unique check 判断以后就马上释放, STATEMENT这个生命周期还是太大了, 如果在insert into values 场景, 前面的insert 还是影响到后面的insert 了.&lt;/p&gt;

    &lt;p&gt;官方已经在一些地方增加了 lock_duation_t::AT_LEAST_STATEMENT 这个类型, 但是这里麻烦的地方在于InnoDB 的lock 还存在锁继承和锁复用, 比如当前需要申请一个GAP lock 的时候, 当前事务因为unique check 已经有了该GAP lock, 那么这次申请直接返回ture 了, 因为当前的实现默认是所有的lock 都在事务提交的时候一起释放. 但是现在如果unique check 申请的GAP lock 提前释放了, 那么这里就冲突了, 因此锁复用的时候就也需要考虑声明周期了.&lt;/p&gt;

    &lt;p&gt;另外就是锁继承, 如果在gap 中间有record 被purge 或者插入了一个新的record, 那么就继承了一个生命周期是STATEMENT 的场景, unique check 引入的GAP lock 释放的时候该lock 也要释放.&lt;/p&gt;

    &lt;p&gt;这些问题都非常的细碎, 所以官方也在慢慢的修复之中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另外一个思路是通过latch 来做unique check 而不是lock. 我们知道latch 的生命周期远远小于lock, 通常来说latch=short-lived, lock=long-lived, 可以在mtr 提交的时候就可以释放.&lt;/p&gt;

    &lt;p&gt;但是带来的问题是, 如果有大量的delete-marked record, 那么就会覆盖到多个page, 那么mtr 持有的latch 就会很多, 我们知道mtr 是InnoDB Btree 修改的最小单位, 如果mtr 持有的page latch 过多, 那么Btree 的并发性能是必然下降的.&lt;/p&gt;

    &lt;p&gt;另外因为Undo purge 等等操作需要持有page latch 进行, 那么可能造成持有Page latch 的过程中是进行IO 操作, 那么持有latch 的时间肯定较长, 造成unique-check 判断时间过长. 对于latch 的冲突和lock 的冲突处理方式完全不一样, latch 冲突是当前线程等待的方式, lock 冲突以后, 当前事务会进入到事务锁等待, 等冲突的lock 释放以后重新唤醒的过程. 具体可以看&lt;a href=&quot;https://15721.courses.cs.cmu.edu/spring2019/papers/06-indexes/a16-graefe.pdf&quot;&gt;Goetz 的文章&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;其实这也是Fungo 在issue 里面回复的PostgreSQL 的做法, PostgreSQL 在做unique check 的时候对于第一个page 是X latch, 后面的page 通过latch coupling 进行page latch 的持有和释放.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我在 issue 里面也提出我的改法.&lt;/p&gt;

&lt;p&gt;在row_ins_scan_sec_index_for_duplicate() 函数里面将next_key lock 改成record lock, 然后在insert 阶段, 通过将 insert 时候申请的&lt;/p&gt;

&lt;p&gt;LOCK_X | LOCK_GAP | LOCK_INSERT_INTENTION;  改成 =&amp;gt;&lt;/p&gt;

&lt;p&gt;LOCK_X | LOCK_ORDINARY | LOCK_INSERT_INTENTION;&lt;/p&gt;

&lt;p&gt;那么就变成持有record lock, 等待LOCK_ORDINARY | LOCK_INSERT_INTENTION, 那么session2/session3 就会互相冲突, 那么就无法同时插入..&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;insert 的时候为什么要持有LOCK_GAP 而不是 LOCK_ORDINARY ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如原有record 1, 4, 10 需要插入record 6, 7&lt;/p&gt;

&lt;p&gt;那么trx 去抢的都是record 10 的lock, 因为此时6, 7 都还未在btree 中, record 10 是next record..如果加的是10 上面的 LOCK_ORDINARY, 那么两个非常简单的insert 6, 7 就会互相等待死锁了..&lt;/p&gt;

&lt;p&gt;因此只能加LOCK_GAP.&lt;/p&gt;

&lt;p&gt;但是这里对于有可能冲突的SK, 互相死锁则是想要的, 比如如果现有的record&lt;/p&gt;

&lt;p&gt;&amp;lt;1, 1&amp;gt;, &amp;lt;4, 2&amp;gt;, &amp;lt;10(delete-mark), 3&amp;gt;, &amp;lt;10(d), 8&amp;gt;, &amp;lt;10(d), 11&amp;gt;, &amp;lt;10(d), 21&amp;gt;, &amp;lt;15, 9&amp;gt;  需要插入&lt;/p&gt;

&lt;p&gt;trx1: &amp;lt;10, 6&amp;gt;,  trx2: &amp;lt;10,7&amp;gt;&lt;/p&gt;

&lt;p&gt;trx1 先插入成功, 然后是trx2.&lt;/p&gt;

&lt;p&gt;第一步的时候给 &amp;lt;10, 3&amp;gt;&amp;lt;10,8&amp;gt;&amp;lt;10,11&amp;gt;&amp;lt;10,21&amp;gt; 加record s lock.&lt;/p&gt;

&lt;p&gt;插入的时候判断 插入的位置在&amp;lt;10,3&amp;gt;&amp;lt;10,8&amp;gt; 之间, 有10, 那么就可以申请的时候 &amp;lt;10, 8&amp;gt; 的 LOCK_X | LOCK_ORDINARY | insert_intention,   和已经持有record s lock 互相冲突, 已经是死锁了&lt;/p&gt;

&lt;p&gt;如果插入&amp;lt;10,6&amp;gt;&amp;lt;10,9&amp;gt; 也一样&lt;/p&gt;

&lt;p&gt;第一步给所有&amp;lt;10, x&amp;gt; 都加record s lock&lt;/p&gt;

&lt;p&gt;插入的时候,  trx1 申请&amp;lt;10, 8&amp;gt; LOCK_ORDINARY, 持有trx2 想要的&amp;lt;10, 11&amp;gt; record s lock, trx 申请&amp;lt;10, 11&amp;gt; LOCK_X | LOCK_ORDINARY, 持有trx1 想要的&amp;lt;10, 8&amp;gt; record s lock 因此也是互相死锁冲突的.&lt;/p&gt;

&lt;p&gt;最后再拓展一下, primary key 也是unique key index, 为什么primary key 没有这个问题?&lt;/p&gt;

&lt;p&gt;本质原因是在secondary index 里面, 由于mvcc 的存在, 当删除了一个record 以后, 只是把对应的record delete marked, 在插入一个新的record 的时候, delete marked record 是保留的.&lt;/p&gt;

&lt;p&gt;在primary index 里面, 在delete 之后又insert 一个数据, 会将该record delete marked 标记改成non-delete marked, 然后记录一个delete marked 的record 在undo log 里面, 这样如果有历史版本的查询, 会通过mvcc 从undo log 中恢复该数据. 因此不会出现相同的delete mark record 跨多个page 的情况, 也就不会出现上述case 里面(13000, 100) 在page1, (13000, 112) 在page3.&lt;/p&gt;

&lt;p&gt;那么在insert 的时候, 和上面的二级索引插入2阶段类似, 需要有latch 或者lock 进行保护, 这里primary index 通过持有page X latch 就可以保证两个阶段的原子性, 从而两次的insert 不可能同时插入成功, 进而避免了这个问题.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;结论:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在delete + insert, insert … on duplicate key update, replace into 等场景中, 为了实现判断插入记录与现有物理记录是否冲突和插入记录这两个阶段的原子, unique check 的时候会给所有的相同的record 和下一个record 加上next-key lock. 导致后续insert record 虽然没有冲突, 但是还是会被Block 住, 进而有可能造成死锁的问题.&lt;/p&gt;

</description>
        <pubDate>Fri, 22 Apr 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2022/04/22/unique-key-check/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/04/22/unique-key-check/</guid>
      </item>
    
      <item>
        <title>Innodb Physiological Logging</title>
        <description>&lt;p&gt;为什么InnoDB 的redo log 是&lt;strong&gt;Physiological logging&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;有一个存储的同学来问, 如果redo log 是纯physical log 的话, 那么就可以省去double write buffer 的开销, 保证每一次修改都是在4kb以内(由操作系统保证4kb以内的原子操作), 那么就不存在应用redo 到不新不旧的page 上的问题, 就不需要double write buffer.&lt;/p&gt;

&lt;p&gt;目前主要有两种Logical logging and Physical logging.&lt;/p&gt;

&lt;p&gt;Logical logging 像Binlog 这种, 记录的是操作, 跟物理格式无关, 所以通过binlog 可以对接不同的存储引擎.&lt;/p&gt;

&lt;p&gt;Physical logging 是纯物理格式, byte for byte 的记录数据的改动, 比如 [start, end, ‘xxxxx’] 这样的格式内容改动.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Physical logging&lt;/strong&gt; 的优点是高效率, 并且可以直接修改物理格式, 任何操作都不需要重新遍历btree 到指定page.&lt;/p&gt;

&lt;p&gt;但是缺点也很明显, 记录的内容非常冗余, 比如一次delete 操作, logical logging 只需要记录MLOG_COMP_REC_DELETE offset 就可以, 实际执行的过程中会修改prev record-&amp;gt;next_record, next_record-&amp;gt;prev_record, checksum, PAGE_DIR_SLOT_MIN_N_OWNED, 可能还需要更新dir slot 信息等等. 如果改成physical logging 那么这些信息涉及到的内容在page 不同位置, 那么需要记录的日志就非常多了.&lt;/p&gt;

&lt;p&gt;另外在page reorgnize 或者 SMO 场景需要记录大量的无用日志, 比如当一个page 内部有过大量的删除, 有碎片需要整理的时候, 因为需要重新组织page结构, 如果physical logging 那么就需要一个一个record 重新insert 到当前page, offset 需要重新记录, 而logical logging 就只需要记录MLOG_PAGE_REORGANIZE 就可以了. 对比一下16kb 的page 只需要记录几个字节, 而physical logging 需要写差不多16kb 的内容了.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Logical logging&lt;/strong&gt; 的优点是记录非常高效, 如上面说的delete 操作, 只需要记录几个字节, 在SMO, page reorgnize 等场景更加明显.&lt;/p&gt;

&lt;p&gt;但是最大的缺点也很明显, 因为记录的是record_id, 那么所有改动就需要重新遍历btree, 因为都需要对btree 进行修改, 那么就得走加index lock, 串行修改的逻辑. 而物理日志因为page 之前完全没有依赖, 那么就可以并行回放, 这样crash recovery 的效率最高的.&lt;/p&gt;

&lt;p&gt;在&lt;a href=&quot;./https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf&quot;&gt;ARIES&lt;/a&gt; 文章之后, 大部分的商业数据库选择的是”Physiological Logging”,  也就是”physical to a page, logical within a page.”, InnoDB 也是这样, 尽可能将Logocal logging 和 Physical logging 的优点结合在一起.&lt;/p&gt;

&lt;p&gt;记录的redo log 的格式是操作类型, 有些操作类型需要修改record 的话会记录offset. 大量的操作是一些逻辑操作, 比如 MLOG_1BYTE/MLOG_2BYTE/MLOG_INIT_FILE_PAGE 等等.&lt;/p&gt;

&lt;p&gt;对于insert/update/delete 等等操作可以保证到记录到page level, 那么在crash recovery 的时候, 就可以并行的回放日志不需要重新执行btree 遍历找到page逻辑, 从而加快crash recovery.&lt;/p&gt;

&lt;p&gt;当然现在InnoDB 的日志还有一些冗余的地方, PolarDB 也做了一些改进, 比如增加了record 长度信息, 减少了连续mtr 里面page id 记录等等, MariaDB Marko 也一直在优化这块 &lt;a href=&quot;./https://jira.mariadb.org/browse/MDEV-12353&quot;&gt;MDEV-12353&lt;/a&gt;. 整体而言都是为了在page 内部的Logical redo 尽可能高效并且减少冗余.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;C. Mohan, Don Handerle&lt;strong&gt;.&lt;/strong&gt; ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging.&lt;/li&gt;
  &lt;li&gt;C. Mohan, Frank Levine. ARIES/lM: An Efficient and High Concurrency index Management Method Using Write-Ahead Logging.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 10 Apr 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2022/04/10/physiological-log/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/04/10/physiological-log/</guid>
      </item>
    
      <item>
        <title>MySQL InnoDB space file</title>
        <description>&lt;p&gt;InnoDB 最后的数据都会落到文件中.&lt;/p&gt;

&lt;p&gt;整体而言InnoDB 里面除了redo log 以外都使用统一的结构进行管理, 包括system tablespace(ibdata1), user tablespace(用户表空间), undo log, temp tablespace. 这个结构我们统称space file.&lt;/p&gt;

&lt;p&gt;接下来会4篇文章介绍InnoDB 主要的从文件, page, index, record 在具体文件里面是如何分布的, 这里大量引用了Jeremy Cole 里面的图片和文章的内容.&lt;/p&gt;

&lt;p&gt;同时介绍的过程会结合inno_space 工具直观的打印出文件的内部结构.&lt;/p&gt;

&lt;p&gt;什么是inno_space?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;./https://github.com/baotiao/inno_space&quot;&gt;inno_space &lt;/a&gt; 是一个可以直接访问InnoDB 内部文件的命令行工具,  可以打印出文件的内部结构.&lt;/p&gt;

&lt;p&gt;Jeremy Cole 用ruby 写了一个类似的工具, 不过不支持MySQL 8.0, 并且ruby 编译以及改动起来特别麻烦, 所以用cpp 重写了一个. inno_space 做到不依赖任何外部文件, 只需要make, 就可以得到可执行文件, 做到开箱即用.&lt;/p&gt;

&lt;p&gt;inno_space 除了支持打印出文件的具体结构之外, 同时还支持修复 corrupt page 功能, 如果遇到InnoDB 表文件中的page 损坏, 实例无法启动的情况, 如果损坏的只是leaf page, inno_space 可以将corrupt page 跳过, 从而保证实例能够启动, 并且将绝大部分的数据找回.&lt;/p&gt;

&lt;p&gt;inno_space 还提供分析表文件中的数据情况, 是否有过多的free page, 从而给用户建议是否需要执行 optimize table 等等&lt;/p&gt;

&lt;p&gt;具体可以看代码, 在github 上面开源: https://github.com/baotiao/inno_space/commits/main&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;InnoDB space file 也就是整个InnoDB 文件系统的管理, 介绍.ibd 文件的基础结构. &lt;a href=&quot;./InnoDB space file.md&quot;&gt;InnoDB space file&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;InnoDB page management  具体的在InnoDB file space 这些16kb 大小的page 是如何管理的 &lt;a href=&quot;./InnoDB page management.md&quot;&gt;Page management&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;InnoDB Index page 上面讲了这16kb 的page 如何管理, 那么我们细看一下最常见的page 类型, Index Page 存的是用户表空间的数据,  这些Index Page 是如何维护成一个table 的数据 &lt;a href=&quot;./InnoDB Index page.md&quot;&gt;Index page&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;InnoDB record 是具体在InnoDB page 里面, Mysql 里面的record 是如何保存在InnoDB page 里面的 &lt;a href=&quot;./InnoDB record.md&quot;&gt;InnoDB record&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这篇文章只描述InnoDB file space, 接下来会有文章介绍InnoDB page management,  InnoDB page, InnoDB record&lt;/p&gt;

&lt;h4 id=&quot;1-innodb-space-file-基本结构&quot;&gt;1. InnoDB space file 基本结构&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Page&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在InnoDB 里面, 16kb 大小的page 是最小的原子单元&lt;/p&gt;

&lt;p&gt;其他的大小都是在page 之上, 因此有:&lt;/p&gt;

&lt;p&gt;1 page = 16kB = 16384 bytes&lt;/p&gt;

&lt;p&gt;1 extent = 64 pages = 1 MB&lt;/p&gt;

&lt;p&gt;FSP_HDR  page = 256 extents = 16384 pages = 256 MB&lt;/p&gt;

&lt;p&gt;page 有最基础的38字节的 FIL Header, 8字节的FIL Trailer&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/NxR6eb3.jpg&quot; alt=&quot;Imgur&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要的内容包括:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Checksum: 这个page 的checksum, 用来判断page 是否有corrupt&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Page Number: Page Number 可以计算出在文件上的偏移量, 一个page 是否初始化了, 也可以看这个page number 是否设置对了, 这个值其实是冗余的, 根据file offset 可以算出来, 所以这个值是否正确, 就可以知道这个page 是否被初始化了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Previous Page/Next Page: 这个只有在Index page 的时候才有用, 而且只有leaf page 的时候才有用, non-leaf page 是没用的, 大部分类型的page 并没有使用这个字段.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LSN for last page modification: 刷脏的时候, 写入这个page 的 newest_modification_lsn&lt;/p&gt;

    &lt;p&gt;​	mach_write_to_8(page + FIL_PAGE_LSN, newest_lsn);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Page Type: 这个page 具体的类型, 比如是btree index leaf-page, undo log page,  btree index non-leaf page, insert buffer, fresh allocated page, 属于ibdata1 的system page 等等. Page Type 最重要, 决定这个page 的用途类型, 里面很多字段就不一样了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Flush LSN:  保存的是已经flush 到磁盘的page 的最大lsn 信息. 只有在space 0 page 0 这个page 里面有用, 其他地方都没用.. 什么用途?什么时候写入? 什么时候读取?&lt;/p&gt;

    &lt;p&gt;在进行shutdown 的时候, 或者执行force checkpoint的时候通过 fil_write_flushed_lsn_to_data_files 写入.&lt;/p&gt;

    &lt;p&gt;用途是在启动的时候, 读取这个flush lsn, 可以确保这个lsn 之前的page 已经刷到磁盘了, 从这个flush lsn 之后的redo log 才是uncheckpoint redo log, 但是其实redo log 里面已经有了 checkpoint 的信息了, 为何还需要这个字段?&lt;/p&gt;

    &lt;p&gt;logs_empty_and_mark_files_at_shutdown =&amp;gt;&lt;/p&gt;

    &lt;p&gt;在实例启动的时候, innobase_start_or_create_for_mysql =&amp;gt; open_or_create_data_files =&amp;gt; fil_read_first_page&lt;/p&gt;

    &lt;p&gt;fil_read_first_page 里面会读取出这个lsn 信息, 用于更新启动的时候的 min_flushed_lsn, max_flushed_lsn. 因为这个时候redo log 模块还没有初始化,  可以拿这个两个Lsn 做一些简单的判断&lt;/p&gt;

    &lt;p&gt;整体来看, 这个字段目前已经没啥用了, 但是每一个page 都占用了8字节的空间, 还是比较浪费, 可以充分复用&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Space ID: 当前Page 所属space ID (8.0 里面已经将该字段删除了)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过inno_space 可以看到相应的结构:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./inno -f ~/git/primary/dbs2250/sbtest/sbtest1.ibd -p 10

==========================block==========================
FIL Header:
CheckSum: 2065869235
Page number: 10
Previous Page: 9
Next Page: 11
Page LSN: 554513658770
Page Type: 17855
Flush LSN: 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Space file&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个space file 就是2^32 个page 的合集, 连续64个page 叫做extent, 256个连续的extent 会有一个XDES(extent descriptor) 进行管理, 第一个XDES 又叫做FSP_HDR, 还有一些额外的信息.&lt;/p&gt;

&lt;p&gt;下图就是这个基本文件组织结构的描述, 无论是undo space, system space, 用户的table space 都是这样结构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../../Library/Application Support/typora-user-images/image-20211118052832966.png&quot; alt=&quot;image-20211118052832966&quot; style=&quot;zoom:40%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所有的space file 前3个page 都是一样.&lt;/p&gt;

&lt;p&gt;page 0 是 FSP_HDR(file space header)&lt;/p&gt;

&lt;p&gt;page 1 是 insert buffer bitmap&lt;/p&gt;

&lt;p&gt;page 2 是 inode page, 下一节会介绍&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The system space&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;system space 的space id = 0, 文件名叫 ibdata1, 也就是系统文件.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/l3UHMqR.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;page 0, 1, 2 这3个page 所有的space file 都一样&lt;/p&gt;

&lt;p&gt;在system space 里面接下来的3, 4, 5 等等page 也都是有指定的用途&lt;/p&gt;

&lt;p&gt;page 3 存放的是insert buffer 相关信息&lt;/p&gt;

&lt;p&gt;page 4 存放的是insert buffer tree 的root page&lt;/p&gt;

&lt;p&gt;page 5 存放的是trx_sys 模块相关信息, 比如最新的trx id, binlog 信息等等.&lt;/p&gt;

&lt;p&gt;page 6 存放的是FSP_FIRST_RSEG_PAGE_NO, 也就是undo log rollback segment的header page. 其他的undo log rollback segment 都在不同的undo log 文件中&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ScLs3Oj.jpg&quot; alt=&quot;Imgur&quot; style=&quot;zoom:40%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;page 7 存放的是 FSP_DICT_HDR_PAGE_NO, 存放的是DD 相关的信息&lt;/p&gt;

&lt;p&gt;page 64-127 是first 64 个double write buffer 的位置&lt;/p&gt;

&lt;p&gt;page 128-191 是second 64个double write buffer 的位置&lt;/p&gt;

&lt;p&gt;剩下的其他page 就有可能被申请成Undo log page 等等了&lt;/p&gt;

&lt;p&gt;通过inno_space 打开 ibdata1文件可以观察到如下的信息&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;File path /home/zongzhi.czz/git/primary/log2250/ibdata1 path
File size 209715200
start           end             count           type
0               0               1               FSP HDR
1               1               1               INSERT BUFFER BITMAP
2               2               1               INDEX NODE PAGE
3               3               1               SYSTEM PAGE
4               4               1               INDEX PAGE
5               5               1               TRX SYSTEM PAGE
6               7               2               SYSTEM PAGE
8               8               1               SDI INDEX PAGE
9               12799           12790           FRESHLY ALLOCATED PAGE
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;打开一个普通的用户表空间, 可以看到如下的结构.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;└─[$] ./inno -f ~/git/primary/dbs2250/sbtest/sbtest1.ibd -c list-page-type
File path /home/zongzhi.czz/git/primary/dbs2250/sbtest/sbtest1.ibd path, page num 0
page num 0
==========================space page type==========================
File size 2604662784
start           end             count           type
0               0               1               FSP HDR
1               1               1               INSERT BUFFER BITMAP
2               2               1               INDEX NODE PAGE
3               3               1               SDI INDEX PAGE
4               16383           16380           INDEX PAGE
16384           16384           1               XDES
16385           16385           1               INSERT BUFFER BITMAP
16386           31990           15605           INDEX PAGE
31991           31999           9               FRESHLY ALLOCATED PAGE
32000           32767           768             INDEX PAGE
32768           32768           1               XDES
32769           32769           1               INSERT BUFFER BITMAP
32770           49151           16382           INDEX PAGE
49152           49152           1               XDES
49153           49153           1               INSERT BUFFER BITMAP
49154           65535           16382           INDEX PAGE
65536           65536           1               XDES
65537           65537           1               INSERT BUFFER BITMAP
65538           81919           16382           INDEX PAGE
81920           81920           1               XDES
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下一篇物理页管理我们会更详细的介绍.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;File Per Table&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;InnoDB 常见的file per table 模式下. 一个table 对应一个.ibd 文件.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/I2vFSGn.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;page 0, 1, 2 这3个page 所有的space file 都一样&lt;/p&gt;

&lt;p&gt;page 3 一般是 primary index root page.&lt;/p&gt;

&lt;p&gt;page 4 一般是 secondary index root page. 当然这里是create table 就指定的时候, 比如如下 page 4 一般是k_1 这个index 的root page&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;Create Table: CREATE TABLE `sbtest1` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `k` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `c` char(120) NOT NULL DEFAULT &apos;&apos;,
  `pad` char(60) NOT NULL DEFAULT &apos;&apos;,
  PRIMARY KEY (`id`),
  KEY `k_1` (`k`)
) ENGINE=InnoDB AUTO_INCREMENT=237723 DEFAULT CHARSET=latin1
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果后面运行过程中再加的新的 secondary index, 新的Index的root page 那就不会是连续着的, 而是分散在其他page 上了&lt;/p&gt;

&lt;p&gt;alter table sbtest1 add index idx_c(c);&lt;/p&gt;

&lt;p&gt;比如执行alter table 以后, 额外增加的一个index, 通过inno_space 工具可以看到每一个index 的root page 所在等等&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Example 2:
./inno -f ~/git/primary/dbs2250/sbtest/sbtest1.ibd -c index-summary
File path /home/zongzhi.czz/git/primary/dbs2250/sbtest/sbtest1.ibd path, page num 0
==========================Space Header==========================
Space ID: 15
Highest Page number: 158976
Free limit Page Number: 152256
FREE_FRAG page number: 24
Next Seg ID: 7
File size 2604662784
========Primary index========
Primary index root page space_id 15 page_no 4
Btree hight: 2
&amp;lt;&amp;lt;&amp;lt;Leaf page segment&amp;gt;&amp;gt;&amp;gt;
SEGMENT id 4, space id 15
Extents information:
FULL extent list size 2140
FREE extent list size 0
PARTIALLY FREE extent list size 1
Pages information:
Reserved page num: 137056
Used page num: 137003
Free page num: 53

&amp;lt;&amp;lt;&amp;lt;Non-Leaf page segment&amp;gt;&amp;gt;&amp;gt;
SEGMENT id 3, space id 15
Extents information:
FULL extent list size 1
FREE extent list size 0
PARTIALLY FREE extent list size 1
Pages information:
Reserved page num: 160
Used page num: 116
Free page num: 44

========Secondary index========
Secondary index root page space_id 15 page_no 31940
Btree hight: 2
&amp;lt;&amp;lt;&amp;lt;Leaf page segment&amp;gt;&amp;gt;&amp;gt;
SEGMENT id 6, space id 15
Extents information:
FULL extent list size 7
FREE extent list size 0
PARTIALLY FREE extent list size 219
Pages information:
Reserved page num: 14465
Used page num: 12160
Free page num: 2305

&amp;lt;&amp;lt;&amp;lt;Non-Leaf page segment&amp;gt;&amp;gt;&amp;gt;
SEGMENT id 5, space id 15
Extents information:
FULL extent list size 0
FREE extent list size 0
PARTIALLY FREE extent list size 0
Pages information:
Reserved page num: 19
Used page num: 19
Free page num: 0

**Suggestion**
File size 2604662784, reserved but not used space 39354368, percentage 1.51%
Optimize table will get new fie size 2565308416

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;这里tablespace id 是15&lt;/li&gt;
  &lt;li&gt;Btree 的高度是3层&lt;/li&gt;
  &lt;li&gt;secondary Index 由于只存索引, 所以primary index 占用的空间是secondary index 的10倍&lt;/li&gt;
  &lt;li&gt;primary Index 上面大量的page 都是用满的状态, 而secondary 会20% 左右的空闲page&lt;/li&gt;
  &lt;li&gt;整体而言, 空闲page 只占了文件的1.51% 左右, 所以不需要做optimize table 操作的&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Mon, 29 Nov 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2021/11/29/inno-space/</link>
        <guid isPermaLink="true">http://localhost:4000/2021/11/29/inno-space/</guid>
      </item>
    
      <item>
        <title>MySQL Repeatable-Read 的一些误解</title>
        <description>&lt;h5 id=&quot;背景&quot;&gt;背景&lt;/h5&gt;

&lt;p&gt;首先1992 年发表的SQL Standard 对隔离级别进行的定义是根据几个异象(Dirty Read, Non-Repeatable Read, Phantom Read) , 当然这个定义非常模糊, 后面Jim Grey 也有文章说这个不合理, 然而此时MVCC, snapshot isolation 还没被发明. 等有snapshot isolation 以后发现snapshot isolation 能够规避Dirty Read, Non-Repeatable Read, 因此认为snapshot isolation 和 Repeatable-read 很像, 所以MySQL, Pg 把他们实现的snapshot isolation 就称为了Repeatable-read isolation.&lt;/p&gt;

&lt;p&gt;另外snapshot isolation 其实也没有准确的定义, 因此MySQL 和 PG, Oracle 等等的实现也是有很大的区别的.&lt;/p&gt;

&lt;p&gt;关于&lt;strong&gt;snapshot isolation&lt;/strong&gt; 的定义:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A transaction running in Snapshot Isolation is never blocked attempting a read as long as the snapshot data from its Start-Timestamp can be maintained.The transaction’s writes (updates, inserts, and deletes) will also be reflected in this snapshot, to be read again if the transaction accesses (i.e., reads or updates) the data a second time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里对于snapshot isolation 的定义不论对于读操作和写操作都是读取snapshot 的版本, 这也是pg, oracle 等等版本实现的, 但是InnoDB 不是这样的. InnoDB 只有读操作读取到的是snapshot 的版本, 但是DML 操作是读取当前已提交的最新版本.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;When the transaction T1 is ready to commit, it gets a &lt;em&gt;Commit-Timestamp,&lt;/em&gt; which is larger than any existing Start-Timestamp or Commit-Timestamp. The transaction successfully commits only if no other transaction T2 with a Commit-Timestamp in T1’s &lt;em&gt;execution interval&lt;/em&gt; [&lt;em&gt;Start- Timestamp&lt;/em&gt;, &lt;em&gt;Commit-Timestamp&lt;/em&gt;] wrote data that T1 also wrote. Otherwise, T1 will abort. This feature, called &lt;em&gt;First- committer-wins&lt;/em&gt; prevents lost updates (phenomenon P4).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于 first-committer-wins 的定义, 在si 模式下, 如果在Start-Timestamp -&amp;gt; Commit-Timestamp 这之间如果有其他的trx2 修改了当前trx1 修改过的内容, 并且在trx1 提交的时候, trx2 已经提交了. 那么trx1 就会abort, 这个叫first-committer-wins.&lt;/p&gt;

&lt;p&gt;但是InnoDB 也不是这样的. InnoDB 并不遵守这个规则, 在repeatable read 模式下, 如果trx1, trx2 都修改了同一行, trx2 是先提交的, 那么trx1 的提交会直接把trx2 覆盖. 而在类似PG, Oracle 实现的snapshot isolation 里面, 则是遵守first-committer-wins 的规则.&lt;/p&gt;

&lt;p&gt;所以InnoDB 的snapshot isolation&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;仅仅Read 操作读的是历史版本&lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;不遵守first-committer-wins 规则&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;官方把这种实现叫做&lt;strong&gt;Write committed Repeatable Read&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;MySQL 开发者对于InnoDB repeatable-read 实现的介绍:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;But when InnoDB Repeatable Read transactions modify the database, it is possible to get phantom reads added into the static view of the database, just as the ANSI description allows.  Moreover, InnoDB relaxes the ANSI description for Repeatable Read isolation in that it will also allow non-repeatable reads during an UPDATE or DELETE.  Specifically, it will write to newly committed records within its read view.  And because of gap locking, it will actually wait on other transactions that have pending records that may become committed within its read view.  So not only is an UPDATE or DELETE affected by pending or newly committed records that satisfy the predicate, but also ‘SELECT … LOCK IN SHARE MODE’ and ‘SELECT … FOR UPDATE’.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;This WRITE COMMITTED implementation of REPEATABLE READ is not typical of any other database that I am aware of.  But it has some real advantages over a standard ‘Snapshot’ isolation.  When an update conflict would occur in other database engines that implement a snapshot isolation for Repeatable Read, an error message would typically say that you need to restart your transaction in order to see the current data. So the normal activity would be to restart the entire transaction and do the same changes over again.  But InnoDB allows you to just keep going with the current transaction by waiting on other records which might join your view of the data and including them on the fly when the UPDATE or DELETE is done.  This WRITE COMMITTED implementation combined with implicit record and gap locking actually adds a serializable component to Repeatable Read isolation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PG 社区对于repeatable-read 实现的介绍:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UPDATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELETE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT FOR UPDATE&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT FOR SHARE&lt;/code&gt; commands behave the same as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; in terms of searching for target rows: they will only find target rows that were committed as of the transaction start time. However, such a target row might have already been updated (or deleted or locked) by another concurrent transaction by the time it is found. In this case, the repeatable read transaction will wait for the first updating transaction to commit or roll back (if it is still in progress). If the first updater rolls back, then its effects are negated and the repeatable read transaction can proceed with updating the originally found row. But if the first updater commits (and actually updated or deleted the row, not just locked it) then the repeatable read transaction will be rolled back with the message&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;https://www.postgresql.org/docs/13/transaction-iso.html#XACT-READ-COMMITTED&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以这里我们看一下MySQL repeatable-read 的具体行为, 也了解MySQL社区为什么要做这样的实现.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;mysql&amp;gt; create table checking (name char(20) key, balance int) engine InnoDB;
Query OK, 0 rows affected (0.03 sec)

mysql&amp;gt; insert into checking values (&quot;Tom&quot;, 1000), (&quot;Dick&quot;, 2000), (&quot;John&quot;, 1500);
Query OK, 3 rows affected (0.00 sec)
Records: 3  Duplicates: 0  Warnings: 0

Client #1                               Client #2
=====================================   =====================================
mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from checking;
+------+---------+
| name | balance |
+------+---------+
| Dick |    2000 |
| John |    1500 |
| Tom  |    1000 |
+------+---------+
3 rows in set (0.00 sec)

mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; update checking
   set balance = balance - 250
   where name = &quot;Dick&quot;;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; update checking
   set balance = balance + 250
   where name = &quot;Tom&quot;;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; select * from checking;
+------+---------+
| name | balance |
+------+---------+
| Dick |    1750 |
| John |    1500 |
| Tom  |    1250 |
+------+---------+
3 rows in set (0.02 sec)
                                        mysql&amp;gt; begin;
                                        Query OK, 0 rows affected (0.00 sec)

                                        mysql&amp;gt; select * from checking;
                                        +------+---------+
                                        | name | balance |
                                        +------+---------+
                                        | Dick |    2000 |
                                        | John |    1500 |
                                        | Tom  |    1000 |
                                        +------+---------+
                                        3 rows in set (0.00 sec)
																				
                                        mysql&amp;gt; update checking
                                           set balance = balance - 200
                                           where name = &quot;John&quot;;
                                        Query OK, 1 row affected (0.00 sec)
                                        Rows matched: 1  Changed: 1  Warnings: 0
																				
                                        mysql&amp;gt; update checking
                                           set balance = balance + 200
                                           where name = &quot;Tom&quot;;

                                        ### Client 2 waits on the locked record
mysql&amp;gt; commit;
Query OK, 0 rows affected (0.00 sec)
                                        Query OK, 1 row affected (19.34 sec)
                                        Rows matched: 1  Changed: 1  Warnings: 0
mysql&amp;gt; select * from checking;
+------+---------+
| name | balance |
+------+---------+
| Dick |    1750 |
| John |    1500 |
| Tom  |    1250 |
+------+---------+
3 rows in set (0.00 sec)
                                        mysql&amp;gt; select * from checking;
                                        +------+---------+
                                        | name | balance |
                                        +------+---------+
                                        | Dick |    2000 |
                                        | John |    1300 | 
                                        | Tom  |    1450 |
                                        +------+---------+
                                        3 rows in set (0.00 sec)

                                      # 这里可以看到Tom = 1450, 而不是从上面 1000 + 200 = 1200, 
                                      # 因为update 的时候, InnoDB 实现的是write-committed repeatable, 
                                      # 不是基于场景的snapshot isolation的实现, 
                                      # write 操作是直接读取的已提交的最新版本的数据1250, 
                                      # 而不是snapshot 中的数据1000.
																				
                                        mysql&amp;gt; commit;
                                        Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from checking;
+------+---------+
| name | balance |
+------+---------+
| Dick |    1750 |
| John |    1300 |
| Tom  |    1450 |
+------+---------+
3 rows in set (0.02 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里可以看到Tom = 1450, 而不是从上面 1000 + 200 = 1200, 因为update 的时候, InnoDB 实现的是write-committed repeatable, 不是基于场景的snapshot isolation的实现, write 操作是直接读取的已提交的最新版本的数据1250, 而不是snapshot 中的数据1000.&lt;/p&gt;

&lt;p&gt;对比在PG里面, 由于PG是使用常见的 snapshot isolation 实现repeatable-read, 那么trx2 在修改Tom 的时候, 同样必须等待trx1 commit or rollback, 因为PG 读取和修改基于trx 开始时候的snapshot 的record. 因此如果trx1 rollback, 那么trx2 则会基于开始snapshot 时候的值进行修改, 也就是Tom = 1200, 如果trx1 commit, 那么trx2 只能rollback, 并且会返回&lt;/p&gt;

&lt;p&gt;ERROR:  could not serialize access due to concurrent update&lt;/p&gt;

&lt;p&gt;也就是在上面的场景下 trx2 是会rollback.&lt;/p&gt;

&lt;p&gt;那么MySQL 为什么要这么做呢?&lt;/p&gt;

&lt;p&gt;MySQL 社区的观点是在常见的通过snapshot isolation 来实现repeatable Read 的方案里面, 经常会出现如果两个事务修改了同一个record, 那么就需要后提交的事务重试这个流程. 这种在小事务场景是可以接受的, 但是如果后提交的事务是大事务, 比如trx1 修改了1个record rec1并先提交了, 但是trx2 修改了100 行, 正好包含了rec1, 那么常见的snapshot isolation 的实现就需要trx2 返回错误, 然后重新执行这个事务. 这样对冲突多的场景是特别不友好的.&lt;/p&gt;

&lt;p&gt;但是Innodb 的实现则在修改rec1 的时候, 如果trx1 已经提交了, 那么直接读取trx1 committed 的结果, 这样就可以避免了让trx2 重试的过程了. 也可以达到几乎一样的效果.&lt;/p&gt;

&lt;p&gt;当然这个仅仅MySQL InnoDB 是这样的实现, 其他的数据库都不会这样.&lt;/p&gt;

&lt;p&gt;两种方案都有优缺点吧, 基于常见SI(snapshot isolation) 实现会存在更多的事务回滚, 一旦两个事务修改了同一个row, 那么必然有一个事务需要回滚, 但是InnoDB 的行为可以允许和其他trx 修改同一个record, 并且可以在其他trx 修改后的结果上进行更新, 不需要进行事务回滚, 效率会更高一些, 但是基于常见的snapshot isolation 的实现更符合直观感受.&lt;/p&gt;
</description>
        <pubDate>Fri, 20 Aug 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2021/08/20/innodb-snapshot-isolation/</link>
        <guid isPermaLink="true">http://localhost:4000/2021/08/20/innodb-snapshot-isolation/</guid>
      </item>
    
      <item>
        <title>路在脚下, 从BTree 到Polar Index</title>
        <description>&lt;p&gt;上一篇文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/151397269&quot;&gt;InnoDB BTree latch 优化历程&lt;/a&gt; 介绍了 InnoDB 的BTree latch 的优化历程, 我们知道在InnoDB 里面, 依然有一个全局的index latch, 由于全局的index latch 存在会导致同一时刻在Btree 中只有一个SMO 能够发生, index latch 依然会成为全局的瓶颈点, 导致在大批量插入场景, 比如TPCC 的场景中, 性能无法提高. 在MySQL 的官方性能测试人员Dimitrick 的&lt;a href=&quot;http://dimitrik.free.fr/blog/posts/mysql-80-tpcc-mystery.html&quot;&gt;MySQL Performance : TPCC “Mystery” [SOLVED]&lt;/a&gt; 中也可以看到, index lock contention 是最大的瓶颈点.&lt;/p&gt;

&lt;p&gt;在这之前, 我们进行了大量的探索和验证, 在这个&lt;a href=&quot;./https://zhuanlan.zhihu.com/p/50112182&quot;&gt;POLARDB · B+树并发控制机制的前世今生&lt;/a&gt; 和 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/50630867&quot;&gt;POLARDB · 敢问路在何方 — 论B+树索引的演进方向&lt;/a&gt; 中,  我们对比了blink-tree, bw-tree, masstree 等等, 其实学术界更多的探索在简单的场景中进行lock free, 多线程, 针对硬件相关的优化, 但是在实际工程中, MySQL 的索引结构已经不是一个简单的Btree, 它是和MySQL 的事务锁模块强绑定, 同时他还需要支持不仅仅是前序遍历, 还需要支持 modify_prev/search_prev, 需要对non-leaf node 进行加锁操作. 因此在MySQL 中的Btree 的修改就不仅仅是涉及到btree 子模块, 还需要涉及undo log, 事务子模块等等.&lt;/p&gt;

&lt;p&gt;因此PolarDB 提出来High Performance Polar Index 解决这个问题, 从而在我们某一个线上业务的实际场景中, 性能能够有3倍的提升, 在TPCC 场景下更是能够有有11倍的性能提升..&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/img/20210521014602.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;那Polar Index 的本质是什么, 如何实现的呢?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先再来回顾一下InnoDB SMO的加锁流程（简化起见，假设本次SMO只需分裂leaf page）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对全局index-&amp;gt;lock加SX锁&lt;/li&gt;
  &lt;li&gt;从root page开始，以不加锁的方式向下遍历non-leaf pages至level 2&lt;/li&gt;
  &lt;li&gt;对level 1的non-leaf page加X锁&lt;/li&gt;
  &lt;li&gt;对level 0的leaf page及其left、right page加X锁，完成leaf page的SMO&lt;/li&gt;
  &lt;li&gt;从root page开始，以不加锁的方式向下遍历至leaf page的parent&lt;/li&gt;
  &lt;li&gt;向parent page插入SMO中对应指向new page的nodeptr&lt;/li&gt;
  &lt;li&gt;释放所有锁，SMO结束&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里可以看到有下面2个瓶颈点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对于单个SMO来说，参与SMO的leaf pages及其parent page的X锁会从一开始加着直到SMO结束，这样的加锁粒度有些大，其实SMO也是分层、从下到上依次操作的，如上面流程中：步骤4先在level 0对leaf page做分裂，然后再在步骤5向parent page插入指向new page的nodeptr，但其实在做步骤4的时候没必要先加着parent page X锁，同样再步骤5中也没必要还占着leaf pages X锁，这个问题在级联SMO场景（leaf page分裂引发其路径上多个non-leaf pages分裂）更为明显，这样在读写混合场景下，SMO路径上的读性能会受影响&lt;/li&gt;
  &lt;li&gt;虽然SMO对index-&amp;gt;lock加了SX锁，可以允许其他非SMO操作并发进来，但SX之间还是互斥的，也就是说多个SMO并不能并发，即使它们之间完全没有page交集，这样在高并发大写入压力下（剧烈触发SMO）性能不理想&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;这些瓶颈点在Polar Index是如何解决的?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;原先BTree 之所以需要持有Index latch 的原因是正常的搜索顺序是保证严格的自上而下, 自左向右, 但是SMO 操作由于需要保持对BTree 修改的原子性, 不能让其他线程访问到BTree 的中间状态, 因此需要持有叶子加点去加父节点的latch, 因此SMO 操作出现了自下而上的加锁操作, 在编程实现中, 一旦出现了多个线程无法遵守同一严格的加锁顺序, 那么死锁就无法避免, 为了避免这样的冲突InnoDB 通过将整个BTree index latch, 从而SMO 的时候, 不会有搜索操作进行.&lt;/p&gt;

&lt;p&gt;Polar Index 的核心想法是把 SMO 操作分成了两个阶段.&lt;/p&gt;

&lt;p&gt;在Polar Index 中每一个node 包含有一个link page 指针, 指向他的node.  以及fence key 记录的是link page 的最小值.&lt;/p&gt;

&lt;p&gt;比如split 阶段&lt;/p&gt;

&lt;p&gt;阶段1: 将一个page 进行split 操作,  然后建立一个link 连接在两个page 之间. 下图Polar Index 就是这样的状态&lt;/p&gt;

&lt;p&gt;阶段2: 给父节点添加一个指针, 从父节点指向新创建的page.&lt;/p&gt;

&lt;p&gt;当然还可以有一个阶段3 将两个page 之间的link 指针去掉.&lt;/p&gt;

&lt;p&gt;在Polar Index 中, 阶段1 和阶段2 的中间状态我们也认为是合理状态, 如果这个阶段实例crash, 那么在crash recovery 阶段可以识别当前page 有Link page, 那么会将SMO 的下一个阶段继续完成, 从而保证BTree 的完整性.&lt;/p&gt;

&lt;p&gt;这样带来的优点是在SMO 的过程中, 由于允许中间状态是合法状态, 那么就不需要为了防止出现中间状态的出现而需要持有叶子节点加父节点latch 的过程. 因此就避免的自下而上的加锁操作, 从而就不需要Index latch.&lt;/p&gt;

&lt;p&gt;如下图对比BTree 和 Polar Index.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/img/20210521014742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在去掉Index latch 之后, 通过latch coupling 从而保证每一次的修改都只需要在btree 的某一层加latch, 从而最大的减少了latch 的粒度.&lt;/p&gt;

&lt;p&gt;如下是具体执行right split 的过程:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/baotiao/bb/main/img/20210521014719.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;带来的收益是:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;降低SMO的page加锁粒度，当前修改哪一层，就只对这一层相关的page加X锁，并且修改完之后立刻放锁再去修改其他层，这样读写并发就上来了。这样的做法要解决的问题就是：&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;对leaf page做完分裂之后，放锁放锁去修改parent，那么已经迁移到new page上的数据怎么被其他线程访问到呢？&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;这里Polar Index采用了类似Blink tree的做法，给分裂的leaf page设置一个high key，这个值为new page上最小的rec，这样如果leaf page放X锁之后，从parent下来的其他读操作检测到这个high key之后，就知道如果要查找的目标rec在当前leaf page没找到并且大于等于high key的话，就去next page（也就是new page）上查找。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;去掉全局index-&amp;gt;lock，正常的读写及SMO不对index-&amp;gt;lock加任何锁，这样写并发就能上来了。不过在具体实现中，不是简单的删掉代码那么容易，要解决去掉它之后各种各样的问题：&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;遍历BTree的加锁方式&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;InnoDB在普通读、写操作时遍历BTree的方式：是从root page开始，将路径上所有non-leaf pages加S锁，然后占着S锁去加目标leaf page的X锁，加到之后释放non-leaf pages的S锁；在SMO是遍历BTree的方式是前面流程中的步骤2。当我们去掉index-&amp;gt;lock，允许多个SMO并发起来，显然SMO的遍历方式是有问题的，因为在第一遍以无锁方式遍历BTree找到所有需要加X锁的page到第二遍遍历真正对这些page加锁之间，可能其他SMO已经修改了BTree结构。所以我们将遍历方式统一改成lock coupling，同时最多占2层page锁，这样做的好处是不管是普通读、写还是SMO操作，在遍历BTree时对non-leaf pages的加锁区间都很小，进一步提高并发&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;除此之外，在具体实现中，还要解决大量问题，比如：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;多个SMO之间有重叠的pages，如何解决冲突，避免死锁&lt;/li&gt;
    &lt;li&gt;对于左分裂、左合并这种右-&amp;gt;左的加锁，如何避免死锁&lt;/li&gt;
    &lt;li&gt;对于non-leaf page删除leftmost rec而触发其parent的级联删除如何处理&lt;/li&gt;
    &lt;li&gt;… …&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在InnoDB 里面, 依然有一个全局的Index latch, 由于全局的Index latch 存在会导致同一时刻在Btree 中只有一个SMO 能够发生, 从而导致性能无法提升.&lt;/p&gt;

&lt;p&gt;Polar Index 通过将SMO 操作分成两个阶段, 并保证中间状态的合理性, 从而避免了Index latch. 从而保证任意时刻在BTree 中只会持有一层latch, 从而实现性能极大提升.&lt;/p&gt;
</description>
        <pubDate>Fri, 21 May 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2021/05/21/polar-index/</link>
        <guid isPermaLink="true">http://localhost:4000/2021/05/21/polar-index/</guid>
      </item>
    
      <item>
        <title>WorkLog InnoDB Faster truncate/drop table space</title>
        <description>&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在InnoDB 现有的版本里面, 如果一个table space 被truncated 或者 drop 的时候, 比如有一个连接创建了临时表, 连接断开以后, 对应的临时表都需要进行drop 操作.&lt;/p&gt;

&lt;p&gt;InnoDB 是需要将该tablespace 对应的所有的page 从LRU/FLUSH list 中删除, 如果没有这个操作, 新的table 的table spaceid 如果重复的话, 那么就可能访问到脏数据.&lt;/p&gt;

&lt;p&gt;为了将这些page 删除, 那么就需要全部遍历LRU/FLUSH list, 当bp 特别大的时候, 这样遍历的开销是很大的, 并且无论这个要删除的table 有多大, 都需要将这些LRU/FLUSH list 全部遍历..&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解决方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;解决方法和之前解决undo ACID DDL 的方法类似, 核心思想就是&lt;strong&gt;通过引用计数的方法, 对table_space 加reference, 然后后续lazy delete&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;bp 上的每一个page 都有自己对应的version, 当table space 被drop/rename 的时候, 只需要对fil_space 的version + 1, 那么bp 中该fil_space 对应的page 就因为version &amp;lt; fil_space.current_version 而变得无效.&lt;/p&gt;

&lt;p&gt;原先由drop/rename tablespace 触发的space_delete 操作就变的非常的轻量. 后续定期的将这些stable page 删除或者复用即可&lt;/p&gt;

&lt;p&gt;不过带来的额外开销就是, 每一次访问bp 中的一个page 就需要确认当前page 是否过期.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;具体实现&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;buf_page_t 增加 m_space, m_version.&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Additions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf_page_t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// 指向对应的fil_space_t&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;fil_space_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;

 &lt;span class=&quot;c1&quot;&gt;// Version number of the page to check for stale pages. This value is&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// &quot;inherited&quot; from the m_space-&amp;gt;m_version when we init a page.&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// page 的version number, 在page_init 的时候设置成m_space-&amp;gt;m_version&lt;/span&gt;
 &lt;span class=&quot;kt&quot;&gt;uint32_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fil_space_t 增加m_version,  m_n_ref_count.&lt;/p&gt;

&lt;p&gt;m_version 就是当前fil_space_t 的版本号, 每次delete/truncate 就会 + 1&lt;/p&gt;

&lt;p&gt;m_n_ref_count: bp 每增加一个page , m_n_ref_count + 1, 只能等到m_n_ref_count == 0 的时候, 改fil_space 才能被删除, 否则bp 里面的m_space 指针就会指向空&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Additions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;fil_space_t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// Version number of the instance, not persistent. Every time we truncate&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// or delete we bump up the version number.&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;lsn_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;

 &lt;span class=&quot;c1&quot;&gt;// Reference count of how many pages point to this instance. An instance cannot&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// be deleted if the reference count is greater than zero. The only exception&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// is shutdown.&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic_int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_n_ref_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;增加了lazy delete fil_space 以后, 那么什么时候将内存中的fil_space_t 删除呢?&lt;/p&gt;

&lt;p&gt;最后的删除操作在 master_thread 会定期执行, 将之前已经标记删除, 放入到m_deleted_spaces 中的space 一起删除&lt;/p&gt;

&lt;p&gt;/* Purge any deleted tablespace pages. */
fil_purge();  =&amp;gt; fil_shard.purge()&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;purge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mutex_acquire&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_deleted_spaces&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_deleted_spaces&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// has_no_references() 说明该fil_space 对应的bp 已经都删除了, 那么该space 就可以删除&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;has_no_references&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ut_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;front&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_pending&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;space_free_low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_deleted_spaces&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;erase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mutex_release&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;drop/rename tablespace&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;执行drop/rename tablespace 的时候需要执行 row_drop_tablespace =&amp;gt; fil_delete_tablespace =&amp;gt; space_delete(space_id, buf_remove)&lt;/p&gt;

&lt;p&gt;新增加 buf_remove_t 类型: BUF_REMOVE_NONE. 不需要移除该tablespace 的所有bp.&lt;/p&gt;

&lt;p&gt;8.0.23 drop table 的时候, 执行 row_drop_tablespace =&amp;gt; fil_delete_tablespace,  之前delete tablespace 的时候, 传入的是 BUF_REMOVE_ALL_NO_WRITE, 需要将该space 对应的bp 都清理才可以完成操作.&lt;/p&gt;

&lt;p&gt;传入 BUF_REMOVE_NONE 就只需要将tablespace 标记删除, 放入到 m_deleted_spaces 中, 不需要清理bp, 然后将对应的物理文件删除即可. 该tablespace 对应bp 中的数据就变成 stale page, 后续会有操作将这些stale page 删除或者复用.&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf_remove_t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/** Don&apos;t remove any pages. */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BUF_REMOVE_NONE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/** Remove all pages from the buffer pool, don&apos;t write or sync to disk */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BUF_REMOVE_ALL_NO_WRITE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/** Remove only from the flush list, don&apos;t write or sync to disk */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BUF_REMOVE_FLUSH_NO_WRITE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/** Flush dirty pages to disk only don&apos;t remove from the buffer pool */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BUF_REMOVE_FLUSH_WRITE&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;BUF_REMOVE_ALL_NO_WRITE:&lt;/p&gt;

&lt;p&gt;从flush list 和 LRU list 上面都删除, 数据不需要, 并且也不需要刷盘. 从LRU list 上面也都删除开销是比较大的, 因此更多的时候是使用BUF_REMOVE_FLUSH_NO_WRITE, 只删flush list, 不删LRU&lt;/p&gt;

&lt;p&gt;一般来说truncate table 的时候是执行这个.  在5.6/5.7 里面, 由于truncate table 了以后, space id 是不会变的, 那么就必须把这些space 对应的page 都删除, 否则如果新的table 的space id 和老的space id 一致, 那就访问到脏数据了.&lt;/p&gt;

&lt;p&gt;BUF_REMOVE_FLUSH_NO_WRITE:&lt;/p&gt;

&lt;p&gt;从flush list 删除删除, 并且不需要刷盘, 直接丢弃掉. 和BUF_REMOVE_ALL_NO_WRITE 相比, 把从LRU list 上面删除的操作放到了后台来做, 因为lru list 的大小是远远大于flush list, 删除lru list 的成本是很大的, 因此放在后来执行&lt;/p&gt;

&lt;p&gt;一般drop table 是执行这个操作, 让后台慢慢从lru list 里面把要drop 的tablespace 删除&lt;/p&gt;

&lt;p&gt;BUF_REMOVE_FLUSH_WRITE:&lt;/p&gt;

&lt;p&gt;从flush list 上删除, 并且刷脏, 那么就不需要从LRU list 上删除, 因为LRU list 上也是最新的&lt;/p&gt;

&lt;p&gt;常用场景, 执行DDL 以后,  DDL 只需要确保这个DDL 产生的page 必须进行刷脏. 执行刷脏逻辑&lt;/p&gt;

&lt;p&gt;BUF_REMOVE_NONE:&lt;/p&gt;

&lt;p&gt;只需要将tablespace 标记删除, 不需要清理bp, 该tablespace 对应bp 中的数据就变成 stale page, 后续会有操作将这些stale page 删除或者复用.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;那么什么时候会将这些 stale page 删除呢?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总共有多个场景:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在正常从bp 中读取page 的时候, 如果读取到的page 是 stale, 那么通过执行 buf_page_free_stale() 将该page 进行删除操作&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;在从double write buffer Double_write::write_pages() 到磁盘的时候, 如果这个时候改page 的space file 已经被删除, 那么这个时候通过 buf_page_free_stale_during_write() 进行删除&lt;/li&gt;
  &lt;li&gt;在刷脏操作buf_flush_batch()的时候, 从LRU_list 或者 flush_list 拿取page, 如果发现该page 是stale, 并且没有io 操作在这个page 上面, 那么通过 buf_page_free_stale() 进行删除操作&lt;/li&gt;
  &lt;li&gt;在single page flush 的时候, 同样判断该page 是stale, 那么通过buf_page_free_stale() 进行删除&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Mon, 08 Feb 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2021/02/08/faster-truncate-drop/</link>
        <guid isPermaLink="true">http://localhost:4000/2021/02/08/faster-truncate-drop/</guid>
      </item>
    
      <item>
        <title>InnoDB page management</title>
        <description>&lt;p&gt;这个图片可以看到InnoDB 里面涉及的文件:&lt;/p&gt;

&lt;p&gt;从 tablespace =&amp;gt; segment =&amp;gt; extent =&amp;gt; page=&amp;gt;row&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/U8lbbM5.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在一个tablespace 里面, 每一个segment 也是有一个唯一的id 的标识的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tablespace&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个唯一的Tablespace 会由这个file space 的第一个Page来描述&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/K5HswIh.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里主要有几个重要的list&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;维护Inode 的FULL_INODE, FREE_INODE list, 和维护 extent 的 FREE List, FREE_FRAG List, FULL_FRAG List 都在FSP Header里面, 我们可以理解成这两个资源是这个file space 的meta信息&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tablespace =&amp;gt; segment&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个tablespace 里面包含了多个segment, 特别是tablespace 0, sys tablespace, 里面还包含了rollback segment,  用户创建的table 所对应的table space 里面, 一般有segment, left node segment 和 non-leaf node segment. 如果用户创建了索引, 又会增加两个新的segment.&lt;/p&gt;

&lt;p&gt;tablespace 是如何找到segment 的呢?  这些segment 的描述信息在哪里呢?&lt;/p&gt;

&lt;p&gt;一个Inode Entry 用来描述一个 segment,  然后所有的这些Inode Entry 都在一个Inode page 里面, 默认这个Inode page 在tablespace 的第2个page. 如果这个tablespace 里面有过多的segment 了, 那么就创建更多的Inode page, 这些Inode page 通过FSP header 里面的FULL_INODE list 和 FREE_INODE list 连接在一起&lt;/p&gt;

&lt;p&gt;所以tablespace 通过Inode Page 找到所有的segment.&lt;/p&gt;

&lt;p&gt;底下这个图是Inode Page 结构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/bE5NM0m.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个Inode Page 里面包含84个Inode Entry&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;segment=&amp;gt;extent&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个segment 里面包含了多个extent,  所以每一个extent 都有一个属于的segment id.&lt;/p&gt;

&lt;p&gt;那么segment 如何找到属于它的extent, 这些extent 的描述信息在哪里呢?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ofrhlCX.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在Inode Entry 里面, 也就是每一个segment 的描述结构里面, 有3个List, NOT_FULL List, Free List, NOT_FULL List,  这3个List 就把对应的 extent 连在一起了.&lt;/p&gt;

&lt;p&gt;所以通过遍历Inode Entry 里面的3个List, 就可以找到这个Segment 的所有的 extent了, 然后extent 对应的描述符就是XDES Entry.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Extent =&amp;gt; Page&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个extent 里面包含了64 个page,  只有一个index 的root page, 也就是根节点这个page, 会记录该page 所对应的两个segment 的Inode Entry 在Inode page 里面的具体位置.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/hQqvXoP.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么一个extent 是如果管理这64个page 是否空闲呢? 是也通过InnoDB List 么?&lt;/p&gt;

&lt;p&gt;不是的, 和一个segment 对应一个Inode Entry 类似, 一个extent 也对应一个XDES Entry.&lt;/p&gt;

&lt;p&gt;类似有一个Inode Page 存储了所有的Inode Entry, XDES Entry 也存在XDES page 里面(如果这个XDES page 是这个file space 的第一个XDES, 这个XDES 又叫做FSP_HDR, 一个file space 只会有一个FSP_HDR). 类似Inode Page 存在第2个Page, 这个XDES Entry 存在256MB XDES 的第一个page 上.&lt;/p&gt;

&lt;p&gt;对应的XDES Entry 的结构:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/KkDOOCy.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里标记了 XDES对应的extent 属于的File Segment ID. XDES List 就把一个segment 对应的多个extent 连成一个链表, 然后State 标记这个extent 是FREE, FREE_FRAG, FREE_FULL, 然后在FSP_HDR 里面有FREE_LIST, FREE_FRAG, FREE_FULL list 把这些extent 也连在一起了.&lt;/p&gt;

&lt;p&gt;在一个XDES Entry 里面包含了 Page State Bitmap=16 字节 = 128 byte. 每两个byte 用来描述1个page. 所以一个XDES 可以描述连续的61 个page, 这也是为什么extent = 64page 的原因.&lt;/p&gt;

&lt;p&gt;所以Extent 通过Page State Bitmap 来管理64 个空闲page&lt;/p&gt;

&lt;p&gt;对应的XDES Page 的结构:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ebBjQW3.jpg&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个XDES Page 里面保存了 256 个XDES Entry.&lt;/p&gt;

&lt;p&gt;这里与Inode page 不一样的地方, 因为每256M 的第一个page 都是XDES page. 所以不需要动态的分配XDES Page.&lt;/p&gt;

&lt;p&gt;这里可以看出对于 Extent, FSP_Header 里面有3个List 可能把它连在一起 FREE_FRAG, FULL_FRAG, FREE. Inode Entry 里面同样有3个List FREE, NOT_FULL, FULL.&lt;/p&gt;

&lt;p&gt;当一个extent 完全被某一个segment 使用的时候, 就会连在Inode Entry 里面, 如果这个extent 完全空的, 就连在FREE. 一般被这个segment 使用, 连在NOT_FULL, 全部连在FULL.&lt;/p&gt;

&lt;p&gt;如果一个extent 被多个segment 混用, 这里面还没满, 就连在FREE_FRAG, 被混用满了, 就连在FULL_FRAG, 这个extent 完全空闲, 有可能后续被分配给某一个segment 连在Inode Entry里面的FREE, 也有可能分配给 FREE_FRAG 使用&lt;/p&gt;

&lt;p&gt;所以当我需要新的segment 的时候, 就从Inode Page 上面去找一个空闲的Inode Entry, 如果没有, FSP 就会分配一个新的Inode Page, 然后从这个新的Inode Page 去找新的Inode Entry&lt;/p&gt;

&lt;p&gt;当我需要新的extent的时候, 就从XDES Page/FSP_HDR 上去找, XDES Page 有每一个XDES Entry 的状态, 如果没有, 就从下一个256M 的 XDES Page 上去找&lt;/p&gt;

&lt;p&gt;当我需要新的page 的时候, 就从XDES Entry 上面找, XDES 里面的Page State Bitmaps 记录着里面是否有空闲page, 如果没有空闲page, 就申请一个新的 extent.这个新的extent 是从XDES Page 上去申请.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于一个用户创建的table 对应一个file space, 那么这个file space 里面就只会有两个segment, left page segment, non-leaf page segment, 那么这个这个file space 对应的Inode page 就只有两个Inode entry 是有用的吧&lt;/p&gt;

&lt;p&gt;但是如果给这个table 建立一个索引, 就会增加两个segment, 所以最多给这个表建立42个索引以后, 这个Inode page 里面的Inode entry 就会用用满了, 然后这个file space 里面所对应的FSP_HEADER 里面就会去创建一个新的Inode page, 所以在file space 这个level, 也有两个InnoDB list, FREE_INODES, FULL_INODES, 记录在FSP header 这个结构体, 所以我们也可以看到Inode page 里面也有12 字节的InnoDB LIst 结构体&lt;/p&gt;

&lt;p&gt;虽然大部分情况下一个Inode page 都是用不满的&lt;/p&gt;

&lt;p&gt;可以这么理解, 只有redo log 是脱离Innode page management 这一套, undo log 里面的rollback segment page, undolog segment page, undolog normal page 都是走的Inode page management 这一套的&lt;/p&gt;

</description>
        <pubDate>Tue, 08 Sep 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/09/08/innodb-page-management/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/09/08/innodb-page-management/</guid>
      </item>
    
      <item>
        <title>InnoDB btree latch 优化历程</title>
        <description>&lt;p&gt;(一般在数据库里面latch 指的是物理Lock, Lock 指的是事务的逻辑lock, 这里混用)&lt;/p&gt;

&lt;p&gt;在InnoDB 的实现中, btree 主要有两种lock: index lock 和 page lock&lt;/p&gt;

&lt;p&gt;index lock 就是整个Index 的lock, 具体在代码里面就是 dict_index-&amp;gt;lock&lt;/p&gt;

&lt;p&gt;page lock 就是我们在btree 里面每一个page 的变量里面都会有的 lock&lt;/p&gt;

&lt;p&gt;当我们说btree lock的时候, 一般同时包含 index lock 和 page lock 来一起实现&lt;/p&gt;

&lt;p&gt;在5.6 的实现里面比较简单,btree latch 大概是这样的流程&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果是一个查询请求
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;那么首先把btree index-&amp;gt;lock  S LOCK&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;然后直到找到 leaf node 以后, 对leaft node 也是 S LOCK, 然后把index-&amp;gt; lock 放开&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/7AouKrR.png&quot; alt=&quot;Imgur&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果是一个修改leaf page 请求
    &lt;ul&gt;
      &lt;li&gt;同样把btree index-&amp;gt; lock  S LOCK&lt;/li&gt;
      &lt;li&gt;然后直到找到leaf node 以后, 对leaf node 执行 X LOCK, 因为需要修改这个page. 然后把index-&amp;gt;lock 放开.   到这里又分两种场景了, 对于这个page 的修改是否会引起 btree 的变化
        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;如果不会, 那么很好, 对leaf node 执行了X LOCK 以后, 修改完数据返回就可以&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;如果会, 那么需要执行悲观插入操作, 重新遍历btree.&lt;/p&gt;

            &lt;p&gt;对btree inex 加X LOCK, 执行btr_cur_search_to_nth_level 到指定的page.&lt;/p&gt;

            &lt;p&gt;因为leaft node 修改, 可能导致整个沿着leaf node 到root node 的btree 都会随着修改, 因此必须让其他的线程不能访问到, 因此需要整个btree 加X LOCK, 那么其他任何的查询请求都不能访问了, 并且加了index X LOCK 以后, 进行record 插入到page, 甚至可能导致上一个Level 的page 也需要改变, 这里需要从磁盘中读取数据, 因此可能有磁盘IO, 这就导致了加X LOCK 可能需要很长一段时间, 这段时间sread 相关的操作就都不可访问了&lt;/p&gt;

            &lt;p&gt;这里具体的代码在 row_ins_clust_index_entry&lt;/p&gt;

            &lt;p&gt;首先尝试乐观的插入操作&lt;/p&gt;

            &lt;p&gt;err = row_ins_clust_index_entry_low(
	0, BTR_MODIFY_LEAF, index, n_uniq, entry, n_ext, thr,
	&amp;amp;page_no, &amp;amp;modify_clock);&lt;/p&gt;

            &lt;p&gt;然后这里如果插入失败, 再尝试悲观的插入操作,&lt;/p&gt;

            &lt;p&gt;return(row_ins_clust_index_entry_low(
		0, BTR_MODIFY_TREE, index, n_uniq, entry, n_ext, thr,
		&amp;amp;page_no, &amp;amp;modify_clock));&lt;/p&gt;

            &lt;p&gt;从这里可以看到, 唯一的区别在于这里latch_mode = BTR_MODIFY_LEAF 或者 BTR_MODIFY_TREE. 并且由于btr_cur_search_to_nth_level 是在函数 row_ins_clust_index_entry_low 执行, 那么也就是尝试了乐观操作失败以后, 重新进行悲观插入的时候, 需要重新遍历btree&lt;/p&gt;

            &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/MZrRVA6.png&quot; alt=&quot;Imgur&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面可以看到, 5.6 里面只有对整个btree  的index lock,  以及在btree 上面的leaf node page 会有lock, 但是btree 上面non-leaf node 并没有 lock.&lt;/p&gt;

&lt;p&gt;这样的实现带来的好处是代码实现非常简单, 但是缺点也很明显由于在SMO 操作的过程中, 读取操作也是无法进行的, 并且SMO 操作过程可能有IO 操作, 带来的性能抖动非常明显, 我们在线上也经常观察到这样的现象.&lt;/p&gt;

&lt;p&gt;所以有了官方的改动, 其实这些改动在5.7 就引入, 我们这里以8.0 为例子:&lt;/p&gt;

&lt;p&gt;主要有这两个改动&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;引入了sx lock&lt;/li&gt;
  &lt;li&gt;引入了non-leaf page lock&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;引入SX Lock 以后&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先介绍一下 SX Lock,  SX Lock 在index lock 和 page lock 的时候都可能用到.&lt;/p&gt;

&lt;p&gt;SX Lock 是和 S LOCK 不冲突, 但是和 X LOCK 冲突的, SX LOCK 和 SX LOCK 之间是冲突的.&lt;/p&gt;

&lt;p&gt;SX LOCK 的意思我有意向要修改这个保护的范围, 但是现在还没开始修改, 所以还可以继续访问, 但是要修改以后, 就无法访问了.  因为我有意向要修改, 因此不能允许其他的改动发生, 因此和 X LOCK 是冲突的.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;目前主要用途因为index SX lock 和 S LOCK 不冲突, 因此悲观insert 改成index SX LOCK 以后, 可以允许用户的read/乐观写入&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;SX LOCK 的引入由这个 WL 加入 &lt;a href=&quot;https://dev.mysql.com/worklog/task/?id=6363&quot;&gt;WL#6363&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以认为 SX LOCK 的引入是为了对读操作更加的优化,  SX lock 是和 X lock 冲突, 但是是和 S lock 不冲突的, 将以前需要加X lock 的地方改成了SX lock, 因此对读取更加友好了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;引入non-leaf page lock&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其实这也是大部分商业数据库都是这样, 除了leaf page 有page lock, non-leaf page 也有page lock.&lt;/p&gt;

&lt;p&gt;主要的想法还是 Latch coupling, 在从上到下遍历btree 的过程中, 持有了子节点的page lock 以后, 再把父节点的page lock 放开, 这样就可以尽可能的减少latch 的范围. 这样的实现就必须保证non-leaf page 也必须持有page lock.&lt;/p&gt;

&lt;p&gt;不过这里InnoDB 并未把index-&amp;gt;lock 完全去掉, 这就导致了现在InnoDB 同一时刻仍然只有同时有一个 BTR_MODIFY_TREE 操作在进行, 从而在激烈并发修改btree 结构的时候, 性能下降明显.&lt;/p&gt;

&lt;p&gt;回到5.6 的问题&lt;/p&gt;

&lt;p&gt;可以看到在5.6 里面, 最差的情况是如果要修改一个btree leaf page, 这个btree leaf page 可能会触发btree 结构的改变, 那么这个时候就需要加一整个index X LOCK, 但是其实我们知道有可能这个改动只影响当前以及上一个level 的btree page, 如果我们能够缩小LOCK 的范围, 那么肯定对并发是有帮助的.&lt;/p&gt;

&lt;p&gt;那么到了8.0&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;如果是一个查询请求&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;那么首先把btree index-&amp;gt;lock  S LOCK&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;然后沿着搜索btree 路径, 遇到的non-leaf node page 都加 S LOCK&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;然后直到找到 leaf node 以后, 对leaft node page 也是 S LOCK, 然后把index-&amp;gt; lock 放开&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/AGN3ghS.png&quot; alt=&quot;Imgur&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果是一个修改leaf page 请求&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;同样把btree index-&amp;gt; lock  S LOCK, 通过对non-leaf node page 都加S LOCK&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;然后直到找到leaf node 以后, 对leaf node 执行 X LOCK, 因为需要修改这个page. 然后把index-&amp;gt;lock 放开.   到这里又分两种场景了, 对于这个page 的修改是否会引起 btree 的变化&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;如果不会, 那么很好, 对leaf node 执行了X LOCK 以后, 修改完数据返回就可以&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;如果会, 那么需要执行悲观插入操作, 重新遍历btree. 这时候给index-&amp;gt;lock 是加 SX LOCK&lt;/p&gt;

            &lt;p&gt;**因为已经给btree 加上sx lock, 那么搜索路径上的btree 的page 都不需要加 lock, 但是需要把搜索过程中的page 保存下来, 最后阶段给搜索路径上有可能发生结构变化的page  加x lock. **&lt;/p&gt;

            &lt;p&gt;这样就保证了在搜索的过程中,  对于read 操作的影响降到最低.&lt;/p&gt;

            &lt;p&gt;只有在最后阶段确定了本次修改btree 结构的范围, 对可能发生结构变化的page 加X lock 以后, 才会有影响.&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;8.0 里面, SMO 操作过程中, 拿着sx lock 的持续时间是&lt;/p&gt;

            &lt;p&gt;持有sx lock 的时间:&lt;/p&gt;

            &lt;p&gt;第一次btr_cur_optimistic_insert insert 失败以后, 在 row_ins_clust_index_entry 会调用&lt;/p&gt;

            &lt;p&gt;row_ins_clust_index_entry_low(flags, BTR_MODIFY_TREE …) 进行插入, 在 row_ins_clust_index_entry_low 里面,  在btr_cur_search_to_nth_level 函数里面加上 sx lock, 到这里btree 因为已经加了sx lock, 就已经无法进行smo 操作了, 然后接下来仍然会尝试先乐观插入,这个时候sx lock 依然持有, 失败的话, 再尝试悲观插入操作.&lt;/p&gt;

            &lt;p&gt;释放sx lock 的时间:&lt;/p&gt;

            &lt;p&gt;在悲观插入操作里面会一直持有sx lock, 直到在 btr_page_split_and_insert 内部, 将新的page2 已经产生, 同时page2 已经连接上father node 之后.  并且这次发生SMO 的page 还需要是leaf page, 否则一直持有sx lock, 直到SMO 操作完成, 并且insert 成功才会释放&lt;/p&gt;

            &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ye4VVpc.png&quot; alt=&quot;Imgur&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

            &lt;p&gt;具体执行SMO 操作并且insert 的函数是 btr_page_split_and_insert&lt;/p&gt;

            &lt;p&gt;btr_page_split_and_insert 操作大概有8个流程:&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;
                &lt;p&gt;从要分裂的page 中, 找到要split 的record, split 的时候要保证split 的位置是record 的边界&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;分配一个新的索引页&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;分别计算page, 和new_page 的边界record&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;在上一级索引页(父节点)添加新的索引页的索引项, 如果上一级没有足够的空间, 那么就触发父节点的分裂操作了&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;连接当前索引页, 当前索引页prev_page, next_page, father_page, 新创建的 page. 当前的连接顺序是先连接父节点, 然后是prev_page/next_page, 最后是 page 和 new_page  (在这一步结束之后就可以放开index-&amp;gt;sx lock)&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;将当前索引页上的部分Record 移动到新的索引页&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;SMO 操作已经结束, 计算本次insert 要插入的page 位置&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;进行insert 操作, 如果insert 失败, 通过reorgination page 重新尝试插入&lt;/p&gt;
              &lt;/li&gt;
            &lt;/ol&gt;

            &lt;p&gt;​&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现有代码里面只有一个场景会对index-&amp;gt;lock X lock. 也就是&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  if (lock_intention == BTR_INTENTION_DELETE &amp;amp;&amp;amp;
      trx_sys-&amp;gt;rseg_history_len &amp;gt; BTR_CUR_FINE_HISTORY_LENGTH &amp;amp;&amp;amp;
      buf_get_n_pending_read_ios()) { 如果这次lock_intention 是BTR_INTENTION_DELETE, 并且history list 过长, 才会对 index 加 x lock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;8.0 比5.6 改进的地方&lt;/p&gt;

&lt;p&gt;在5.6 里面, 写入的时候, 如果有SMO 在进行, 那么就需要把整个index-&amp;gt;lock x lock, 那么在SMO 期间所有的read 操作也是无法进行的.&lt;/p&gt;

&lt;p&gt;在8.0 里面SMO 操作的过程中是允许有read 和 乐观写入操作的.&lt;/p&gt;

&lt;p&gt;但是8.0 里面还有一个约束就是同一时刻只能有一个SMO 正在进行, 因为SMO 的时候需要拿 sx lock. sx lock 和 sx lock 是冲突的, 这也是目前8.0 主要问题.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优化点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当然这里还是有优化点.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;依然有全局的index-&amp;gt;lock, 虽然是sx lock, 但是理论上按照8.0 的实现, 可以完全将index lock 放开, 当然很多细节需要处理&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在执行具体的分裂操作过程中, btr_page_split_and_insert 里面的持有index lock 是否还可以优化?&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;比如按照一定的顺序的话, 是否将新创建page 连接到new_page 以后就可以放开index-&amp;gt;lock&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;还可以考虑发生SMO 的page 持有x lock 的时间.&lt;/p&gt;

        &lt;p&gt;目前会持有整个路径上的page x lock 直到SMO 操作结束, 并且这次insert 完成, 同时需要一直持有fater_page, prev_page, next_page 的x lock, 是否可以减少持有page 的个数, 比如这个优化 &lt;a href=&quot;https://bugs.mysql.com/bug.php?id=99948&quot;&gt;BUG#99948&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;btr_attach_half_pages 中多次通过btr_cur_search_to_nth_level 遍历btree 操作是否可以避免?
函数是将father link, prev link, next link 等建立好的操作
在这里会重新执行一次 btr_page_get_father_block 对btree 进行遍历找到父节点, 在该函数里面有需要重新执行 btr_cur_search_to_nth_level 函数, 其实这一步操作是可以避免的. 
因为这时index已经 sx lock 了,  father 肯定不会变了的, 那么可以将上次btr_cur_search_to_nth_level 的结果保留, 就可以获得&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;是否可以像b-link tree 类似, 给正在SMO 的page 标记状态, 这个状态是允许读取的, 只不过有可能存在要读取的record 不在当前的page, 那么就需要去该page-&amp;gt;next page 去尝试读取, 如果能读取到依然是可以的..&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每次进行btr_cur_search_to_nth_level, 搜索路径中遇到的page 是否可以保留? 这样即使重复搜索, 只需要确定upper level page 的max trx_id, 则可以确定整个搜索路径都没有改变, 那么就不需要重新遍历.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;是否还需要保留先乐观insert 再悲观insert 的操作过程?&lt;/p&gt;

    &lt;p&gt;我理解现有的流程是因为在5.6 的实现中, 悲观insert 操作的开销太大, 从而尽可能的避免悲观insert, 因此沿用到了目前的8.0 实现中.这种多次insert 需要多次遍历btree, 带来额外开销&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;talking&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;https://dom.as/2011/07/03/innodb-index-lock/&lt;/p&gt;

&lt;p&gt;https://dev.mysql.com/worklog/task/?id=6326&lt;/p&gt;

</description>
        <pubDate>Sun, 28 Jun 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/06/28/innodb-btree-latch/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/28/innodb-btree-latch/</guid>
      </item>
    
      <item>
        <title>Buffer pool 并发控制</title>
        <description>&lt;h3 id=&quot;buffer-pool-并发控制&quot;&gt;Buffer pool 并发控制&lt;/h3&gt;

&lt;p&gt;InnoDB 对buffer pool 的访问除了包含了用户线程会并发访问buffer pool 以外, 同时还有其他的后台线程也在访问buffer pool, 比如刷脏, purge, IO 模块等等, InnoDB 主要通过5个不同维度的mutex, rw_lock, io_fix 进行并发访问的控制&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;free/LRU/flush list Mutex&lt;/li&gt;
  &lt;li&gt;hash_lock rw_lock (在5.6 之前, 只会有一个大的buffer pool Mutex)&lt;/li&gt;
  &lt;li&gt;BPageMutex mutex&lt;/li&gt;
  &lt;li&gt;io_fix, buf_fix_count&lt;/li&gt;
  &lt;li&gt;BPageLock lock  rw_lock&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;free/LRU/flush list Mutex&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;所有的page 都在free list, LRU list, flush list 上, 所以大部分操作第一步如果需要操作这几个list, 需要首先获得这几个list mutex, 然后在进行IO 操作的过程, 是会把list Mutex 放开.&lt;/p&gt;

&lt;p&gt;InnoDB 也是尽可能让持有LRU list, flush list 的时间尽可能短&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hash_lock rw_lock&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个buffer pool instance 下面的buffer block 都存在一个hash table上&lt;/p&gt;

&lt;p&gt;这个hash_lock 是这个hash_table 上面的slot/segment 的rw_lock, 也就是这个hash table 有多少个slot, 就有多少个这个hash_lock, 这个hash_lock 的引入也是为了尽可能的减少锁冲突, 这样可以做到需要写入的时候锁的只是这个hash_table 的slot/segment 级别&lt;/p&gt;

&lt;p&gt;这里InnoDB 优化这个lock level 从整个hash table 到hash table slot 级别, 在5.6 之前的版本, 是一个整个hash table mutex.&lt;/p&gt;

&lt;p&gt;从代码里面可以看到, 总是先拿 hash_lock, 然后才是 buffer block mutex 或者是 page frame mutex&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BPageMutex mutex&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们也叫做buffer block mutex, 在buf_block_t 结构体里面.&lt;/p&gt;

&lt;p&gt;BPageMutex mutex 保护的是io_fix, state, buf_fix_count, state 等等变量, 引入这个mutex 是为了减少早期版本直接使用buffer pool-&amp;gt;mutex 的开销
可以理解BPageMutex 是保护buf_block_t 结构体, 而下面BPageLock 是为了保护page frame&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;io_fix, buf_fix_count&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;io_fix, buf_fix_count 受 pager block mutex的保护.&lt;/p&gt;

&lt;p&gt;io_fix 表示当前的page frame 正在进行的IO 操作状态, 主要有 BUF_IO_READ, BUF_IO_WRITE, BUF_IO_PIN.&lt;/p&gt;

&lt;p&gt;buf_fix_count 表示当前这个block 被引用了多少次, 每次访问一个page 的时候, 都会对buf_fix_count++, 最后在mtr:commit() 的最后资源释放阶段, 会对这个buf_fix_count–, 进行资源的释放.&lt;/p&gt;

&lt;p&gt;比如: 在flush 一个page 的时候, 会检测一个page 是否可以被flush, 这里为了减少拿 page frame rw_lock, 直接通过判断 io_fix 即可&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldest_modification&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;buf_page_get_io_fix_unlocked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_IO_NONE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;比如: 在检查一个block 能否被replace 的时候, 除了确定当前这个block io_fix == BUF_IO_NONE, 还需要确保当前没有其他的线程在引用这个block, 当然还需要保证当前block oldest_modification ==0.  来确定当前这个block 是否可以允许被replace&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ibool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;buf_flush_ready_for_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_page_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_page_in_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldest_modification&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_fix_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;buf_page_get_io_fix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_IO_NONE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以理解, 引入io_fix, buf_fix_count 是为了减少调用page frame rw_lock 的开销, 因为page frame 的调用是在btree search 的核心路径&lt;/p&gt;

&lt;p&gt;如果io_fix 处于BUF_IO_READ, BUF_IO_WRITE 那我们可以知道, 当前page 处于IO 状态, 如果要进行replace, flush 操作是不可以的, 这样就不需要去获得page frame rw_lock, 然后再检查当前page frame 是否允许这样的操作&lt;/p&gt;

&lt;p&gt;所以代码里面我们会看到在设置了io_fix 的状态以后, 我们就可以把之前的几个mutex, rw_lock 都完全放开, 因为被设置了io_fix 状态的page 是不可以从list 上面删除或者replace, 需要等IO 操作完成以后, 将io_fix 设置成BUF_IO_NONE 才可以进行操作&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BPageLock lock  rw_lock&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如上所说, BPageMutex 是保护buf_block_t 结构体, 而BPageLock 是为了保护page frame.
当需要对buffer pool page frame 内容进行读取/修改的时候, 就需要持有BPageLock.&lt;/p&gt;

&lt;p&gt;比如最常见的我们要修改一个btree page 内容的时候,
都需要通过btr_cur_search_to_nth_level() 把page 从磁盘读取到内存中, 然后修改.
这里修改之前会对page 加 x lock. 如果是读取操作, 就需要加s lock.&lt;/p&gt;

&lt;p&gt;同样后台进行刷脏操作的时候, 也需要对page 加x lock.&lt;/p&gt;

&lt;p&gt;在InnoDB 访问btree 的过程中, btr_cur_search_to_nth_level() 函数里面, 会对btree index s lock, 如果只是修改leaf page, 那么在8.0 里面, 是沿着btree 的搜索路径, 给路径上的non-leaf page 都加上s lock, 最后给leaf page 加x lock. 具体看文章 InnoDB latch&lt;/p&gt;

&lt;p&gt;但是后台操作比如刷脏, 或者当前page frame 不在buffer pool 中, 同样需要拿 page frame rw_lock, 那么是会对前台的page 访问有非常大的性能影响. 因此上述的io_fix, page block mutex 也是为了尽可能减少持有page frame rw_lock 的机会&lt;/p&gt;

&lt;p&gt;我们看到官方做了很多优化, 比如尽可能减少访问btree 的时候, 拿着btree index lock, 在访问btree 的时候, 不会像在5.6 时候一样, 拿着整个btree index lock.&lt;/p&gt;

&lt;p&gt;这里与5.6 对比, 5.6 在做SMO 的时候, 是所有的读操作也无法进行的, 因为读操作都需要加 index s lock..&lt;/p&gt;

&lt;p&gt;在8.0 在做SMO 的时候, 因为index 加的是sx lock, 所以所有的读操作依然是可以进行的, 但是由于sx lock 和 sx lock 之间是互斥的, 因此同一时刻只能有一个smo 在进行.  但是这也比5.6 好很多,  至少在SMO 的过程, 读操作还可以进行的&lt;/p&gt;

&lt;p&gt;但是8.0 里面还有一个约束就是同一时刻只能有一个SMO 正在进行, 因为SMO 的时候需要拿 sx lock. 这也是目前8.0 主要问题.&lt;/p&gt;

&lt;p&gt;(其实引入sx lock 是对读取的优化, 对写入并没有优化. 因为持有sx lock 的时候, s lock 操作是可以进行的, 但是x lock 操作是不可以进行的. 跟原先需要修改就直接拿着x lock 对比, 允许更多的读取了, 但是x lock 和之前是一样的)&lt;/p&gt;

&lt;p&gt;但是这些优化只是优化了用户访问路径上page frame rw_lock 的获取, 但是在后台的路径并没有过多的优化.&lt;/p&gt;

&lt;p&gt;但是后台操作比如刷脏, 或者当前page frame 不在buffer pool 中, 同样需要拿 page frame rw_lock, 那么是会对前台的page 访问有非常大的性能影响. 因此上述的io_fix, page block mutex 也是为了尽可能减少持有page frame rw_lock 的机会&lt;/p&gt;

&lt;p&gt;我们看到官方做了很多优化, 比如尽可能减少访问btree 的时候, 拿着btree index lock,  在访问btree 的时候, 不会像在5.6 时候一样, 拿着整个btree index lock, 尽可能的只拿着会引起树结构变化的子树. 比如引入sx lock, 在真正要修改的时候, 才会获得x lock 去修改btree. (其实引入sx lock 是对读取的优化, 对写入并没有优化. 因为持有sx lock 的时候, s lock 操作是可以进行的, 但是x lock 操作是不可以进行的. 跟原先需要修改就直接拿着x lock 对比, 允许更多的读取了, 但是x lock 和之前是一样的)&lt;/p&gt;

&lt;p&gt;但是这些优化只是优化了用户访问路径上page frame rw_lock 的获取, 但是在后台的路径并没有过多的优化.&lt;/p&gt;

&lt;p&gt;比如: page frame rw_lock 是在buf_page_io_complete 之后才会放开的&lt;/p&gt;

&lt;p&gt;在page flush, read ahead 的时候, 在走simulated AIO 的时候, page 操作被放入队列即可, 但是并没有执行完成.&lt;/p&gt;

&lt;p&gt;执行完成的通知是在simulated AIO fil_aio_wait:buf_page_io_complete() 里面完成, 在buf_page_io_complete() 操作里面, 会把page 上的rw_lock 给释放.&lt;/p&gt;

&lt;p&gt;所以一个page 在进行IO 操作的时候, 是在调用simulated AIO 之前, 给page frame rw_lock 加 x/sx lock, 但是释放page frame rw_lock 需要等到IO 操作结束才可以完成, 而fio_io() 只是将IO 放到的队列中, 这个IO 并没有执行完成.  是在simulated io handler 的 fil_aio_wait() 函数里面, 这个操作才会完成, 然后调用buf_page_io_complete() 进行通知操作.&lt;/p&gt;

&lt;p&gt;因此page frame 的rw_lock 的持有周期是整个异步IO 的周期, 直到IO 操作完成, 这个page frame 才会释放.&lt;/p&gt;

&lt;p&gt;而page frame 的rw_lock 又是用户访问btree 路径上面的 btr_cur_search_to_nth_level() 必须要获得的lock, 因此就可能出现大量的page frame由于刷脏或者read ahead 的时候, 持有了page frame x lock/sx lock, 当用户的访问路径需要x/sx lock 的时候, 被堵塞住的情况.&lt;/p&gt;

&lt;p&gt;这种堵塞住的情况, 如果是非leaf page 的时候, 影响会更明显, 而且目前InnoDB simulated AIO 的队列长度是*(n_read_thread + n_write_thread) * 256, 那么会可能出现大量的page 因为在IO 等待队列中等待, 造成更多的btree search 操作被堵住, 特别是如果底层存储IO latency 比较长的情况, 这里问题会更加的明显.&lt;/p&gt;

&lt;p&gt;当然我们也通过simulated AIO 优化, copy page等等减少持有page frame 的时长.&lt;/p&gt;

&lt;p&gt;buf_page_io_complete 主要做什么呢?&lt;/p&gt;

&lt;p&gt;将page io_fix 设置成NONE, 表示这个page 的io 操作已经完成了&lt;/p&gt;

&lt;p&gt;buf_page_set_io_fix(bpage, BUF_IO_NONE);&lt;/p&gt;

&lt;p&gt;将page 上面的rw_lock 放开, 如果是read, 把 x lock 放开, 如果是write, 把sx lock 放开.&lt;/p&gt;

&lt;p&gt;为什么是这样? 那么什么时候拿s lock?&lt;/p&gt;

&lt;p&gt;读操作要拿 x lock 主要是为了避免多个线程同时去读这个page, 然后另外一个线程如果需要访问该page, 那么会通过buf_wait_for_read(block) 操作, 尝试给这个page frame 加s lock, 如果加成功, 这说明这个page 已经被获得了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;free/LRU/flush List 相关mutex 主要是是否操作 list 时候持有.&lt;/p&gt;

&lt;p&gt;而后面4个mutex 一般操作都是加hash_lock rw_lock, 然后获得buf block mutex, 放开hash_lock rw_lock, 然后修改 io_fix, buf_fix_count,然后放开 buf block mutex, 最后持有page frame rw_lock.&lt;/p&gt;

&lt;p&gt;如上面所说寻找block 在hash table 的位置, 通过hash_lock slot 级别的Lock 来进行了优化, 减少了修改和查找hash table 的冲突&lt;/p&gt;

&lt;p&gt;引入 buf block mutex, io_fix, buf_fix_count 将IO操作通过判断io_fix, buf_fix_count 避免不必要的获得page frame rw_lock 的开销.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;具体代码流程&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;buf_page_init_for_read&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以 buf_read_page_low() =&amp;gt; buf_page_init_for_read() 来举例并发过程&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;// 根据page_id 返回对应的buf_pool instance
buf_pool_t *buf_pool = buf_pool_get(page_id);&lt;/p&gt;

    &lt;p&gt;// 先尝试从LRU list 获得一个free block
block = buf_LRU_get_free_block(buf_pool);&lt;/p&gt;

    &lt;p&gt;// 持有我们说的第一层 LRU_list_mutex
mutex_enter(&amp;amp;buf_pool-&amp;gt;LRU_list_mutex);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;// 然后持有我们说的第二层 hash_lock
hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
rw_lock_x_lock(hash_lock);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;// 持有page block mutex
buf_page_mutex_enter(block);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;// 在持有page block mutex 的情况下, 会修改 block-&amp;gt;state, io_fix 等等&lt;/p&gt;

    &lt;p&gt;buf_page_init(buf_pool, page_id, page_size, block);&lt;/p&gt;

    &lt;p&gt;buf_page_set_io_fix(bpage, BUF_IO_READ);&lt;/p&gt;

    &lt;p&gt;// 将当前Block 加入到LRU list 中&lt;/p&gt;

    &lt;p&gt;buf_LRU_add_block(bpage, TRUE /* to old blocks */);&lt;/p&gt;

    &lt;p&gt;// 释放 LRU list mutex, 这里持有LRU list mutex 到现在, 是因为要把page block 加入到LRU list中&lt;/p&gt;

    &lt;p&gt;mutex_exit(&amp;amp;buf_pool-&amp;gt;LRU_list_mutex);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;// 这里给page frame 加了rw_lock x lock,
// 保证同一时刻只会有一个线程从磁盘去读取这个page&lt;/p&gt;

    &lt;p&gt;rw_lock_x_lock_gen(&amp;amp;block-&amp;gt;lock, BUF_IO_READ);  &lt;br /&gt;
// 依次放开hash_lock rw_lock
rw_lock_x_unlock(hash_lock);
// page block mutex
buf_page_mutex_exit(block);&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;buf_page_try_get_func&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如在 buf_page_try_get_func() 函数里面, 也是这样顺序获得mutex 的操作.&lt;/p&gt;

&lt;p&gt;// 1. 首先获得这个bp, 因此这里不涉及到各个list 相关操作, 因此没有list
  // 相关Mutex
  buf_pool_t *buf_pool = buf_pool_get(page_id);&lt;/p&gt;

&lt;p&gt;// 2. 获得这个page 在hash table 上面的slot 上面的block, 
  // 同时在这个函数里面, 已经把这个hash_lock 给s lock 了
  block = buf_block_hash_get_s_locked(buf_pool, page_id, &amp;amp;hash_lock);&lt;/p&gt;

&lt;p&gt;// 3. 或者这个page block block mutex, 同时将这里的hash_lock 给释放
  buf_page_mutex_enter(block);
  rw_lock_s_unlock(hash_lock);&lt;/p&gt;

&lt;p&gt;// 4. 在持有page block mutex 之后, 给这个block buf_fix_count++, 同时把这个page block mutex 释放
  // 这里设置了buf_fix_count 之后, 上述的mutex, rw_lock 都放开了, 因为这个page frame 在buf_fix_count != 0 的情况下, 是不能被replace 的, 会议在在buffer pool 里面, 因此后续的page frame s lock 操作可以放心操作&lt;/p&gt;

&lt;p&gt;buf_block_buf_fix_inc(block, file, line);
  buf_page_mutex_exit(block);&lt;/p&gt;

&lt;p&gt;// 5. 获得这个page frame 的rw_lock
  mtr_memo_type_t fix_type = MTR_MEMO_PAGE_S_FIX;
  success = rw_lock_s_lock_nowait(&amp;amp;block-&amp;gt;lock, file, line);&lt;/p&gt;

&lt;p&gt;在写入操作里面&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;buf_flush_page_and_try_neighbors&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在执行刷脏的时候, 可能从LRU_list, flush_list 上面刷脏, 分别是&lt;/p&gt;

&lt;p&gt;buf_do_LRU_batch, buf_do_flush_list_batch&lt;/p&gt;

&lt;p&gt;这两个函数都会调用 buf_flush_page_and_try_neighbors 进行刷脏操作, 这里在进行具体page 刷脏操作过程中是会将 lru_list_mutex/flush_list_mutex 放开, 然后操作完成以后再持有&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flush_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_FLUSH_LRU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;mutex_exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LRU_list_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flush_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_FLUSH_LRU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;mutex_exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;buf_flush_list_mutex_exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 在进行具体flush 操作的时候, 是会将LRU_list_mutex/buf_flush_list mutex放开&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf_flush_try_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flush_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_to_flush&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flush_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_FLUSH_LRU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;mutex_enter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LRU_list_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;buf_flush_list_mutex_enter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;具体的page flush 操作&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;buf_flush_try_neighbors =&amp;gt; buf_flush_page&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;// 1. 首先获得 hash_lock rw_lock&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/* We only want to flush pages from this buffer pool. */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf_page_hash_get_s_locked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buf_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_page_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 2. 然后是获得page header mutex, 同事释放hash_lock &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;block_mutex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf_page_get_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mutex_enter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rw_lock_s_unlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// =&amp;gt; 进入buf_flush_page()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 3. 修改 io_fix 设置成 BUF_IO_WRITE&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;buf_page_set_io_fix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_IO_WRITE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 4. 放开buf block mutex&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 因为已经修改了 io_fixed 和 oldest_modification&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 因此到这里已经不需要持有任何mutex 了&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mutex_exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block_mutex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 5. 获得这个page frame 的 rw_lock&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rw_lock_sx_lock_gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rw_lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_IO_WRITE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 对这个page 进行flush 操作的时候, 不需要持有mutex&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;buf_flush_write_block_low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flush_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 13 Apr 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/04/13/innodb-bp-coucurrency/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/04/13/innodb-bp-coucurrency/</guid>
      </item>
    
  </channel>
</rss>
