<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Paper Review Optimizing Paxos with batching and pipelining &#8211; baotiao</title>
    <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com">
    <link rel="dns-prefetch" href="//cdn.mathjax.org">
    <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Optimizing Paxos with batching and pipelining">
    <meta name="robots" content="all">
    <meta name="author" content="baotiao">
    <meta name="keywords" content="">
    <link rel="canonical" href="http://localhost:4000/2018/05/02/batch-pipeline/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for baotiao" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?202208210357" type="text/css">

    <!-- Fonts -->
    
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
    

    <!-- MathJax -->
    

    <!-- Verifications -->
    
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Paper Review Optimizing Paxos with batching and pipelining">
    <meta property="og:description" content="做有积累的事情">
    <meta property="og:url" content="http://localhost:4000/2018/05/02/batch-pipeline/">
    <meta property="og:site_name" content="baotiao">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@baotiao" />
    
    <meta name="twitter:title" content="Paper Review Optimizing Paxos with batching and pipelining" />
    <meta name="twitter:description" content="Optimizing Paxos with batching and pipelining" />
    <meta name="twitter:url" content="http://localhost:4000/2018/05/02/batch-pipeline/" />

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">

    
</head>

<body class="site">
  
	

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="http://localhost:4000" class="site-title">baotiao</a>
      <nav class="site-nav">
        
    

    
        <a href="/about/">About</a>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    


    

    

    

    

    
        <a href="/links/">Links</a>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    


    

    

    

    

    

    
        <a href="/paper/">Paper</a>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    


      </nav>
      <div class="clearfix"></div>
      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h1>Paper Review Optimizing Paxos with batching and pipelining</h1>
  <span class="post-meta">May 2 2018</span><br>
  
  <span class="post-meta small">
  
    2 minute read
  
  </span>
</div>

<article class="post-content">
  <h3 id="paxos-batch-pipeline">Paxos batch pipeline</h3>

<p>使用batch, pipeline 一直是优化包含state machine 一致性协议的方法, 比如paxos, raft 等等, 这篇文章主要是提出了模型(cpu 利用率, 网络延迟, 网络带宽), 然后结合实际测试和仿真为我们提供了实际环境中如何使用batch, pipeline 的方法.</p>

<p>首先看结论</p>

<h4 id="结论">结论</h4>

<p>在同机房的场景中, 由于网络延迟较低, 即使在小包的情况下, 系统的瓶颈主要是是cpu, 因此<strong>只需要通过batch 就可以达到系统最大的吞吐</strong>,  而且batch 实现又较为简单, 因此几乎在任意的包含状态机的系统中, batch 是第一步要做的优化.</p>

<p>pipeline 的效果决定于节点的性能和网络延迟,  节点花越多的时间等待从副本的返回, 那么pipeline 带来的效果是越好的. pipeline 在上面的实验中可以看出, 如果允许选择过多的pipeline 会导致系统性能反而下降</p>

<p>那么在网络延迟比较高的跨机房场景中, 可以通过batch + pipeline 可以达到最大的吞吐.  那么该如何进行选择参数呢</p>

<ol>
  <li>在用户能够接受的延迟下, 选择一个最大的batch size</li>
  <li>使用上述的模型, 选择一个合理的Pipeline 的值</li>
</ol>

<p>为什么这样做呢?</p>

<p>首先batch 带来的优化是非常明显, 但是batch 过大会拉大返回的时间. 所在可以在给定带宽和相应时间的情况下, 我们可以很快的算出这个batch 的大小,  然后可以根据上述的模型, 可以算出设置pipeline 多少个的时候,可以获得最大的吞吐.</p>

<p>比如在下面跨机房的模型里面,  如果平均请求的大小是1KB,  那么根据上述做法 batch 大小应该设置成8kb, 然后pipeline 的个数应该设置成16</p>

<h3 id="tldr-接下来是论文具体的内容">TLDR; 接下来是论文具体的内容</h3>

<p>模型主要参数:</p>

<p>主要关注3个瓶颈点</p>

<ol>
  <li>网络延迟</li>
</ol>

<p>其实就是网络带宽的占用</p>

<ol>
  <li>cpu time</li>
</ol>

<p>也就是cpu 的利用</p>

<ol>
  <li>网络带宽</li>
</ol>

<p>在局域网中,  主要的瓶颈是cpu, 在广域网中, 主要的瓶颈是网络延迟. 如果请求都是大包的场景中, 瓶颈主要是带宽</p>

<p><img src="https://i.imgur.com/5q6zGJE.jpg" alt="Imgur" /></p>

<p>出现瓶颈的过程基本是这样, 如果cpu 是瓶颈, 那么可以通过调整batch 的大小, 因为加大batch 的size 可以提高cpu 的利用率, 如果延迟是瓶颈, 那么可以增加Pipeline 的个数, 来减少延迟带来的影响.  如果带宽是瓶颈, 那么说明我们已经达到极限了.</p>

<p>最后如何设定这个pipeline 的个数呢?</p>

<p>w = ⌈min(wcpu,wnet)⌉.</p>

<p>这里也就是看cpu 先达到瓶颈, 还是网络先打到瓶颈. 如果cpu 先打到瓶颈, 那么 w = wcpu, 如果是网络, 那么w = wnet.</p>

<p>接下来就是通过实际的实验和仿真对模型的正确性进行了验证.</p>

<p>这里instance 值得是执行一整个batch 的时候, 所包含的所有请求, 也就是一个instance 包含多个client request</p>

<ul>
  <li>首先是同机房场景下的验证</li>
</ul>

<p>这里的测试环境是同机房下netperf 940Mbit/s 的网络,</p>

<p><img src="https://i.imgur.com/dEev8CP.jpg" alt="Imgur" /></p>

<p>这里主要三个参数 WND 就是最大的pipeline 的个数, BSZ 就是最大的batch size, 三角形B是最大的batch 时候的timeout</p>

<p>从上面这个图可以看到</p>

<ol>
  <li>无论 request size 是多少, pipeline 个数对qps 几乎没有影响, 主要原因是因为这个时候的主要瓶颈是cpu, 因此提高pipeline 个数对结果没有影响</li>
</ol>

<p><img src="https://i.imgur.com/mGfwchr.jpg" alt="Imgur" /></p>

<p>上面这几图可以看出</p>

<ol>
  <li>4(a) 图中, 随着batch size 的增加,  平均每一个客户端请求的延迟是立刻降低的, 比如这里从最开始的500ms 降低到了100ms 左右</li>
  <li>4(b) 图中, 随着batch size 的增加, 执行每一个instance 的延迟是增加的,  因为这个batch 的大小增加了, 也可以理解</li>
  <li>4(c) 随着这里batch size 的提高, qps 虽然在降低, 但是因为每一个instance 中包含的请求数是增加的, 因此整体的吞吐是增加的, 比如这里batch size 最小的时候 只有2000, 那么也就是只有200 的qps, 而3(a) 图中可以看到, 在有一定的batch 大小以后, qps 是可以达到12000 的</li>
</ol>

<p>这里仍然可以看出, pipeline 的大小在同机房的场景下,是没有影响的</p>

<p><img src="https://i.imgur.com/ZkwUDm5.jpg" alt="Imgur" /></p>

<p>这个图中w = ⌈min(wcpu,wnet)⌉. w 表示的是在当前环境下, 最大化的利用资源时, pipeline 的个数, 可以看出, 在同机房的网络中, 几乎不需要pipeline 都可以达到最大值吞吐, 最大的资源利用率, 因此这里都可以看出wcpu 都会小于wnet, 因此cpu 一直都是瓶颈, 提高pipeline 是没有效果的.</p>

<ul>
  <li>在跨机房的场景中的仿真</li>
</ul>

<p>这里测试场景中replicas 的带宽是10Mbits, 延迟是50ms</p>

<p><img src="https://i.imgur.com/m1eRSDn.jpg" alt="Imgur" /></p>

<p>从上图可以看到, 在高延迟的跨机房场景中, 虽然通过batch 还是能够有非常明显的性能提升, 比如在WND=1 的情形下, 无论batch size 的大小都从只有个位数的 qps 到了 request size = 128 的时候有3000, request size = 1kb 的时候到达了 600 等等, 但是还是无法达到最大的吞吐,  在request size = 1kb, 8kb 的时候, 甚至只有最大吞吐的一半的性能,  因此可以看出在跨机房的场景中, 仅仅通过batch 是达不到最大的吞吐</p>

<p><img src="https://i.imgur.com/mW1cTR7.jpg" alt="Imgur" /></p>

<p>从上面图中可以看到,</p>

<p>上图(a) 中, 在高延迟的跨机房场景中, 在request size 比较小的时候, 仅仅通过pipeline 也同样达不到最大吞吐(这里k 表示的是一个batch 请求里面request 的个数),  但是在request size = 8kb 的时候, 是可以达到最大吞吐的.  为什么这样?</p>

<p>在request size 比较小的时候, 主要的瓶颈是cpu, 因此batching 能够降低平均每一个request 的cpu 利用率. 所以请求数就上来了, 但是当request size 比较大的时候, 那么这个时候主要瓶颈就是网络带宽或者网络延迟, 这个时候batch 就没用了. 当瓶颈是网络延迟的时候, pipeline 能够有效的提高吞吐, 但是当瓶颈是带宽的时候, 就没办法了</p>

<p>图(b),(c)还有一个结果是随着 pipeline window 大小的提高, 反而有性能的下降. 原因是pipeline 过多, 超过了网络的容量, 那么会导致包的丢失和重传, 进而影响了网络的效率.</p>

<p><img src="https://i.imgur.com/zZrOYlo.jpg" alt="Imgur" /></p>

<p>上图(a)可以看到在跨机房的网络中, 无论pipeline 的个数是多少, 使用batch 都能够明显降低客户端的延迟, 从原来的10s 降低到0.5s 左右,  pipeline 个数虽然也影响客户端的延迟, 但是影响的没有batch 那么明显.</p>

<p>同样这里的测试可以看到其实 WND=5的时候, Latency 就已经差不多是最小的了, 所以在polarstore 里面Praft 里面的LBA 的大小是2~5 其实就够了, 之前我一直以为pipeline 的话, 一般都需要有上百个pipeline 并行才会达到最大的吞吐, 但是在praft 中LBA 从1=&gt;2 就有了几乎翻倍的性能提升,  所以pipeline 其实不需要特别大, 有几个同时并行就够了.</p>

<p>上图(c) 可以看到通过batch 和 pipeline, 在跨机房的网络中,  同样如果batch size 比较小, 那么执行的instance 个数就比较多, 但是由于instance 中只包含1个request, 那么其实获得的qps 是不够高的, 需要选择合理batch size 才可以获得最大的qps. 比如这里合理的batch size 应该是20kb</p>

<p><img src="https://i.imgur.com/EDamqgm.jpg" alt="Imgur" /></p>

<p>从这里图里面可以看出 w 在request size 比较小并且batch size 也比较小的时候,  pipeline 个数需要 20~35 来实现最大的吞吐,  但是随着batch size 的增加, 其实还是只需要1~2 个来达到最大的吞吐. batch size 唯一的缺点是在压力不大的时候, request 也需要等待一段时间.</p>

<p><strong>Reference:</strong> 
https://pdfs.semanticscholar.org/a0d0/cdd2e8af1945c03cfaf2cb451f71f208d0c9.pdf</p>

</article>






  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'baotiao';
    var disqus_identifier = '/2018/05/02/batch-pipeline';
    var disqus_title      = 'Paper Review Optimizing Paxos with batching and pipelining';

    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>






      </div>
    </div>
  </div>

  <footer class="center">
</footer>


</body>
</html>
