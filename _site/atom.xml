<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title></title>
 <link href="http://baotiao.github.io//atom.xml" rel="self"/>
 <link href="http://baotiao.github.io/"/>
 <updated>2014-04-24T19:30:58+08:00</updated>
 <id>http://baotiao.github.io/</id>
 <author>
   <name></name>
   <email></email>
 </author>

 
 <entry>
   <title>一致性, 两阶段提交和事务提交的发展史(译)</title>
   <link href="http://baotiao.github.io//2014/04/consensus-history/"/>
   <updated>2014-04-17T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2014/04/consensus-history</id>
   <content type="html">&lt;p&gt;原文地址: http://betathoughts.blogspot.com/2007/06/brief-history-of-consensus-2pc-and.html&lt;br/&gt;
[注: 初次翻译, 这里面提到的论文可能理解不够, 有错误的地方感谢帮忙指出]&lt;/p&gt;

&lt;p&gt;这是关于一致性, 事务和两阶段提交的历史, 因为用词的变化导致阅读一致性相关的文章非常的麻烦(consensus 在较早以前都叫做agreement), 这些分布式相关的论文并没有按照逻辑的顺序产出, 并且整体的分布式算法是在并行发展的. 目前只有Lynch 的 Distributed Algorithm 这本书有这些主题&lt;/p&gt;

&lt;p&gt;接下来描述的Paper主要按他们的关联性排序, 并没有根据他们的出版时间进行排序.&lt;/p&gt;

&lt;p&gt;第一个我知道的关于一致性问题的实例是Lamport's &lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/time-clocks.pdf&quot;&gt;&quot;Time, Clocks and the Ordering of Events in a Distributed System&quot; (1978)&lt;/a&gt;, 虽然这篇文章没有严格的定义了一个一致性的问题. 在这个文章里面 Lamport 讨论了在有限的时间内消息是怎么在进程之间进行传输, 并且将进程之间传递消息和爱因斯坦的相对论进行的对比. 最近在博客上讨论分布式系统和爱因斯坦的相对论的关联非常的热门,但是在1978年的时候 Lamport就已经给出了一个完整的时空图的分析. 这个结论是在一个分布式系统里面, 只有A事件能够触发B事件的发生, 你才能够说明A事件发生在B事件前面, 否则是不行的. 不同的进程看到的事件的顺序是不一致的, 也就是在一个分布式系统里面, 只存在一个偏序关系, 不存在一个全序关系. Lamport 定义了&quot;happens before&quot; 关系和操作, 并且给出了一个在分布式系统里面全局的定义事件顺序关系的算法, 这样所有的进程看到的事件的顺序关系就是一致的&lt;/p&gt;

&lt;p&gt;Lamport还介绍了一个分布式的状态机: 所有的状态机以一个相同的初始状态启动, 并且保证所有的状态机处理的消息是一模一样的. 那么每一个状态机就是其他状态机的副本. 那么, 关键的问题是保证每一个副本约定好下一条要处理的消息: 一个一致性问题. 这个用上面给出的全局的定义事件顺序关系的算法可以做到的. 但是这个系统容错能力是不行的, 假如有一个进程失败了, 那么其他的进程必须等待他恢复.&lt;/p&gt;

&lt;p&gt;大约在这边论文发布的相同的时间, Gray 发布了两阶段提交协议的算法 &lt;a href=&quot;http://research.microsoft.com/%7EGray/papers/DBOS.pdf&quot;&gt;&quot;Notes on Database Operating Systems&quot; (1979)&lt;/a&gt;. 两阶段提交协议存在的问题是, 如果TM(Transaction Manager)在某些时刻如果失败了, 整个Transaction 就会阻塞. Skeen又发布了&lt;a href=&quot;http://www.cs.cornell.edu/courses/cs614/2004sp/papers/Ske81.pdf&quot;&gt;&quot;NonBlocking Commit Protocols&quot; (1981)&lt;/a&gt;这篇论文. 论文指出在一个分布式的事务里面, 需要一个三阶段的提交协议来避免在两阶段提交中存在的阻塞问题. 但是问题是这个一个完美三阶段提交协议需要将近25年的时间来完成一次提交!&lt;/p&gt;

&lt;p&gt;Fischer, Lynch and Paterson 在论文 &lt;a href=&quot;http://theory.lcs.mit.edu/tds/papers/Lynch/jacm85.pdf&quot;&gt;&quot;Impossibility of distributed consensus with one faulty process&quot; (1985)&lt;/a&gt;证明, 在一个异步系统里面, 只要有一个错误的进程, 一致性就不可能达成. 这个也就是著名的&quot;FLP&quot;结论. 在这个时间&quot;一致性&quot; 代表的是一堆进程同意同一个值的问题. 一个异步系统(异步系统指的是进程运行的速度不一定, 并且进程之间传递消息所需要的时间也不一定, 有可能无限长)在最完美的网络环境(这里的环境指的是所有的消息都会被送达, 消息送达的顺序和消息被发送的顺序是一致的, 并且消息是不会被多次的发送)下, 只要有一个进程出错, 这个一致性就无法达成. 这个问题的难点在于你不能判断一个进程是停止了还是跑的非常的慢. 处理一个在异步系统里面的错误几乎是不可能的. 这篇论文是非常重要的, 因为它告诉了我们什么事情是不可能的, 就像能量守恒定律对于永动机一样. 这篇文章证明过程是所有想要解决异步系统的一致性问题的算法必须有某些属性, 然后他们通过反证法证明了这些属性是不可能存在的.&lt;/p&gt;

&lt;p&gt;在这个阶段, 人们认为分布式系统分成同步的(进程运行在已知的速度, 并且在进程之间消息的传递在规定的时间到达) 和 异步的(进程运行在任意的速度, 并且进程间消息的传递时间不能保证). 异步的系统是一个更为常见的系统. 一个算法能够解决异步系统的一致性问题, 肯定也能够解决同步系统的一致性问题, 但是反过来不行.你可以把一个同步系统看成一个异步系统的特例, 同步系统是进程运行在规定速度, 进程之间传递消息有时间上线的一个异步系统.&lt;/p&gt;

&lt;p&gt;在FLP之前, 就有&lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/byz.pdf&quot;&gt;&quot;The Byzantine Generals Problem&quot; (1982)&lt;/a&gt;这篇论文. 在这个一致性问题里面, 进程可以传递错误信息, 并且他们积极的将这个错误信息传递给其他进程. 这个问题看起来比FLP结论更难, 但是在同步系统下, 还是有方法能够达成一致的(虽然在这篇文章发布的时候, 同步系统和异步系统的定义还没那么的明确). 但是这个方法在消息的传递的总量, 以及消息传递的轮数都非常的多, 因此性能不行. 这里Byzantine 将军问题最早的想法来自于航空业: 当一个飞机上的传感器捕获一个错误信息的时候该怎么办(这里的系统可以看成是同步系统).&lt;/p&gt;

&lt;p&gt;在1986年, 关注一致性的问题和事务的问题的人们聚集起来. 在那个时候, 最好的一致性算法就是上面提出的Byzantine Generals, 但是这个算法用来处理事务时间开销又太大. Jim Graw 在会议上发布了一篇文章 &lt;a href=&quot;http://research.microsoft.com/%7EGray/papers/TandemTR88.6_ComparisonOfByzantineAgreementAndTwoPhaseCommit.pdf&quot;&gt;&quot;A Comparison of the Byzantine Agreement Problem and the Transaction Commit Problem.&quot; (1987)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;这篇论文包含了这样一段话在开头 :-)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&quot;在这个会议之前, 大量的研究认为在分布式系统里面的事务提交是一个退化版本的Byzantine 将军问题. 可能这个会议最有用的结论是这两个问题没有任何的相关性&quot;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;最终分布式事务被看成了一个新版的一致性问题, 叫 uniform consensus (&lt;a href=&quot;http://infoscience.epfl.ch/getfile.py?recid=88273&amp;amp;mode=best&quot;&gt;&quot;Uniform consensus is harder than consensus&quot; (2000)&lt;/a&gt;). 在uniform consensus 里面, 所有的进程必须同意一个值, 包括哪些出错的进程. 一个事务在当且仅当所有的RMs(资源管理者)已经准备好要提交的时候, 才能够提交. 大部分的一致性只考虑到不出错的进程达成一致. Uniform consensus考虑的是所有的进程都达成一致, 所以Uniform consensus 是更难实现的&lt;/p&gt;

&lt;p&gt;最后 Lamport 在论文&lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/lamport-paxos.pdf&quot;&gt;&quot;The Part-Time Parliament&quot; (submitted in 1990, published 1998).&lt;/a&gt;提出了Paxos一致性算法. 不幸的是这篇论文用希腊明主投票做类比的写法让人们很难看懂, 所以这篇文章一直被忽略. 直到被Butler Lampson 在他的论文&lt;a href=&quot;http://research.microsoft.com/lampson/58-Consensus/Acrobat.pdf&quot;&gt;&quot;How to Build a Highly Availability System using Consensus&quot; (1996)&lt;/a&gt; 提起. 这篇论文介绍了如何使用Paxos来建立一个容错的系统. 后来Lamport 才又发布了&lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf&quot;&gt;&quot;Paxos Made Simple (2001)&quot;&lt;/a&gt;, 写的让大家都看的明白.&lt;/p&gt;

&lt;p&gt;Paxos最核心的问题是, 给定一个固定数目的进程, 这些进程的大部分定义为至少和其他的这个进程的大部分有一个相同的进程. 比如: 有A, B, C三个进程. 那么可能的这些进程大部分是AB, AC, BC. 如果有一个决定被某一个大部分通过, 比如AB. 那么任意一个时刻一个大部分的集合包含A或者B. 这样这些大部分的集合其它元素就可以从A, B那边获得这个决定的值.&lt;/p&gt;

&lt;p&gt;Paxos能够容忍信息丢失, 消息的延迟, 消息的重复发送以及消息的乱序到达. 如存在一个唯一一个在足够长的时间内能够对某一个大部分集合进行两次访问的Leader, 那么这个系统就能达到一致. 任何进程, 包括Leader都可以失败或者重启. 实际上所有的进程允许在同一个时刻同时失败, 这个时候这个算法仍然是安全. 并且这个算法容忍在某一个时候有多个主存在.&lt;/p&gt;

&lt;p&gt;Paxos是一个解决异步系统一致的算法; 这里并没有严格的超时限定. 然而只有当这个异步的系统表现出在同步的状态的情况下, 这个系统才能够达到一致. 在这个系统表现出在异步的状态的时候, 这个系统无法达成一致, 但是这个时候是安全的, 不会返回错误的结果. 有一个特殊的情形下Paxos是无法达成一致的, 这也是符合&quot;FLP&quot;的结论. 但是在实现的时候很容易避免这个情形.&lt;/p&gt;

&lt;p&gt;明确的将系统分成同步和异步有点太过宽泛. Dwork, Lynch 和 Stockmeyer定义了一个偏序的同步系统 &lt;a href=&quot;http://theory.lcs.mit.edu/tds/papers/Lynch/jacm88.pdf&quot;&gt;&quot;Consensus in the presence of partial synchrony&quot; (1988)&lt;/a&gt;. 存在两个版本的偏序同步系统: 一种是进程运行在某一个固定的速度并且消息在某一个规定的时间内传达, 但是这个某一个值是多少事先是不知道的. 另一种是进程运行的速度范围以及消息送达的时间是事先可以知道的, 但是他们保持这种状态仅仅是在未来的一段时间内, 这个时间有多长, 我们不知道. 比起同步系统和异步系统, 这个偏序的同步系统更接近现实世界.网络在绝大部分的情况下应该是可预测的, 但是偶然还是会变的不可预测.&lt;/p&gt;

&lt;p&gt;Lamport 和 Gray 在论文&lt;a href=&quot;http://research.microsoft.com/research/pubs/view.aspx?tr_id=701&quot;&gt;&quot;Consensus on Transaction Commit&quot; (2005)&lt;/a&gt;里继续尝试将Paxos应用到分布式事务系统里, 他们使用Paxos替换掉了两阶段提交里面的Transtraction Manager, 并且对每一个Resource Manager使用一个Paxos实例用来判断是否同意这个Resource Manager提交这个事务.表面上, 每一个Resource Manager 使用一个Paxos看过去成本特别高, 但是事实上不是的. 在没有错误的情况下, Paxos提交在两个阶段就会完成. 它和两阶段提交有着相同的消息延迟, 虽然可能会多传送一部分消息. 在有错误的情况下, Paxos的第三个阶段是需要的, 这个和Skeen 的结论也是一致的. 给定2n + 1个TM副本, Paxos的提交可以容忍n个错误的副本. Paxos提交不需要用Paxos直接解决事务提交的问题. Paxos 没有用来解决uniform consensus, 而是用来使这个系统容灾能力更强.&lt;/p&gt;

&lt;p&gt;因为两阶段提交是阻塞的是无效的, Paxos 提交忙于解决阻塞这个问题. 所以有些人认为分布式事务不应该被使用.&lt;/p&gt;

&lt;p&gt;最近有一些关于CAP(Consistency, Availability, Partition)猜想的讨论.这个猜想断言你不可能在一个分布式系统里面同时满足这三个属性, 也就是不存在一个系统, 它是一致的, 在有错误的进程存在并且有可能出现网络分区的情况下.&lt;/p&gt;

&lt;p&gt;我们通过把Consistency 看成Consensus来检查一下这个CAP猜想, 对于一个异步系统, 根据FLP理论, 只要存在一个进程错误的情况下, 这个系统就无法达成一致. 所以对于一个异步的系统我们不能同时有一致性和可用性.&lt;/p&gt;

&lt;p&gt;现在我们再看一下一个有三个节点的Paxos系统:A, B, C. 加入有两个节点在工作, 我们就能够达到一致. 那么我们就能实现一致性和可用性. 现在假如C被单独隔离了, 而这个时候有请求访问到C, 这个时候C是无法返回的, 因为必须有超过两个节点才能够返回结果, 而这个时候C无法和A, B节点通信的. C此刻是不知道是它自己被分区隔离了还是另外的两个节点都挂掉了, 还是说这个时候的网络特别慢的问题. 另外的两个节点能够继续的工作, 因为她们两个能够通信, 就可以超过半数的返回结果了. 所以对于CAP理论而言, Paxos并没有分区容错性, 因为这个时候C是无法对用户的请求回应的. 然而我们在工程上绕过这个问题. 假如在同一个数据中心里面, 我们可以使用两个独立的网络连接不同的节点, 因为Paxos可以容忍数据的重复发送.&lt;/p&gt;

&lt;p&gt;对于一个同步的网络,假如C被分区了, 假如C在规定的周期内没有收到信息, 那么C能够知道它自己被分区了. 然后C就能够从客户端的访问中摘除掉了.&lt;/p&gt;

&lt;p&gt;Paxos, Paxos Commit 和 HTTP/REST 已经被合并起来建立一个高可用的同配置网格计算系统. 详细的信息可以从这里获得&lt;a href=&quot;http://www.cct.lsu.edu/%7Emaclaren/HARC/&quot;&gt;HARC&lt;/a&gt;, 以及更多的在这个文章里面的讨论&lt;a href=&quot;http://www.allhands.org.uk/2006/proceedings/papers/624.pdf&quot;&gt;&quot;Co-Allocation, Fault Tolerance and Grid Computing&quot; (2006).&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>两阶段提交协议</title>
   <link href="http://baotiao.github.io//2014/03/two-phase-commit/"/>
   <updated>2014-03-28T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2014/03/two-phase-commit</id>
   <content type="html">&lt;p&gt;组内的一个分享, 两阶段提交协议&lt;/p&gt;

&lt;iframe src=&quot;http://www.slideshare.net/slideshow/embed_code/32843186&quot; width=&quot;476&quot; height=&quot;400&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;/iframe&gt;

</content>
 </entry>
 
 <entry>
   <title>多IDC冲突常见解决方案</title>
   <link href="http://baotiao.github.io//2014/03/conflict-solution/"/>
   <updated>2014-03-14T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2014/03/conflict-solution</id>
   <content type="html">&lt;h2&gt;多IDC冲突常见解决方案&lt;/h2&gt;

&lt;p&gt;在分布式系统里面我们会经常遇到多个Client对同一个Key进行了修改, 如果系统不想解决冲突, 那么默认的解决方案是选取时间戳最新的那个结果. 不过有时候业务经常会对一个Key进行局部修改,然后保存. 这个时候其实业务想要的是几次操作的合并.&lt;/p&gt;

&lt;p&gt;比如Key=name:baotiao|age:18 一个Client更新了这个Key, 变成Key=name:chenzonghzi|age:18. 另外一个Client同时也更新了这个Key, 变成 Key=name:baotiao|age:20 这个时候常见的按照最后的时间戳的解决方案会带来问题是只能获得其中一个的结果. 有什么比较好的解决方案么?&lt;/p&gt;

&lt;p&gt;这里介绍三个解决方案.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;h3&gt;Dynamo Vector Lock解决方案&lt;/h3&gt;

&lt;p&gt; Vector Lock的核心思想就是Client对这个数据的了解是远远超过服务端的, 因为对于服务端而言, 这个Key 对应的Value 对于Server 端只是一个字符串. 而Client 端能够具体了解这个Value 所代表的含义, 对这个Value 进行解析. 那么对于这个例子. 当这两个不一样的Value写入到两个副本中的时候, Client进行一次读取操作读取了多个副本.&lt;/p&gt;

&lt;p&gt; Client 发现读到的两个副本的结果是有冲突的, 这里我们假设原始的Key的Vector Lock信息是[X:1], 那么第一次修改就是[X:1,Y:1], 另一个客户端是基于[X:1]的Vector Lock修改的, 所以它的Vector Lock信息就应该是[X:1,Z:1]. 这个时候我们只要检查这个Vector Lock信息就可以可以发现他们冲突, 这个就是就交给客户端去处理这个冲突.并把结果重新Update即可&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;h3&gt;Cassandra 的解决方案&lt;/h3&gt;

&lt;p&gt; Cassandra 的解决方案就是讲一个Key尽可能小粒度的拆分, 所以我们看到在Cassandra里面有RowKey的概念, 通常将一个data分成多个部分. 比如这里存的Key_name=name:baotiao, Key_age=age:18. 那么两次修改分别修改了两个表, 那么最后我们查询的时候在Key_name列里面我们看到的最新时间戳的肯定是Key_name=name:chenzongzhi, Key_age=age:20. 这样我们就可以得到这个Key最新的结果&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;h3&gt;Yahoo! Pnuts 的Primary Key解决方案&lt;/h3&gt;

&lt;p&gt; 这里我们对每一个Key 有一个Primary IDC, 也就是这个Key的修改删除等操作都只会在当前这个IDC完成, 然后读取可以有多个IDC去读取. 那么因为对于同一个Key的修改, 我们都在同一个IDC上. 我们通过给每一个Key加上一个Version信息, 类似Memcached的cas操作, 那么我们就可以保证做到支持单条数据的事务.&lt;br/&gt;
 如果这条数据的Primary IDC是在本机房, 那么插入操作很快.&lt;br/&gt;
 如果这条数据的Primary IDC不是本机房, 那么就有一个Cross IDC的修改操作, 延迟将会比较高.不过我们考虑一下我们大部分的应用场景, 90%的数据的修改应该会在同一个机房. 比如一个用户有一个profile信息, 那么和修改这个信息的基本都是这个用户本人, 90%的情况下应该就是在同一个地点改, 当然写入也会在同一个机房. 所以大部分的修改应该是同一个机房的修改.&lt;br/&gt;
 当然为了做优化, 有些数据可能在一个地方修改过了以后, 多次在其他地方修改, 那么我们就可以修改这个Key的Primary IDC 到另外这个机房&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;后话&lt;/h3&gt;

&lt;p&gt;这里提到的方案只是我个人的理解, 有不对的地方,还望大家指出
目前我觉得Yahoo!这套方案比较适合用来处理业务对数据的丢失比较敏感的方案, 虽然牺牲了10%写的性能不过我感觉能够接受&lt;br/&gt;
Dynamo 的方案问题在于有时候客户端虽然可以获得这个数据, 但是客户端也不知道如何处理这个冲突, 简单的方案可以做Merge, 复杂的结构就不好处理了.&lt;br/&gt;
Cassandra 的方案在读取方面性能可能有损失, 因为毕竟将一个Key 分成了多个Key以后, 每一次的读取操作都要合并多个Key的结果&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Leveldb write </title>
   <link href="http://baotiao.github.io//2014/02/leveldb-write/"/>
   <updated>2014-02-12T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2014/02/leveldb-write</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;年前分享了LevelDB的时候遗留了一个问题
就是在LevelDB Write操作的时候, 如何做到线程安全的, 以及在代码里面为什么要同时通知这么多个的线程
    while (true) {
        Writer* ready = writers_.front();
        writers_.pop_front();
        if (ready != &amp;amp;w) {
            ready-&amp;gt;status = status;
            ready-&amp;gt;done = true;
            ready-&amp;gt;cv.Signal();
        }
        if (ready == last_writer) break;
    }

重新看了一下代码应该是这个样子的
Status DBImpl::Write(const WriteOptions&amp;amp; options, WriteBatch* my_batch) {
    // 这里用到的就是标准的 condition variable 配合 mutex 使用的例子,
    // 这里在这个while 里面添加的 w != writes_.front() 同时又保证了只有一个写
    Writer w(&amp;amp;mutex_); // 这个w锁是一个条件变量, 传入的mutex_是交给条件变量里面的mu_的
    w.batch = my_batch;
    w.sync = options.sync;
    w.done = false;

    // NICE
    // 这里写的也很精妙, 之所以用MutexLock 来实现, 是因为这样只要在中途退出就会自动
    // 触发这个MutexLock的析构函数, 析构函数里面写了unLock这个锁的操作, 那么就可以不用在
    // 每个中间的return 前面都加上这个l-&amp;gt;unLock()操作
    MutexLock l(&amp;amp;mutex_); // 这里的操作是在做pthread_cond_wait之前把mutex_锁住的操作, 这样保证pthread_cond_wait的时候不会死锁
    writers_.push_back(&amp;amp;w);
    //这里用一个队列, 并且只有在队列最头部的那个writeBatch才会被写. 所以进入到下面Write的过程只会有一个线程
    while (!w.done &amp;amp;&amp;amp; &amp;amp;w != writers_.front()) {
        w.cv.Wait(); //这里是condition varaible, 这里wait 的时候会同时把mu_这个锁放开
    }
    /* 之前解释说这里w.done 是写代码写的很小心, 是错误的, 具体解释见下面 */
    if (w.done) {
        return w.status;
    }
    // 接下来处理的就是这个writers_ 里面最头的那个的信息

    // May temporarily unlock and wait.
    // 这里是检查memtable有没有空间可以写入, 如果没有就换一个buffer 和 compaction等操作
    Status status = MakeRoomForWrite(my_batch == NULL);
    uint64_t last_sequence = versions_-&amp;gt;LastSequence();
    Writer* last_writer = &amp;amp;w;
    if (status.ok() &amp;amp;&amp;amp; my_batch != NULL) {  // NULL batch is for compactions

        /*  主要的地方就是这个BuildBatchGroup 函数, 这个函数做的是将这个队列里面前几个的Writer, 合并成一个Batch.
            这么做的原因我想主要也是为了性能考虑, 因为这里我们每一次的Put, 都是一个batch, 所以这里会将多个的batch
            合并成一个Batch来进行处理, 这样能明显的提高性能.
            所以这里将队列的前几个Batch合并成了一个Batch, 由当前的Batch处理了. 所以刚才上面那个代码会判断一下当前的这个
            Write 是否已经被处理好了

            代码见下面
        */

        WriteBatch* updates = BuildBatchGroup(&amp;amp;last_writer);

        WriteBatchInternal::SetSequence(updates, last_sequence + 1);
        last_sequence += WriteBatchInternal::Count(updates);

        // Add to log and apply to memtable.  We can release the lock
        // during this phase since &amp;amp;w is currently responsible for logging
        // and protects against concurrent loggers and concurrent writes
        // into mem_.
        {
            //因为到这里的时候 只有一个writers_里面的一个能到达这里. 所以这里可以保证这有一个线程到了可以AddRecord这一步了.
            //所以这里把锁release掉

            mutex_.Unlock();
            status = log_-&amp;gt;AddRecord(WriteBatchInternal::Contents(updates));
            if (status.ok() &amp;amp;&amp;amp; options.sync) {
                status = logfile_-&amp;gt;Sync();
            }
            if (status.ok()) {
                status = WriteBatchInternal::InsertInto(updates, mem_);
            }
            mutex_.Lock();
        }
        if (updates == tmp_batch_) tmp_batch_-&amp;gt;Clear();

        versions_-&amp;gt;SetLastSequence(last_sequence);
    }

    /*  这里循环判断已经被处理掉的batch, 设置done = true, 并从队列里面取出, 并Pop()掉, 可以看出
        这里都是因为上面做了Batch合并, 同时处理了多个Batch. 所以这里可以直接将这个done = true. 并
        触发这个线程, 然后线程进入刚才的Wait()判断成功. 然后
        if (w.done) {
        return w.status;
        }
        就直接退出了
        就相当于队里头部的这个线程, 完成多其他线程的几个的写操作
    */

    while (true) {
        Writer* ready = writers_.front();
        writers_.pop_front();
        if (ready != &amp;amp;w) {
            ready-&amp;gt;status = status;
            ready-&amp;gt;done = true;
            ready-&amp;gt;cv.Signal();
        }
        if (ready == last_writer) break;
    }

    // 这里之前已经把合并一起的Batch都处理完了, 并且已经处理的Batch都从队列里面Pop()出去了, 然后现在就
    // 唤醒当前队列最前面的线程
    if (!writers_.empty()) {
        writers_.front()-&amp;gt;cv.Signal();
    }

    return status;
}

WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {
    assert(!writers_.empty());
    Writer* first = writers_.front();
    WriteBatch* result = first-&amp;gt;batch;
    assert(result != NULL);

    size_t size = WriteBatchInternal::ByteSize(first-&amp;gt;batch);

    // Allow the group to grow up to a maximum size, but if the
    // original write is small, limit the growth so we do not slow
    // down the small write too much.
    size_t max_size = 1 &amp;lt;&amp;lt; 20; // 这个size 是设置合并的WriteBatch 的大小
    if (size &amp;lt;= (128&amp;lt;&amp;lt;10)) {
        max_size = size + (128&amp;lt;&amp;lt;10);
    }

    *last_writer = first;
    std::deque&amp;lt;Writer*&amp;gt;::iterator iter = writers_.begin();
    ++iter;  // Advance past &quot;first&quot;
    for (; iter != writers_.end(); ++iter) {
        Writer* w = *iter;
        if (w-&amp;gt;sync &amp;amp;&amp;amp; !first-&amp;gt;sync) {
            // Do not include a sync write into a batch handled by a non-sync write.
            break;
        }

        if (w-&amp;gt;batch != NULL) {
            size += WriteBatchInternal::ByteSize(w-&amp;gt;batch);
            if (size &amp;gt; max_size) {
                // Do not make batch too big
                break;
            }

            // Append to *reuslt
            if (result == first-&amp;gt;batch) {
                // Switch to temporary batch instead of disturbing caller's batch
                result = tmp_batch_;
                assert(WriteBatchInternal::Count(result) == 0);
                WriteBatchInternal::Append(result, first-&amp;gt;batch);
            }
            WriteBatchInternal::Append(result, w-&amp;gt;batch);
        }
        *last_writer = w;  // 同时更新最后的last_writer 到队列里面最新的last_writer
    }
    return result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;总结:    LevelDB Write 的线程安全是通过将所有的写入插入到一个队列中, 然后有且仅有一个线程去消费这个队列来做到的. 消费这个队列的线程会把队列头部的几个Batch合并成一个大的Batch 一起消费掉, 也是为了提高效率.&lt;/h3&gt;
</content>
 </entry>
 
 <entry>
   <title>CAP theorem</title>
   <link href="http://baotiao.github.io//2014/01/cap-theorem/"/>
   <updated>2014-01-02T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2014/01/cap-theorem</id>
   <content type="html">&lt;h3&gt;CAP theorem (摘自维基百科)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Consistency (all nodes see the same data at the same time)&lt;/li&gt;
&lt;li&gt;Availability (a guarantee that every request receives a response about whether it was successful or failed)&lt;/li&gt;
&lt;li&gt;Partition tolerance (the system continues to operate despite arbitrary message loss or failure of part of the system)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这里 Availability 可以这么理解, 就是在单位的时间内, 这个分布式系统能否给你返回一个成功或者失败.&lt;/p&gt;

&lt;h3&gt;实际工作例子&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;数据的一致性
当客户端写入数据, 考虑可用性和一致性的折中&lt;br/&gt;
可以配置是要eventual consistency 还是 strict consistency.

&lt;ul&gt;
&lt;li&gt;方案一: 主写入BinLog, 直接返回成功. 然后是将记录插入到DB中, 然后同步给从BinLog, 然后从将数据插入到DB中&lt;/li&gt;
&lt;li&gt;方案二: 主写入BinLog, 然后写入DB成功后返回成功. (Dynamo 在W参数 = 1 的时候情形). 然后从同步BinLog, 然后从将数据插入到DB中&lt;/li&gt;
&lt;li&gt;方案三: 主写入BinLog, 写DB同步数据给从的BinLog. 然后返回成功. (Mola, BigTable, Dynamo在W参数= 2 是这个情形). 然后从将数据插入到DB中&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 可以看出方案一到三是 一致性越来越强, 可用性越来越弱的过程.(这里指的是用户的写会越来越慢, 只有之前的事物完成,才算完成) 我们最后选择的方案二, 因为我们这里对一致性的需求没有那么强烈, 如果等到将数据同步. 我们的性能是不允许的&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>How redis implement data structure</title>
   <link href="http://baotiao.github.io//2013/11/survey-redis/"/>
   <updated>2013-11-23T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/11/survey-redis</id>
   <content type="html">&lt;ol&gt;
&lt;li&gt;redis implement the append command by realloc the space need by the function.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;When we append the value. Redis first Makeroom for the result.  Redis control the memory by double the memory. The copy the chars to new space by memcpy.&lt;br/&gt;
2. use copy-on-write technology to make as less copy as possible.&lt;br/&gt;
3. &lt;strong&gt;how redis implement list?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;redid really implement two kind of list.&lt;/p&gt;

&lt;p&gt;the first is the zip list, it is also the default list.  every time we have the value the size, we will transfer the zip list the the second link list.&lt;/p&gt;

&lt;p&gt;Why redis implement this way. Because We know link list is the as fast as zip list. At the beginning of time, we just need small space. So we can first encode the chars and store the value. Then if we need the value, what we need to do is just to decode the memory. So It is very quickly. As the data grow, the space is not big enough, and every time the decoding is also waste of time .&lt;/p&gt;

&lt;p&gt;So we need to modify the way we save data, we just put the data in link list, and we travel the list by the point.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>vector locks</title>
   <link href="http://baotiao.github.io//2013/11/vector-locks/"/>
   <updated>2013-11-12T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/11/vector-locks</id>
   <content type="html">&lt;p&gt;vector locks 是Amazon 的Dynamo 论文提出的一个处理冲突的解决方案&lt;/p&gt;

&lt;p&gt;核心思想是由于server知道的信息有限, 如果发生了冲突, 能做的做大的办法
就是根据timestamp取最新的数据. 如果把冲突放在客户端解决, 由于客户端
知道数据所代表的含义, 那么冲突可以得到更好的解决&lt;/p&gt;

&lt;p&gt;vector locks 很好理解, 可以看:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://basho.com/why-vector-clocks-are-easy/&quot;&gt;why-vector-clocks-are-easy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;vector locks 存在的问题:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://basho.com/why-vector-clocks-are-hard/&quot;&gt;why-vector-clocks-are-hard&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;为什么Cassandra 不用vector locks. 然后Cassandra的解决方案是什么&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.datastax.com/dev/blog/why-cassandra-doesnt-need-vector-clocks&quot;&gt;why-cassandra-doesnt-need-vector-clocks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cassandra的解决方案是将一行拆成多列, 然后分别更新. 这样就解决的vector clocks 最擅长解决的问题局部冲突解决的问题.
不过我感觉带来的问题也有就是 将一行拆成多列以后, 获取数据的时候如何保证获取到一致的版本? 还有存储的空间肯定加大了.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Basho levelDB 改进</title>
   <link href="http://baotiao.github.io//2013/11/leveldb-eleveldb/"/>
   <updated>2013-11-11T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/11/leveldb-eleveldb</id>
   <content type="html">&lt;h1&gt;eleveldb 对 leveldb 的改进&lt;/h1&gt;

&lt;h2&gt;整体改进目标&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;服务方面: Riak 需要在压力比较大的互联网环境使用. 所以增加了硬件的CRC校验, 增强了Bloom filter 的命中率, 还有默认的数据的完整性的检查&lt;/li&gt;
&lt;li&gt;多数据库支持: Riak 会同时打开 8-64个数据库. Google的leveldb也支持这些, 不过他的compaction 线程不支持这些.
具体的做法是当这个 compaction thread 有太多的事情要做的时候, 就停止让用户写入这些数据.
Basho 的leveldb 的改进包括多个线程同时锁住, 让优先级更高的的线程进行compaction 操作&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;Basho 与 官方对比&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;官方: 只限制sst文件的大小&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basho: 限制sst文件的大小同时限制sst文件key的个数&amp;lt;75000&lt;/p&gt;

&lt;p&gt;原因: 为了控制bloom filter中key的个数, 反正key过多bloom filter的命中率降低&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方: LevelDB 的每个级别的sst文件大小&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basho: 定制了每个级别的sst文件大小&lt;/p&gt;

&lt;p&gt;原因: 因为一个进程需要打开64个levelDB实例, 所以需要限制levelDB单个实例的open_files.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方: 没有统计当前DB的key个数等方法&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basho: 增加统计工具. 通过在sst文件的头部添加统计结构, 可以统计每一个sst文件中key 的个数&lt;/p&gt;

&lt;p&gt;原因: 方便管理统计&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方: 没有DB的操作数的记录统计&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basho: 在Leveldb进程加入shared memory segment, 用来统计Get, Put, OpenFile 等当前信息&lt;/p&gt;

&lt;p&gt;原因: 方便管理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方: 当Compaction线程落后很多的时候, 会不可写&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basho: 增加Compaction线程, 每个线程有优先级.优先级最高的是imm_ 到 Level 0的Compaction&lt;/p&gt;

&lt;p&gt;原因: 因为当imm&lt;em&gt;满的时候, 写入是不允许的. 增加Compaction的优先级, 可以优先满足imm&lt;/em&gt;到Level 0 的Compaction
具体的做法是这样:
有4个线程 normal,  level0 =&gt; level1, background unmap (目前没用), imm_ =&gt; level0&lt;/p&gt;

&lt;p&gt;每个线程各自维护着自己要Compaction的Item, 当出现imm_到level0 的线程需要Compaction 而normal 线程正在Compaction的时候,&lt;/p&gt;

&lt;p&gt;会把normal这个线程里面的Item删除, 加入imm&lt;em&gt; =&gt; level0 的需要Compaction的Item. 这样能有效的提高了imm&lt;/em&gt; =&gt; level0 Compaction的效率&lt;/p&gt;

&lt;h2&gt;具体参数调整&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;write_buffer_size: Riak 会随机把这个write_buffer_size 设置在30MB ~ 60MB 之间, 而默认大小是 4MB.
这样带来的影响是log文件的大小变大, 同样level0 的文件的大小也相应的增大了&lt;/li&gt;
&lt;li&gt;max_open_files: Riak 考虑了max_open_files 对内存的影响, 因为这个 max_open_files 对应的是打开的table_cache的数量, 因此Riak 减少了这一部分的cache&lt;/li&gt;
&lt;li&gt;具体计算哪一个级别需要进行compaction的 score上进行了修改&lt;/li&gt;
&lt;li&gt;对每个级别的sst 文件的大小,  每个级别的MaxBytes, m_DesireBytesForlevel 进行了调整, 而原来leveldb 是每个级别的sst 的大小均为2M,

&lt;h4&gt;可以看出 eleveldb 调整了 write_buffer_size 的大小, 调整了每个级别的sst 文件的大小, 调整了每个级别能有MaxBytesForLevel 等等参数都是为了减少sst 文件的数目.因为Riak 的实现里面也是一个进程开了多个 eleveldb 的实例, 所以如果文件比较多, 那么打开的open_files 就比较多.很容易超出进程的open files.&lt;/h4&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>levelDB Compaction 相关</title>
   <link href="http://baotiao.github.io//2013/10/leveldb-compaction/"/>
   <updated>2013-10-15T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/10/leveldb-compaction</id>
   <content type="html">&lt;h1&gt;levelDB&lt;/h1&gt;

&lt;h2&gt;level DB 如何选择要Compaction的级别&lt;/h2&gt;

&lt;p&gt;这个计算级别的函数在version_set::Finalize() 里面&lt;/p&gt;

&lt;p&gt;在Finalize里面, 有一个算score的过程&lt;/p&gt;

&lt;p&gt;看了一下这个 算Finalive的过程, 根据官方配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;level 0: 差不多 4 个 sst 文件的时候分数 = 1
level 1: 差不多 5 个 sst 文件的时候分数 = 1
level 2: 差不多 50 个 sst 文件的时候分数 = 1
level 3: 差不多 500 个 sst 文件的时候分数 = 1
……
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finalize 只会在 LogAndApply 和 VersionSet::Recover() 的时候被调用, 也就是生成一个新的Version 的时候被调用.&lt;/p&gt;

&lt;p&gt;结论: 所以可以这么说 每次生成一个新的Version 的时候 我们都已经初始化好了这个分数, 判断这一个version 是否需要 compaction 以及那个级别需要compaction&lt;/p&gt;

&lt;h2&gt;level DB 会触发Compaction的操作&lt;/h2&gt;

&lt;p&gt;触发这个MaybeScheduleCompaction() 的地方应该就是有可能触发后台这个Compaction的地方了, 目前会调用到这个MaybeScheduleCompaction() 的地方有&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在进行了一次Compaction 以后, 也就是在DBImpl::Background()函数里面&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;为什么要做Compaction 因为可能会产生太多的新文件在新的一个级别, 所以会检查一下是否需要再进行一次Compaction&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在进行了一次 DBImpl::Get 操作了以后, 如果这个数据是在sst的文件里面找到的.
get的时候找到的这个key存在多个level 0 的文件里面那么就会触发compaction&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;为什么要做Compaction 因为如果一个key在多个文件里面找到,那么说明这个key在多个level 0的文件里面重复了, 所以检查一下是否需要进行compaction
    if (have_stat_update &amp;amp;&amp;amp; current-&gt;UpdateStats(stats)) { // 这里如果有更新, 那么会判断是否启动后台的Compaction() 进程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在 DBImpl::Write 的 MakeRoomForWrite 函数里面, 当immutable 生成一个level 0 文件的时候, 会检查一下是否需要Compaction, 这样会防止level 0 文件过多.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;为什么要做Compaction 这时候做Compaction, 主要为了防止不断的从immutable 生成到level 0 文件, 一直触发immutable到level0 过程, 而没有时间进行其他级别的合并 并且在MakeRoomFroWrite 的时候, 我们会检查一下 如果level0 的文件数 &gt; config::kL0_SlowdownWritesTrigger 这个数据的大小的话. 那么我们 就会sleep 一段时间, 也是为了让出时间给其他级别进行Compaction&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在DB::Open() 这里函数里面, 如果Recover 成功以后, 并且进行了
s = impl-&gt;versions&lt;em&gt;&gt;LogAndApply(&amp;amp;edit, &amp;amp;impl&gt;mutex&lt;/em&gt;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;为什么要做Compaction 这里会将可以上次DB关闭以后没有来得及写入的数据重新回放, 所以这里可能会生成新的level 0的文件, 所以这里也会进行 检查 MaybeScheduleCompaction().&lt;/p&gt;

&lt;h2&gt;具体的MaybeCompaction() 过程&lt;/h2&gt;

&lt;h4&gt;函数入口&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;void DBImpl::MaybeScheduleCompaction() {
mutex_.AssertHeld();
// 如果后台有Compaction 线程, 那么直接退出
if (bg_compaction_scheduled_) {
            // Already scheduled
            // 如果db 要被 shut_down, 直接退出
        } else if (shutting_down_.Acquire_Load()) {
            // DB is being deleted; no more background compactions
            // 如果 imm_ 这个文件还是空的, 并且是manual_compaction是空的, 这里
            // TODO
        } else if (imm\_ == NULL &amp;amp;&amp;amp;
manual_compaction\_ == NULL &amp;amp;&amp;amp;
\!versions_-&amp;gt;NeedsCompaction()) {
            // No work to be done
        } else {
            // 设置这个后台有compaction 线程已经启动
            bg_compaction_scheduled_ = true;
            env_-&amp;gt;Schedule(&amp;amp;DBImpl::BGWork, this); //调用下面的 BGWork函数. 这里虽然是env_, 当时这env_里面会调用这个函数指针, 调用DBImpl::BGWork 这个函数
        }
}

* 在PosixEnv::Schedule 这个函数里面

void PosixEnv::Schedule(void (*function)(void*), void\* arg) {
PthreadCall(&quot;lock&quot;, pthread_mutex_lock(&amp;amp;mu_));

// Start background thread if necessary
// 看是否有后台线程已经启动, 如果没有启动就启动这个后台线程, 并执行一个死循环
// 具体的执行是BGThreadWrapper \-&amp;gt; BGThread 这个函数,
// 在BGThread 函数就是一个死循环, 不断的从这个queue\_ 里面读出, 这个是FIFO的形式
// 读出, 先进先出. 没有做一个优先级的概念.
if (\!started_bgthread_) {
                started_bgthread_ = true;
                PthreadCall(
                        &quot;create thread&quot;,
                        pthread_create(&amp;amp;bgthread_, NULL,  &amp;amp;PosixEnv::BGThreadWrapper, this));
            }

// If the queue is currently empty, the background thread may currently be
// waiting.
// 如果这个queue\_ 里面的数据当前是空的, 则等待cond 锁让它起来
if (queue_.empty()) {
                PthreadCall(&quot;signal&quot;, pthread_cond_signal(&amp;amp;bgsignal_));
            }

// Add to priority queue
queue_.push_back(BGItem());
queue_.back().function = function; // 这里注册的函数是 &amp;amp;DBImpl::BGWork
queue_.back().arg = arg; // 这里arg 是 db-&amp;gt;this指针

PthreadCall(&quot;unlock&quot;, pthread_mutex_unlock(&amp;amp;mu_));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;接下来是具体执行 函数 BackgroundCall() -&gt; BackgroundCompaction().&lt;/h4&gt;

&lt;p&gt;在BackgroundCompaction() 函数里面&lt;/p&gt;

&lt;p&gt;优先 compaction immutable -&gt; level0 sst&lt;/p&gt;

&lt;p&gt;然后 我们都是!is_manual 的, 那么我们就要选择去Compaction() 那个级别的.&lt;/p&gt;

&lt;p&gt;在versions_-&gt;PickCompaction().&lt;/p&gt;

&lt;p&gt;这里我们有之前在Finalfize() 里面算出来的compaction_score_, 如果这个score &amp;lt; 1 就不进行compaction.&lt;/p&gt;

&lt;p&gt;这里可以看到并不是每次检查是否需要Compaction 的时候都会进行. 只有score &gt;= 1 的时候levelDB才会选一个级别进行Compaction()&lt;/p&gt;

&lt;p&gt;在选择好Compaction的级别以后. 就调用BackgroundCompaction&lt;/p&gt;

&lt;p&gt;如果生成的这个Compaction 是空的, 那么就不进行Compaction
选择是否能直接将这个文件移动到level + 1, 而不用与level + 1 的文件进行归并的计算
进行真正的Compaction DoCompactionWork() 函数&lt;/p&gt;

&lt;h4&gt;在DoCompactionWork()函数里面&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;对这些指针进行归并, 归并出一个MergeIterator input.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;具体的iterator 看leveldb iterator&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;遍历获得的需要合并的数据, 如果这个key以前是否出现.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;如果已经出现过了就不会再进行处理 因为leveldb 里面对相同的key是进行过排序的. 默认squencenumber 最大的排在最前面, 也就是最新的数据排在最前面.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;如果这个key 的squenctNumber &amp;lt; 当前快照的版本号, 说明这个key 是旧的了.
如果这个key 的类型是delete, 并且更高级别已经没有这个key的数据了, 那么这个key也会被drop掉
可以看出, levelDB 这里做了这些操作也都是尽可能的减少key的数量
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;接下来就把这些剩余的key插入到新的version里面&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>levelDB Get过程</title>
   <link href="http://baotiao.github.io//2013/09/leveldb-Get/"/>
   <updated>2013-09-05T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/09/leveldb-Get</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;Status DBImpl::Get(const ReadOptions&amp;amp; options,
        const Slice&amp;amp; key,
        std::string* value) {
    Status s;
    MutexLock l(&amp;amp;mutex_); //这里初始化levelDB的锁, 默认把锁加上
    SequenceNumber snapshot; //这里就是定义一个最新的一个操作号, 有一个全局
    唯一的SequenceNumber
    if (options.snapshot != NULL) { //如果要求取的是某一个版本的数据
        snapshot = reinterpret_cast&amp;lt;const SnapshotImpl*&amp;gt;(options.snapshot)-&amp;gt;number_;
    } else {
        snapshot = versions_-&amp;gt;LastSequence(); //否则就是最新的数据, 也就是当
        前versions_里面最大的SequenceNumber的数据
    }

    MemTable* mem = mem_; //mem table
    MemTable* imm = imm_; //imm table
    Version* current = versions_-&amp;gt;current(); //当前的version
    mem-&amp;gt;Ref(); //对mem的引用+1, 这个ref主要是用来删除文件的时候判断, 如果这
    个ref引用为0了, 那么就可以删除掉.
    if (imm != NULL) imm-&amp;gt;Ref();
    current-&amp;gt;Ref(); //同样对当前版本的ref引用+1

    bool have_stat_update = false; //用来是否有更新, 如果有更新再判断是否启动compaction线程
    Version::GetStats stats;

    // Unlock while reading from files and memtables
    {
        mutex_.Unlock(); //把锁放开, 可以看到 正真加锁部分只有获得当前版本号
        , 以及获得当前最新的版本这一部分, 也就是说在具体的get操作之前就已经
        可以支持多个线程进行读取了. 为什么可以这么做呢? 首先获得了当前最新的
        current以后, 并把这个current 的引用+1, 就可以保证当前的这个version
        是不会被删除的, 同样对于当前的这个imm, mem ref+1 以后可以保证是不会
        呗删除掉得. 所以只要在这段时间锁住就可以. 如果这个时候又有新的key写
        入, 那么他这个时候写入的key 是一个新的SequenceNumber. 不会影响我们接
        下来读的结果.

        // First look in the memtable, then in the immutable memtable (if any).
        LookupKey lkey(key, snapshot);
        if (mem-&amp;gt;Get(lkey, value, &amp;amp;s)) { //从mem里面读取这个key的 value  这
        里要注意memtable里面的kv 是如何排序的. 这里面key的排序是 首先按照
        SquenceNumber排序, 然后是操作类型(删除排在最前面), 然后是key的大小(
        具体再看一下Compaction里面)
            // Done
        } else if (imm != NULL &amp;amp;&amp;amp; imm-&amp;gt;Get(lkey, value, &amp;amp;s)) {
            // Done
        } else {
            s = current-&amp;gt;Get(options, lkey, value, &amp;amp;stats); //如果mem 和
            imm 都找不到, 那么这个时候我们要从一个一个level里面去找.
            have_stat_update = true;
        }
        mutex_.Lock();
    }

    if (have_stat_update &amp;amp;&amp;amp; current-&amp;gt;UpdateStats(stats)) { //
    这里如果有更新, 那么会判断是否启动后台的Compaction() 进程
        MaybeScheduleCompaction();
    }
    mem-&amp;gt;Unref(); //分别把 mem, imm, current 的ref - 1
    if (imm != NULL) imm-&amp;gt;Unref();
    current-&amp;gt;Unref();
    return s;
}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>levelDB thought</title>
   <link href="http://baotiao.github.io//2013/09/leverdb-thought/"/>
   <updated>2013-09-03T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/09/leverdb-thought</id>
   <content type="html">&lt;ol&gt;
&lt;li&gt;在ENV 里面可以把levelDB的结果从写入到本地 改成写入到 hdfs 来实现数据的备份, 复制等操作 具体的做法就是调用hdfs的写入这些库来实现.  这样实现levelDB的分布实话非常方便&lt;/li&gt;
&lt;li&gt;levelDB的VersionSet 是管理者 version. 然后 每一个version 有一个列表, 这个列表是这个version 的对应的所有的SST文件.  所以你要查找某一个Version的数据的时候.  先会在这个VersionSet里面查找一遍包含这个当前快照的一个版本, 然后再从这个version 的这个list里面去具体的文件查找具体的内容&lt;/li&gt;
&lt;li&gt;在一台机器上面getInstance()出来1000 levelDB的实例的话, 只会有一个compaction线程, 然后一个机器1000 个levelDB 实例和1个机器1个levelDB的实例的话 带来的好处是在机器挂掉得时候recovery的非常的快.  不过这样compaction起来就很费劲&lt;/li&gt;
&lt;li&gt;在将本地文件写入到hdfs的节点中, 因为hdfs的写入性能比较慢.  所以在本地应该是writrBranch. 然后20ms向hdfs写一次. 这样比较适合.&lt;/li&gt;
&lt;li&gt;levelDB 如何实现原子的getAndSet.  因为levelDB不是再内存层面实现这个对具体某一个key操作. 所以这个levelDB 的getAndSet操作不是通过汇编层面实现的.&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>levelDB中用到的迭代器模型</title>
   <link href="http://baotiao.github.io//2013/08/leveldb-iterator/"/>
   <updated>2013-08-22T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/08/leveldb-iterator</id>
   <content type="html">&lt;h3&gt;迭代器的设计模式是一种很常用的设计模式. leveldb的实现里面就用到了.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Iteartor模式:提供一种方法顺序访问一个聚合对象中的各个元素, 而又不暴露其内部的表示.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在leveldb 里面include/iterator.h 定义了 iterator.h 的基类, leveldb 里面有memtable, block 等数据格式. 都是通过定义一个自己的iterator来实现对这一个数据的访问.&lt;/p&gt;

&lt;p&gt;比如这里的block类:
在每一个类的里面都定义了一个&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator* NewIterator(const Comparator* comparator);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在 NewIterator 的实现里面&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator* Block::NewIterator(const Comparator* cmp) {
    if (size_ &amp;lt; 2*sizeof(uint32_t)) {
        return NewErrorIterator(Status::Corruption(&quot;bad block contents&quot;));
    }
    const uint32_t num_restarts = NumRestarts();
    if (num_restarts == 0) {
        return NewEmptyIterator();
    } else {
        return new Iter(cmp, data_, restart_offset_, num_restarts);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会具体的返回一个在这个类内部的一个指针, 这个指针在这个block类的内部具体定义的.
这个Iter指针实现了需要的所有的操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Block::Iter : public Iterator {
    private:
        const Comparator* const comparator_;
        const char* const data_;      // underlying block contents
        uint32_t const restarts_;     // Offset of restart array (list of fixed32)
        uint32_t const num_restarts_; // Number of uint32_t entries in restart array


        // current_ is offset in data_ of current entry.  &amp;gt;= restarts_ if !Valid
        uint32_t current_;
        uint32_t restart_index_;  // Index of restart block in which current_ falls
        std::string key_;
        Slice value_;  // 这里就会直接存这个value_的值
        Status status_;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next(), Prev(), Value() 等等操作&lt;/p&gt;

&lt;p&gt;比如这里Next()的实现的时候, 没进行一个Next()操作, 就会调用ParseNextKey(), 然后这个函数就会更新value&lt;em&gt;的值. 所以调用Value()的时候直接返回 value&lt;/em&gt;即可.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;virtual void Next() {
    assert(Valid());
    ParseNextKey();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样在这个dbImpl这个类里面, dbImpl的iterator的定义就在db_impl.cc里面定义.&lt;/p&gt;

&lt;p&gt;使用这种迭代器模型, 我们调用的时候就可以不用知道这个具体的结构, 直接用一个Iterator, 就可以使用这个类&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Iterator* iter = mem-&amp;gt;NewIterator(); //这个是memtable 
Iterator* iter = table_cache_-&amp;gt;NewIterator(ReadOptions(), output_number, current_bytes); //table_cache 这个类
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>learn c++ from levelDB</title>
   <link href="http://baotiao.github.io//2013/08/leveldb-c%2B%2B/"/>
   <updated>2013-08-22T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/08/leveldb-c++</id>
   <content type="html">&lt;h3&gt;LevelDB是一个学习c++很好的一个代码. 里面有很多写代码的好习惯值得我们学习.&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;assert 断言, 在一些判断的地方直接用 assert 来提示出错 比如&lt;br/&gt;
      char operator&lt;a href=&quot;size_t%20n&quot;&gt;&lt;/a&gt; const { assert(n &amp;lt; size()); return data_[n]; }&lt;/li&gt;
&lt;li&gt;尽量如果一个成员函数的方法不会改变成员变量的话, 添加上const 结尾&lt;/li&gt;
&lt;li&gt;如果想让一个类不被复制,那么就设置它的copy construct 和 copy assign 为 私有函数,&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;并且你要实现的类继承它就可以了, leveldb 里面的WritableFile 就是这么设置的
标注的定义一个类的基类的方法:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    class WritableFile {
        public:
            WritableFile() { }
            virtual ~WritableFile();
            virtual Status Append(const Slice&amp;amp; data) = 0;
            virtual Status Close() = 0;
            virtual Status Flush() = 0;
            virtual Status Sync() = 0;

        private:
            // No copying allowed
            WritableFile(const WritableFile&amp;amp;);
            void operator=(const WritableFile&amp;amp;);
    };
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;在设计中多用迭代器模型, 可以抽象更多的细节.&lt;/li&gt;
&lt;li&gt;未完待续...&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Mac 换上SSD硬盘</title>
   <link href="http://baotiao.github.io//2013/07/add-ssd/"/>
   <updated>2013-07-18T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/07/add-ssd</id>
   <content type="html">&lt;p&gt;给Mac换上的SSD硬盘步骤&lt;/p&gt;

&lt;p&gt;[前期准备]&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;支持SATA的移动硬盘盒&lt;/li&gt;
&lt;li&gt;一套电子维修专用改锥&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[第一步:安装克隆软件]&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在mac上安装Carbon copy cloner软件（简称CCC,请支持正版）&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[第二步:克隆磁盘]&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将SSD装入移动硬盘,接到mac上&lt;/li&gt;
&lt;li&gt;使用CCC将HDD的内容克隆到SSD,一切按提示操作,注意要创建恢复分区,否则SSD无法引导&lt;/li&gt;
&lt;li&gt;等待30~60分钟&lt;/li&gt;
&lt;li&gt;重启电脑,并按住option,选择从SSD启动,检查是否成功启动&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[第三步:安装SSD]&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将SSD装入mac,外面10颗螺丝,里面6颗螺丝,注意硬盘上有四颗内五角螺丝需要专用改锥&lt;/li&gt;
&lt;li&gt;启动电脑,体验非一般的感觉吧&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;    all: TRIM SMS noatime reboot 

    checkroot:
        @echo -n checking privilege...
        @touch / &amp;amp;&amp;gt;/dev/null || ( echo error!;exit 1; )
        @echo ok!


    SMS: checkroot
        @echo -n disabling Sudden Motion Sensor...
        @pmset -a sms 0 || ( echo error!;exit 1; )
        @echo done!

    TRIM: checkroot
        @echo -n enabling TRIM...
        @cp /System/Library/Extensions/IOAHCIFamily.kext/Contents/PlugIns/IOAHCIBlockStorage.kext/Contents/MacOS/IOAHCIBlockStorage /System/Library/Extensions/IOAHCIFamily.kext/Contents/PlugIns/IOAHCIBlockStorage.kext/Contents/MacOS/IOAHCIBlockStorage.bak
        @perl -pi -e 's|(\x52\x6F\x74\x61\x74\x69\x6F\x6E\x61\x6C\x00).{9}(\x00\x54)|$1\x00\x00\x00\x00\x00\x00\x00\x00\x00$2|sg' /System/Library/Extensions/IOAHCIFamily.kext/Contents/PlugIns/IOAHCIBlockStorage.kext/Contents/MacOS/IOAHCIBlockStorage
        - @kextcache -system-prelinked-kernel &amp;amp;&amp;gt;/dev/null
        @kextcache -system-caches
        @echo done

    noatime: checkroot
        @echo -n disabling atime...
        @echo '&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&amp;gt; &amp;lt;plist version=&quot;1.0&quot;&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;com.noatime.root&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;mount&amp;lt;/string&amp;gt; &amp;lt;string&amp;gt;-uwo&amp;lt;/string&amp;gt; &amp;lt;string&amp;gt;noatime&amp;lt;/string&amp;gt; &amp;lt;string&amp;gt;/&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;RunAtLoad&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/plist&amp;gt;' &amp;gt; /Library/LaunchDaemons/com.noatime.root.plist || ( echo error!;exit 1; )
        @echo done!

    reboot: checkroot
        @echo Finished !
        @echo CAUTION: we are going to reboot, press Ctrl-C to abort and you can reboot manually later.;sleep 5;
        @for i in `seq 10 1`; do clear; echo CAUTION: we are going to reboot in $$i seconds;sleep 1; done;
        @reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行方式为:sudo make -f ssd_opt.makefile&lt;/p&gt;

&lt;h4&gt;执行优化包括:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;打开TRIM&lt;/li&gt;
&lt;li&gt;禁用atime&lt;/li&gt;
&lt;li&gt;禁用磁盘保护&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;注意:&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;打开TRIM时,会误报segment fault,忽略即可&lt;/li&gt;
&lt;li&gt;由于系统版本原因,TRIM可能打开失败,如何检测成功与否,以及失败了怎么办,请参见:http://www.cnbeta.com/articles/219752.htm&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>test markdown</title>
   <link href="http://baotiao.github.io//2013/07/test-markdown/"/>
   <updated>2013-07-01T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2013/07/test-markdown</id>
   <content type="html">&lt;p&gt;first time use in markdown&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linux内核设计与实现 进程地址空间 实际中使用的内存</title>
   <link href="http://baotiao.github.io//2012/11/linux-kernel-process/"/>
   <updated>2012-11-16T10:28:59+08:00</updated>
   <id>http://baotiao.github.io//2012/11/linux-kernel-process</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;int main(int argc, char *argv[])
{
    while (1) {
    };
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用pmap 进程号 -d 来查看进程&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Address           Kbytes Mode  Offset           Device    Mapping
0000000000400000       4 r-x-- 0000000000000000 4f9:2c566 a.out
0000000000500000       4 rw--- 0000000000000000 4f9:2c566 a.out
000000302ad00000      84 r-x-- 0000000000000000 008:00002 ld-2.3.4.so
000000302ae14000       8 rw--- 0000000000014000 008:00002 ld-2.3.4.so
000000302af00000    1196 r-x-- 0000000000000000 008:00002 libc-2.3.4.so
000000302b02b000    1020 ----- 000000000012b000 008:00002 libc-2.3.4.so
000000302b12a000      12 r---- 000000000012a000 008:00002 libc-2.3.4.so
000000302b12d000      12 rw--- 000000000012d000 008:00002 libc-2.3.4.so
000000302b130000      16 rw--- 000000302b130000 000:00000   [ anon ]
00002ae829a73000       4 rw--- 00002ae829a73000 000:00000   [ anon ]
00002ae829a87000       8 rw--- 00002ae829a87000 000:00000   [ anon ]
00007fff81022000      84 rw--- 00007fff81022000 000:00000   [ stack ]
ffffffffff600000       4 r-x-- 0000000000000000 000:00000   [ anon ]
mapped: 2456K    writeable/private: 136K    shared: 0K

这里的顺序就是进程的地址空间中各个区域的顺序
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一行 a.out 的代码段 执行权限是r-x
第二行 a.out 的数据段 执行权限是rw-
然后是mapped file
ld的代码段 执行权限r-x
ld的数据段 执行权限rw-
libc库代码段 执行权限r-w
libc库这个我也不太清楚
libc库....
libc库的数据段 执行权限rw-&lt;/p&gt;

&lt;p&gt;接下来有三行的anon, 分别是a.out, ld, libc 的BSS段, BSS段映射文件的内存区域的设备标志为000:00000 这个区域是0页,0页映射的内容全部为零.因为bss段是未初始化的全局变量区,在进程里面未初始化数据区存的都是0.操作系统有写时复制机制,这样子真正有修改的时候,才会从物理内存中获得空间.&lt;/p&gt;

&lt;p&gt;该进程全部地址空间2456K, 可写空间136K.不可写区域可以和其他进程共享,所以多个进程都共享libc库,以及内核的代码.所以物理内存里面只需要保存一份libc库的代码节省了大量的空间&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linux内核的设计与实现:块I/O层</title>
   <link href="http://baotiao.github.io//2012/10/linuxe58685e6a0b8e79a84e8aebee8aea1e4b88ee5ae9ee78eb0e59d97ioe5b182/"/>
   <updated>2012-10-18T23:31:12+08:00</updated>
   <id>http://baotiao.github.io//2012/10/linuxe58685e6a0b8e79a84e8aebee8aea1e4b88ee5ae9ee78eb0e59d97ioe5b182</id>
   <content type="html">&lt;h1&gt;块设备&lt;/h1&gt;

&lt;h3&gt;扇区:&lt;/h3&gt;

&lt;p&gt;扇区是块设备中最小的可寻址的单元,大小一般是2的整数倍.扇区的大小是设备的物理属性,扇区是所有块设备的基本单元--块设备无法对比它还小的单元进行寻址和操作.&lt;/p&gt;

&lt;h3&gt;块:&lt;/h3&gt;

&lt;p&gt;块是自己的最小逻辑可寻址单元.块是文件系统的一种抽象--只能及愉快来范围文件系统.虽然物理磁盘寻址是按照扇区级进行的,但是内核执行的所有的磁盘操作都是按照块进行的.由于扇区是设备的最小可寻址单元,所有块不能比扇区还小,只能数倍于扇区大小.&lt;/p&gt;

&lt;h1&gt;I/O调度程序&lt;/h1&gt;

&lt;h2&gt;I/O调度程序&lt;/h2&gt;

&lt;p&gt; IO调度程序将磁盘I/O资源分配给系统中所有挂起的块I/O请求.具体的说这种资源分配是通过将请求队列中挂起的请求合并和排序来完成的.&lt;/p&gt;

&lt;p&gt; 与进程调度的区别&lt;/p&gt;

&lt;p&gt; 进程调度程序的作用是将处理器资源分配给系统中的运行进程.&lt;/p&gt;

&lt;p&gt; 进程调度程序和I/O调度程序都是将一个资源虚拟给多个对象,对进程调度来说,处理器被虚拟并被系统中的运行进程共享.这种虚拟提供给用户的就是多任务和分时操作系统,像Unix系统.相反,I/O调度程序虚拟块设备给多个磁盘请求,以便降低磁盘寻道的时间, 确保磁盘性能的最优化&lt;/p&gt;

&lt;h2&gt;I/O调度程序的工作&lt;/h2&gt;

&lt;p&gt;  IO调度程序的工作是管理块设备的请求队列.它觉得队列中的请求排列顺序以及在什么时候派发请求到块设备.这样做有利于减少磁盘寻址时间,从而提高全局吞吐量.&lt;/p&gt;

&lt;p&gt;  IO调度两种方法减少寻址时间:合并和排序&lt;/p&gt;

&lt;p&gt;  合并:将两个或多个请求结合成一个新请求.&lt;/p&gt;

&lt;p&gt;  这种情况,文件系统提交请求到请求队列--从文件中读取一个数据区,如果这时文件中已经存在一个请求,它访问的磁盘扇区和当前请求访问的磁盘扇区相连(比如同一个文件中早些时候被读取的数据区),那么这两个请求可以合并为一个对单个和多个相邻磁盘扇区操作的新请求.通过合并请求,I/O调度程序将多次请求的开销压缩成一次请求的开销,而且只需要传递给磁盘一条寻找命令,就可以访问到合并前多次寻址才能访问完的磁盘区域.(寻址是I/O里面最费时的操作)&lt;/p&gt;

&lt;p&gt;  排序:I/O调度程序是的整个请求队列按扇区增长方向有序排序.使所有秦秋按磁盘扇区排列的顺序尽可能有序排列.这样不只是缩短一次请求的寻址时间,更重要的,通过保存磁盘头以直线方向移动,缩短了所有请求的磁盘寻址时间.该排序算法类似于电梯调度&lt;/p&gt;

&lt;h2&gt;Linux 电梯&lt;/h2&gt;

&lt;p&gt;  当一个请求加入到队列中是,有可能发生4中操作
   1. 如果队列中已存在一个对相连磁盘扇区操作的请求,那么新请求将和这个已存在的请求合并成一个请求
   2. 如果队列中存在一个驻留时间过长的请求,那么新请求将被插入到队列尾部,已防止其他旧的请求发生饥饿
   3. 如果队列中以扇区方向为序存在合适的插入位置, 那么新的请求将被插入到该位置,保证队列中的请求是以被访问磁盘物理位置为序进行排列
   4. 如果队列中不存在合适的请求插入位置,请求将被插入到队列尾部&lt;/p&gt;

&lt;h2&gt;其他4中I/O调度程序&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt; . 最终期限I/O调度程序&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt; . 预测I/O调度程序&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt; . 完全公正的排队I/O调度程序&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt; . 空操作的I/O调度程序&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>c++对象模型 构造函数语义学</title>
   <link href="http://baotiao.github.io//2012/09/ce5afb9e8b1a1e6a8a1e59e8b-e69e84e980a0e587bde695b0e8afade4b989e5ada6/"/>
   <updated>2012-09-12T15:16:14+08:00</updated>
   <id>http://baotiao.github.io//2012/09/ce5afb9e8b1a1e6a8a1e59e8b-e69e84e980a0e587bde695b0e8afade4b989e5ada6</id>
   <content type="html">&lt;h1&gt;1. C++ 不会为所有的class构造默认的constructor&lt;/h1&gt;

&lt;p&gt;(我们经常认为c++会为所有的class默认添加构造函数)
只有满足4个条件之一会添加构造函数
     1) 包含带有默认构造函数的对象成员的类
      2) 继承自带有默认构造函数的基类的类
      3) 带有虚函数的类
      4) 带一个虚基类的类
这4中情况会导致编译器必须为未申明构造函数的class, 生成一个默认的constructor. 更多情况下是不会去生成默认的构造函数的.&lt;/p&gt;

&lt;h1&gt;2. copy constructor 构造语义学&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt; C++并不是为所有的类都够着copy constructor. 默认的情况是如果没有定义copy constructor, 那么一般情况下如果有copy constructor 操作, 默认的是执行bitwise copy semantics. 也就是位逐次拷贝. 当然 bistwise copy 是有条件的,当不满足bitwise copy 的条件的时候,就不能进行bitwise copy. 那么C++就会为该类添加默认的copy constructor. ( 这里我感觉就是深拷贝和浅拷贝的区别,很明显bitwise 是浅拷贝,直接将一个对象的data member 拷贝给同一个类的另一个对象. 而如果这里不能直接内存拷贝,则需要深拷贝.就是需要构造一个copy constructor了)
 4种情况不满足bitwise copy. 也就是会调用构造函数
 1)当一个class 内的一个member object,而这个object 声明了一个copy constructor时
 2)当class 继承自一个bass class, 而这个bass class 有 copy constructor
 3)当class申明了一个或多个 virtual functions 时
 4)当class 派生自一个继承串链,其中一个或多个virtual base classes
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;3. copy assign constructor 构造语义学&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt; 跟上面的copy constructor 构造语义学一样, 如果能进行浅拷贝就浅拷贝, 不行的时候才会去生成assign operator
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;4. 对象析构语义学.&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt; 只有在基类拥有析构函数,或者object member 拥有析构函数的时候,编译器在为类合成析构函数,否则都被视为不需要.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几个默认生成的函数都是在需要的时候才会被编译器生成出来, 默认情况下是不会生成这些函数的.所以如果class 当成一个存结构体使用, 效率是和C 的stuct 是一样的&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>c++ 对象模型</title>
   <link href="http://baotiao.github.io//2012/08/c-e5afb9e8b1a1e6a8a1e59e8b/"/>
   <updated>2012-08-25T17:15:01+08:00</updated>
   <id>http://baotiao.github.io//2012/08/c-e5afb9e8b1a1e6a8a1e59e8b</id>
   <content type="html">&lt;ol&gt;
&lt;li&gt;C++的对象模型里面,Nonstatic data members 配置于每一个class object之内, static data members 则被存放在所有的class object之外. static 和 non static function members 也被放在所有的所有的class object 之外. Virtual function 则以两个步骤支持&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;     1)每一个class 产生出一堆执行virtual functions 的指针,放在表格之中.这个表格被称为virtual table(vtbl)&lt;/p&gt;

&lt;p&gt;     2)每一个class object 被添加了一个指针,指向相关的virtual table, 通常这个指针被称为vptr. vptr的设定和重置都有每一个class的constructor, destructor 和copy assignment运算法自动完成. 如下图:(为什么采用这种模型是我们应该考虑的,是基于性能和空间的综合考虑.可以看一下简单对象模型和表格驱动对象模型)&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;http://chenzongzhi.info/wp-content/uploads/2012/08/3e55c34139de2e6b58bc737a91b41905.gif&quot; alt=&quot;3e55c34139de2e6b58bc737a91b41905&quot; /&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在继承的时候,对象的内存布局是这样的&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;基类:&lt;/p&gt;

&lt;p&gt;class ZooAnimal {&lt;/p&gt;

&lt;p&gt;public:&lt;/p&gt;

&lt;p&gt;   ZooAnimal();&lt;/p&gt;

&lt;p&gt;   virtual ~ZooAnimal();&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;   // ...&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;   virtual void rotate();&lt;/p&gt;

&lt;p&gt;protected:&lt;/p&gt;

&lt;p&gt;   int loc;&lt;/p&gt;

&lt;p&gt;   String name;&lt;/p&gt;

&lt;p&gt;};&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://chenzongzhi.info/wp-content/uploads/2012/08/ee21eaea173ebe93e1da4a422db9004e.gif&quot; alt=&quot;Ee21eaea173ebe93e1da4a422db9004e&quot; /&gt;&lt;/p&gt;

&lt;p&gt;子类:&lt;/p&gt;

&lt;p&gt;class Bear : public ZooAnimal {&lt;/p&gt;

&lt;p&gt;public:&lt;/p&gt;

&lt;p&gt;   Bear();&lt;/p&gt;

&lt;p&gt;   ~Bear();&lt;/p&gt;

&lt;p&gt;   // ...&lt;/p&gt;

&lt;p&gt;   void rotate();&lt;/p&gt;

&lt;p&gt;   virtual void dance();&lt;/p&gt;

&lt;p&gt;   // ...&lt;/p&gt;

&lt;p&gt;protected:&lt;/p&gt;

&lt;p&gt;   enum Dances { ... };&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;   Dances dances_known;&lt;/p&gt;

&lt;p&gt;   int cell_block;&lt;/p&gt;

&lt;p&gt;};&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Bear b( &quot;Yogi&quot; );&lt;/p&gt;

&lt;p&gt;Bear *pb = &amp;b;&lt;/p&gt;

&lt;p&gt;Bear &amp;amp;rb = *pb;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://chenzongzhi.info/wp-content/uploads/2012/08/c4613a1593002490b4ee517f61fcd5fc.gif&quot; alt=&quot;C4613a1593002490b4ee517f61fcd5fc&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到,子类是直接将基类的data member 空间直接拷贝过来的.&lt;/p&gt;

&lt;p&gt;然后在它的下面添加上自己的data menber&lt;/p&gt;

&lt;p&gt;3.一个类的对象的内存大小包括：  &lt;/p&gt;

&lt;p&gt;    1) 所有非静态数据成员的大小。&lt;/p&gt;

&lt;p&gt;    2) 由内存对齐而填补的内存大小。&lt;/p&gt;

&lt;p&gt;    3) 为了支持virtual有内部产生的额外负担,一个指针的大小.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://erektilepillenonline.com/products/viagra.htm&quot;&gt;viagra&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>c++ inline</title>
   <link href="http://baotiao.github.io//2012/07/c-inline/"/>
   <updated>2012-07-29T23:46:19+08:00</updated>
   <id>http://baotiao.github.io//2012/07/c-inline</id>
   <content type="html">&lt;p&gt;一个函数被定义成inline 函数. 那么就跟macro 宏一样, 在编译器编译的时候,如果编译器发现你的函数是inline类型的,就把你编译成inline code.&lt;/p&gt;

&lt;p&gt;编译器编译原文件以后,会单独把inline函数列出来.然后当有地方调用inline函数的时候,就会直接把编译好的inline code 插入到调用的这个地方.&lt;/p&gt;

&lt;p&gt;普通的函数调用一个函数,在汇编成面,会有一个函数调用,找到这个函数的地址,然后传递参数给这个函数,然后执行这个函数,最后从函数出返回值.然后堆栈又要恢复调用这个函数前的样子.因此每次调用一次函数都有时间和空间的开销. 如果要调用的函数仅仅是一个小函数,那么每次都重复这样的一个过程肯定非常的浪费时间,并且浪费堆栈的空间,如果是一个递归调用,使用堆栈的空间就更多了.
如果要调用的函数非常长,那么花这个函数调用的时间还是值得的.如果要调用的函数非常的短,那么就可以直接将要调用的函数复制到要调用这个函数的地方.如果函数过长,可以想象每次都要把一个这么长的函数复制到其他地方,是不能接受的. 所以如果一个函数过长,编译器会放弃使用内联的方式.&lt;/p&gt;

&lt;p&gt;总结:内联函数本身通过减少函数调用开销来起到优化目的.内联过大的函数不但起不到优化效果,还会导致代码膨胀,增加内存换页次数,得不偿失.&lt;/p&gt;

&lt;p&gt;所以并不是所有地方都用inline 函数,但是可以用macro的地方必定可以用inline替换.&lt;/p&gt;

&lt;p&gt;inline 是一个对函数的定义修饰的一个修饰符.
所以如果是
inline int max(int a, int b); 是没用的, 这里是函数的声明,不是函数的定义.&lt;/p&gt;

&lt;p&gt;inline 即使函数的声明没声明inline, 函数的定义声明是Inline就可以了.&lt;/p&gt;

&lt;p&gt;tips: 注意在类定义里给出定义的方法会自动内联.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>c++泛型单例模式</title>
   <link href="http://baotiao.github.io//2012/06/c%2B%2B-single-model/"/>
   <updated>2012-06-19T02:23:13+08:00</updated>
   <id>http://baotiao.github.io//2012/06/c++-single-model</id>
   <content type="html">&lt;p&gt;单例模式是在设计模式里面很常见的一种,用来确保一个类只有一个实例. 首先是原生态版本的实现.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#ifndef SING_H
class sing {
    private:
        static sing *m_sing;
    public:
        int num;
        static void open();
        static void close();
        static sing *getInstance();
        void func();
    protected:
        ~sing();
        sing();
};

#define SING_H
#endif


#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &quot;sing.h&quot;
#include &quot;assert.h&quot;
using namespace std;

sing *sing::m_sing = NULL;
sing::sing()
{
    printf(&quot;sing construct\n&quot;);
}

sing::~sing()
{
    printf(&quot;sing destruct\n&quot;);
}

sing *sing::getInstance()
{
    if (m_sing == NULL) {
        printf(&quot;m_sing is NULL\n&quot;);
        m_sing = new sing();
        assert(m_sing != NULL);
    }
    return m_sing;
}

void sing::close()
{
    if (m_sing == NULL) {
        delete m_sing;
        m_sing = NULL;
    }
}

void sing::func()
{
    printf(&quot;sing::func\n&quot;);
}

#include &amp;lt;iostream&amp;gt;
#include &quot;sing.h&quot;

int main()
{
    sing *s = sing::getInstance();
    s-&amp;gt;num = 10;

    sing *s1 = sing::getInstance();
    printf(&quot;%d\n&quot;, s1-&amp;gt;num);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c++ 的单态实现, 这里getInstance()获得那个单态的指针对象.&lt;/p&gt;

&lt;p&gt;以下是c++ 的泛型的单态的实现&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#ifndef TSING_H
#define TSING_H
template 
class sing {
private:
    static T *m_sing;

public:
    static void close();
    static T* getInstance();
    sing();
    ~sing();
};

template  T *sing::m_sing = NULL;

template  sing::sing() {
    printf(&quot;sing construct\n&quot;);
}

template  sing::~sing() {
    printf(&quot;sing destructor\n&quot;);
    close();
}

template  T* sing::getInstance() {
    if (m_sing == NULL) {
        printf(&quot;m_sing is NULL\n&quot;);
        m_sing = new T();
    }
    return m_sing;
}

template  void sing::close() {
    if (m_sing != NULL) {
        delete m_sing;
    }
}
#endif
#include &amp;lt;iostream&amp;gt;
#include &quot;tsing.h&quot;

struct node {
    int num;
    bool flag;
    int type;
};

int main()
{
    node *s = sing::getInstance();
    s-&amp;gt;num = 10;
    s-&amp;gt;flag = 0;
    s-&amp;gt;type = 100;

    //s-&amp;gt;num = 10;

    node *s1 = sing::getInstance();
    printf(&quot;%d %d %d\n&quot;, s1-&amp;gt;num, s1-&amp;gt;flag, s1-&amp;gt;type);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在我理解以来,在没有用泛型以前这里的静态指针sing,既是容器也是sing类型对象,也就是说之前这个单态只能设计来给sing这个类来使用,泛型的sing类,这里把sing只是这个容器的名字,T想要单态的类型,任意的类型对象. 而前面这种没有实现泛型是将sing即是这个类的容器也是这个类的对象.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>vim grep插件</title>
   <link href="http://baotiao.github.io//2012/05/vim-grepe68f92e4bbb6/"/>
   <updated>2012-05-03T13:41:48+08:00</updated>
   <id>http://baotiao.github.io//2012/05/vim-grepe68f92e4bbb6</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>vim复制插件</title>
   <link href="http://baotiao.github.io//2012/05/vim-copy-plugin/"/>
   <updated>2012-05-03T03:34:33+08:00</updated>
   <id>http://baotiao.github.io//2012/05/vim-copy-plugin</id>
   <content type="html">&lt;p&gt;vim复制的时候不发复制到c-v的复制缓冲区,很麻烦,自己动手,丰衣足食&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nnoremap y :set operatorfunc=Pbcopyg@
vnoremap y y:call Pbcopy()
function! s:Pbcopy()
    execute 'call system(&quot;pbcopy&quot;, getreg(&quot;\&quot;&quot;))'
    execute 'call system(&quot;xsel --clipboard --input&quot;, getreg(&quot;\&quot;&quot;))'
endfunction
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将代码保存再.vim/plugin/copy.vim的文件即可
ubuntu环境下 默认得安装一下xsel这个东西&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ternary Search Trees 三分树</title>
   <link href="http://baotiao.github.io//2012/03/ternary-search-trees/"/>
   <updated>2012-03-26T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/03/ternary-search-trees</id>
   <content type="html">&lt;p&gt;经常碰到要存一堆的string, 这个时候可以用hash tables, 虽然hash tables 查找很快,但是hash tables不能表现出字符串之间的联系.可以用binary search tree, 但是查询速度不是很理想. 可以用trie, 不过trie会浪费很多空间(当然你也可以用二个数组实现也比较省空间). 所以这里Ternary Search trees 有trie的查询速度快的优点,以及binary search tree省空间的优点.&lt;/p&gt;

&lt;p&gt;实现一个12个单词的查找&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;data:image/png;base64,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&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个是用二分查找树实现,n是单词个数,len是长度,复杂度是O(logn * n),空间是n*len&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;data:image/png;base64,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&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个是用trie实现,复杂度O(n), 空间是 这里是18 * 26(假设只有26个小写字符),随着单词长度的增长等,需要的空间就更多&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;data:image/png;base64,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&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个是Ternary search tree, 可以看出空间复杂度和binary search tree 一样, 复杂度近似O(n),常数上会比trie差点.&lt;/p&gt;

&lt;h1&gt;介绍&lt;/h1&gt;

&lt;p&gt;Ternary search tree 有binary search tree 省空间和trie 查询快的优点.
Ternary search tree 有三个只节点,在查找的时候,比较当前字符,如果查找的字符比较小,那么就跳到左节点.如果查找的字符比较大,那么就跳转到友节点.如果这个字符正好相等,那么就走向中间节点.这个时候比较下一个字符.
比如上面的例子,要查找&quot;ax&quot;, 先比较&quot;a&quot; 和 &quot;i&quot;, &quot;a&quot; &amp;lt; &quot;i&quot;,跳转到&quot;i&quot;的左节点, 比较 &quot;a&quot; &amp;lt; &quot;b&quot;, 跳转到&quot;b&quot;的左节点, &quot;a&quot; = &quot;a&quot;, 跳转到 &quot;a&quot;的中间节点,并且比较下一个字符&quot;x&quot;. &quot;x&quot; &gt; &quot;s&quot; , 跳转到&quot;s&quot; 的右节点, 比较 &quot;x&quot; &gt; &quot;t&quot; 发现&quot;t&quot; 没有右节点了.找出结果,不存在&quot;ax&quot;这个字符&lt;/p&gt;

&lt;h1&gt;构造方法&lt;/h1&gt;

&lt;p&gt;这里用c语言来实现
节点定义:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct tnode *Tptr;
typedef struct tnode {
    char s;
    Tptr lokid, eqkid, hikid;
} Tnode;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先介绍查找的方法:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int search(char *s) // s是想要查找的字符串
{
    Tptr p;
    p = t; //t 是已经构造好的Ternary search tree 的root 节点.
    while (p) {
        if (*s &amp;lt; p-&amp;gt;s) { // 如果*s 比 p-&amp;gt;s 小, 那么节点跳到p-&amp;gt;lokid
            p = p-&amp;gt;lokid;
        } else if (*s &amp;gt; p-&amp;gt;s) {
            p = p-&amp;gt;hikid;
        } else {
            if (*(s) == '\0') { //当*s 是'\0'时候,则查找成功
                return 1;
            } //如果*s == p-&amp;gt;s,走向中间节点,并且s++
            s++;
            p = p-&amp;gt;eqkid;
        }
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;插入某一个字符串:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Tptr insert(Tptr p, char *s)
{
    if (p == NULL) {
        p = (Tptr)malloc(sizeof(Tnode));
        p-&amp;gt;s = *s;
        p-&amp;gt;lokid = p-&amp;gt;eqkid = p-&amp;gt;hikid = NULL;
    }
    if (*s &amp;lt; p-&amp;gt;s) {
        p-&amp;gt;lokid = insert(p-&amp;gt;lokid, s);
    } else if (*s &amp;gt; p-&amp;gt;s) {
        p-&amp;gt;hikid = insert(p-&amp;gt;hikid, s);
    } else {
        if (*s != '\0') {
            p-&amp;gt;eqkid = insert(p-&amp;gt;eqkid, ++s);
        } else {
            p-&amp;gt;eqkid = (Tptr) insertstr; //insertstr 是要插入的字符串,方便遍历所有字符串等操作
        }
    }
    return p;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同binary search tree 一样,插入的顺序也是讲究的,binary search tree 在最坏情况下顺序插入字符串会退化成一个链表.不过Ternary search Tree 最坏情况会比 binary search tree 好很多.&lt;/p&gt;

&lt;p&gt;肯定得有一个遍历某一个树的操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//这里以字典序输出所有的字符串
void traverse(Tptr p) //这里遍历某一个节点以下的所有节点,如果是非根节点,则是有同一个前缀的字符串
{ 
    if (!p) return; 
    traverse(p-&amp;gt;lokid); 
    if (p-&amp;gt;s != '\0') { 
        traverse(p-&amp;gt;eqkid); 
    } else { 
        printf(&quot;%s\n&quot;, (char *)p-&amp;gt;eqkid); 
    } 
    traverse(p-&amp;gt;hikid); 
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;应用&lt;/h1&gt;

&lt;p&gt;这里先介绍两个应用,一个是模糊查询,一个是找出包含公共前缀的字符串, 一个是相邻查询(哈密顿距离小于某个范围)
模糊查询
psearch(&quot;root&quot;, &quot;.a.a.a&quot;) 应该能匹配出baxaca, cadakd 等字符串&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void psearch1(Tptr p, char *s)
{
    if (p == NULL) {
        return ;
    }
    if (*s == '.' || *s &amp;lt; p-&amp;gt;s) { //如果*s 是'.' 或者 *s &amp;lt; p-&amp;gt;s 就查找左子树
        psearch1(p-&amp;gt;lokid, s); 
    }
    if (*s == '.' || *s &amp;gt; p-&amp;gt;s) { //同上
        psearch1(p-&amp;gt;hikid, s); 
    }
    if (*s == '.' || *s == p-&amp;gt;s) { // *s = '.' 或者 *s == p-&amp;gt;s 则去查找下一个字符
        if (*s &amp;amp;&amp;amp; p-&amp;gt;s &amp;amp;&amp;amp; p-&amp;gt;eqkid != NULL) { 
            psearch1(p-&amp;gt;eqkid, s + 1);
        }
    }
    if (*s == '\0' &amp;amp;&amp;amp; p-&amp;gt;s == '\0') {
        printf(&quot;%s\n&quot;, (char *) p-&amp;gt;eqkid);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解决在哈密顿距离内的匹配问题,比如hobby和dobbd,hocbe的哈密顿距离都是2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void nearsearch(Tptr p, char *s, int d) //s 是要查找的字符串, d是哈密顿距离
{
    if (p == NULL || d &amp;lt; 0)
        return ;
    if (d &amp;gt; 0 || *s &amp;lt; p-&amp;gt;s) {
            nearsearch(p-&amp;gt;lokid, s, d);
    }
    if (d &amp;gt; 0 || *s &amp;gt; p-&amp;gt;s) {
            nearsearch(p-&amp;gt;hikid, s, d);
    }
    if (p-&amp;gt;s == '\0') {
        if ((int)strlen(s) &amp;lt;= d) {
            printf(&quot;%s\n&quot;, (char *) p-&amp;gt;eqkid);
        }
    } else {
        nearsearch(p-&amp;gt;eqkid, *s ? s + 1 : s, (*s == p-&amp;gt;s) ? d : d - 1);
    }   
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;搜索引擎输入bin, 然后相应的找出所有以bin开头的前缀匹配这样类似的结果.比如bing,binha,binb 就是找出所有前缀匹配的结果.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void presearch(Tptr p, char *s) //s 是想要找的前缀
{
    if (p == NULL)
        return;
    if (*s &amp;lt; p-&amp;gt;s) {
        presearch(p-&amp;gt;lokid, s);
    } else if (*s &amp;gt; p-&amp;gt;s) {
        presearch(p-&amp;gt;hikid, s);
    } else {
        if (*(s + 1) == '\0') {
            traverse(p-&amp;gt;eqkid); // 遍历这个节点,也就是找出包含这个节点的所有字符
            return ;
        } else {
            presearch(p-&amp;gt;eqkid, s + 1);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Ternary search tree 效率高而且容易实现&lt;/li&gt;
&lt;li&gt;Ternary search tree 大体上效率比hash来的快,因为当数据量大的时候hash出现碰撞的几率也会大,而Ternary search tree 是指数增长&lt;/li&gt;
&lt;li&gt;Ternary search tree 增长和收缩很方便,而 hash改变大小的话则需要拷贝内存重新hash等操作&lt;/li&gt;
&lt;li&gt;Ternary search tree 支持模糊匹配,哈密顿距离查找,前缀查找等操作&lt;/li&gt;
&lt;li&gt;Ternary search tree 支持许多其他操作,比如字典序输出所有字符串等,trie也能做,不过很费时.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;:http://drdobbs.com/database/184410528?pgno=1&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Memcache initialization</title>
   <link href="http://baotiao.github.io//2012/03/memcached-initialization/"/>
   <updated>2012-03-07T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/03/memcached-initialization</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;1.signal(SIGINT, sig_handler);

2.seetings_init(); //初始化默认的设置,初始化全局变量struct setting settings
static void settings_init(void) {
    settings.use_cas = true;
    settings.access = 0700;
    settings.port = 11211;
    settings.udpport = 11211;
    /* By default this string should be NULL for getaddrinfo() */
    settings.inter = NULL;
    settings.maxbytes = 64 * 1024 * 1024; /* default is 64MB */
    settings.maxconns = 1024;         /* to limit connections-related memory to about 5MB */
    settings.verbose = 0;
    settings.oldest_live = 0;
    settings.evict_to_free = 1;       /* push old items out of cache when memory runs out */
    settings.socketpath = NULL;       /* by default, not using a unix socket */
    settings.factor = 1.25;
    settings.chunk_size = 48;         /* space for a modest key and value */
    settings.num_threads = 4;         /* N workers */
    settings.num_threads_per_udp = 0;
    settings.prefix_delimiter = ':';
    settings.detail_enabled = 0;
    settings.reqs_per_event = 20;
    settings.backlog = 1024;
    settings.binding_protocol = negotiating_prot;
    settings.item_size_max = 1024 * 1024; /* The famous 1MB upper limit. */
    settings.maxconns_fast = false;
    settings.hashpower_init = 0;
}

3. while (-1 != (c = getopt(argc, argv, //对输入的参数进行相应的设置,这种demon,item_max_size 等等

4.getrlimit,setrlimit 是系统调用,用来修改最大连接数 struct rlimit .

5.去掉root权限. 如果是root 通过 -u 参数来启动

6.init_sasl() 是否开启 sasl

7.daemonize(maxcore, setting.verbose) 开启 daemonize 模式

8.main_base = event_init(); 初始化主线程

9.stats_init() 初始化全局变量stats.

10.assoc_init() 初始化hashtable, 默认calloc(2^16, sizeof(void *))个指针

11.conn_init() 初始化连接池conn, 默认的空闲连接池的个数是200 声明calloc(200, sizeof(conn *))

12.slabs_init(settings.maxbytes, setting.factor, preallocate) 初始化memcached. setting.maxbytes 是最大内存的大小,setting.factor 成长因子, preallocate是否预先声明空间 . 默认的最小的chunk_size 是48,成长因子是1.25.

13.sigignore(SIGPIPE) 忽略SIGPIPE信号。 在Linux下写socket的程序的时候，如果尝试send到一个disconnected socket上，底层将抛出一个SIGPIPE信号。如果程序没有处理或没有忽略，这个信号将导致程序退出。这不是我们需要的.

14.thread_init(settings.num_threads, main_base); //初始化线程池模型

15.start_assoc_maintenance_thread() //在assoc里面,有一个独立的线程来维护从old_hashtable中的数据到相应的primary_hashtable中.开启这个线程

16.clock_handler(0, 0, 0); //初始化libevent的时间处理

17.server_socket_unix(settings.socketpath,settings.access) //建立tcp 或者 udp的socket连接sfd,dispatch_thread开始监听这个sfd连接.
server_sockets(settings.port, tcp_transport,portnumber_file) //可以让dispatch同时监听多个连接的端口. 到此 服务器初始化结束,等到client的连接

18.if (event_base_loop(main_base, 0) != 0) //循环main_base事件

19.stop_assoc_maintenance_thread(); //退出在assoc里面的维护hashtable线程
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Memcache stats mt 线上使用情况</title>
   <link href="http://baotiao.github.io//2012/03/memcached-meituan/"/>
   <updated>2012-03-05T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/03/memcached-meituan</id>
   <content type="html">&lt;p&gt;美团网memcached的使用情况,线上有3个memcached服务器,默认的内存空间是256M.
stats
    cmd_get累计的get命令数量 33408439710, cmd_set累计的set命令数量是 4037110852
    get_hits 和 get_misses 分别是 32901704378 和 506735332 我们的命中率大概是98.5%
    incr_misses 和 incr_hists 都是0 我们美团并没有用到incr这部分功能
    decr_misses 和 decr_hists 也都是0 .
    cas_misses 和 cas_hits 也都是0&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bytes_read 8160828819650 bytes_written 82925274065843 是这个server 读到的数据的数量和这个服务器写的数据的数量
limit_maxbytes 268435456 = 256M 这个服务器开的内存的大小
threads 4 当前线程数
curr_items 504204  //当前使用的item的数量
total_items 422927023 //总共使用过的item的数量
bytes 190848020 //用来存目前的item所使用的内存那么空闲的内存就是 268435456 - 190848020 =77587436 = 28%的空闲内存
evictions 1494520 // 根据LRU算法淘汰的item的数量 可以看出evictions的数量远小于total_items.说明服务器的内存空间足够使用,很少有通过LRU重新使用item.
reclaimed 177784574 // 从item 上面的slots上重新使用items的数量. 这个数量将近total_items的一半.说明几乎又一半的item是存在重新使用的items里. 这里可以看出memcached的slabclass的不将空闲的item返回内存池,而是放在空闲链表是非常有用的
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stats setting 查看默认的配置信息&lt;/p&gt;

&lt;p&gt;stats items 和 stats slabs
stats slabs 返回具体的每一个slabclass的信息
stats items 返回格式 items:: \r\n&lt;/p&gt;

&lt;p&gt;stats sizes 查看所有的items的大小和个数&lt;/p&gt;

&lt;p&gt;看一个stats slabs 的结果&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STAT 17:chunk_size 3632 //一个chunk的大小
STAT 17:chunks_per_page 288 
STAT 17:total_pages 28
STAT 17:total_chunks 8064 //总的chunks数 = chunks_per_page * total_pages
STAT 17:used_chunks 4234 // 已经使用的chunks数
STAT 17:free_chunks 3830 // 空闲的chunks数
STAT 17:free_chunks_end 0 // 最后一次声明的那个pages现在有的空闲的chunk数. 发现这里为0.说明有大量的items 被使用,然后被放入到的slabclass的slots数组里面了. slots数组里面又将近一半的items.这也说明了memcached将空闲的item放入到slots链表,而不是返回给内存池是多么的有用
STAT 17:mem_requested 50004272
STAT 17:get_hits 5876286969
STAT 17:cmd_set 602661036
STAT 17:delete_hits 0
STAT 17:incr_hits 0
STAT 17:decr_hits 0
STAT 17:cas_hits 0
STAT 17:cas_badval 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这只是slabs中slabclass[17]的结构.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STAT 1:chunk_size 96 STAT 1:total_pages 1
STAT 2:chunk_size 120 STAT 2:total_pages 3
STAT 3:chunk_size 152 STAT 3:total_pages 1
STAT 4:chunk_size 192 STAT 4:total_pages 42
STAT 5:chunk_size 240 STAT 5:total_pages 13
STAT 6:chunk_size 304 STAT 6:total_pages 84
STAT 7:chunk_size 384 STAT 7:total_pages 2
STAT 8:chunk_size 480 STAT 8:total_pages 2
STAT 9:chunk_size 600 STAT 9:total_pages 3
STAT 10:chunk_size 752 STAT 10:total_pages 4
STAT 11:chunk_size 944 STAT 11:total_pages 6
STAT 12:chunk_size 1184 STAT 12:total_pages 3
STAT 13:chunk_size 1480 STAT 13:total_pages 1
STAT 14:chunk_size 1856 STAT 14:total_pages 1
STAT 15:chunk_size 2320 STAT 15:total_pages 3
STAT 16:chunk_size 2904 STAT 16:total_pages 20
STAT 17:chunk_size 3632 STAT 17:total_pages 28
STAT 18:chunk_size 4544 STAT 18:total_pages 19
STAT 19:chunk_size 5680 STAT 19:total_pages 7
STAT 20:chunk_size 7104 STAT 20:total_pages 3
STAT 21:chunk_size 8880 STAT 21:total_pages 2
STAT 22:chunk_size 11104 STAT 22:total_pages 1
STAT 23:chunk_size 13880 STAT 23:total_pages 1
STAT 24:chunk_size 17352 STAT 24:total_pages 1
STAT 25:chunk_size 21696 STAT 25:total_pages 1
STAT 26:chunk_size 27120 STAT 26:total_pages 1
STAT 27:chunk_size 33904 STAT 27:total_pages 1
STAT 28:chunk_size 42384 STAT 28:total_pages 1
STAT 29:chunk_size 52984 STAT 29:total_pages 1
STAT 31:chunk_size 82792 STAT 31:total_pages 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;摘取的数据, 说明大部分的items的大小是304.(这跟我们框架将每一个对象都缓存,一个对象的大小差不多就是304)导致&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Memcache 内存分配</title>
   <link href="http://baotiao.github.io//2012/02/memcache-slabs/"/>
   <updated>2012-02-18T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/02/memcache-slabs</id>
   <content type="html">&lt;p&gt;内存分配主要在slab.c里面实现.
slabclass 的数据结构&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct {
    unsigned int size;      /* sizes of items */  每一个chunk的大小
    unsigned int perslab;   /* how many items per slab */ 每一个slab包含的chunk的数目

    void **slots;           /* list of item ptrs */ 是当前slab class的空闲的chunk块指针数组    
    unsigned int sl_total;  /* size of previous array */ 已分配的slots数据的大小
    unsigned int sl_curr;   /* first free slot */ 当前可用的slots数组的索引

    void *end_page_ptr;         /* pointer to next free item at end of page, or 0 */ //这个指针指向最新的那个page可用的chunk处
    unsigned int end_page_free; /* number of items remaining at end of last alloced page */ //这个是新的那个page里面可用的chunk的个数,如果*end_page_prt != NUll 并且 end_page_free == 0 说明最后一个page也被填满数据了.

    unsigned int slabs;     /* how many slabs were allocated for this class */ //这个是当前已使用的slab_list的数量

    void **slab_list;       /* array of slab pointers */ //这个是所有的page的list, 每新添加一个page.
    unsigned int list_size; /* size of prev array */ //slab_list指针数组已分配的大小

    unsigned int killing;  /* index+1 of dying slab, or zero if none */
    size_t requested; /* The number of requested bytes */
} slabclass_t;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;slabs 模型. (网上找的,我觉得表示最好的一张图,结合图看下面的函数分析)
&lt;a href=&quot;http://chenzongzhi.info/wp-content/uploads/2012/02/slabs.jpeg&quot;&gt;&lt;img src=&quot;http://chenzongzhi.info/wp-content/uploads/2012/02/slabs.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;﻿&lt;/p&gt;

&lt;p&gt;几个重要变量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static slabclass_t slabclass[MAX_NUMBER_OF_SLAB_CLASSES];
static size_t mem_limit = 0; //内存限制的大小
static size_t mem_malloced = 0;
static int power_largest;

static void *mem_base = NULL; //分配的整块大内存的位置
static void *mem_current = NULL; //目前可用的内存的位置
static size_t mem_avail = 0; //剩余可用的内存的大小
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数介绍:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
     就是根据传进来的size.找到第一个slab class的size比他大的slab class.返回slab class的id.
*/
unsigned int slabs_clsid(const size_t size) {
    int res = POWER_SMALLEST;

    if (size == 0)
        return 0;
    while (size &amp;gt; slabclass[res].size)
        if (res++ == power_largest)     /* won't fit in the biggest slab */
            return 0;
    return res;
}

/*
     slabs初始化函数,初始化了生成一个链表slabclass.
     slabclass 就是size大小不同的,然后size * perslab = 1M的一个链表,然后在这个链表里面每添加一个slab,这个slab也叫page.也就是不断往这个链表后面添加page.然后每个page里面的有perslab 数的chunk,然后真正的数据是叫item,item存在正好比item大一点的chunk上.
     以后每次添加新的page,都是先找到相应大小的那个类型的slab,然后插入在slabclass这个链表的slab_list的后面
*/

void slabs_init(const size_t limit, const double factor, const bool prealloc) {
    int i = POWER_SMALLEST - 1;
    unsigned int size = sizeof(item) + settings.chunk_size; //初始化最小的slabclass里面的size
    mem_limit = limit;

    if (prealloc) { //选择了prealloc就是预先分配一个大内存 然后初始化mem_base,mem_current,mem_avail.
        /* Allocate everything in a big chunk with malloc */
        mem_base = malloc(mem_limit); //分配mem_limit大小的内存
        if (mem_base != NULL) {
            mem_current = mem_base;
            mem_avail = mem_limit;
        } else {
            fprintf(stderr, &quot;Warning: Failed to allocate requested memory in&quot;
                    &quot; one large chunk.\nWill allocate in smaller chunks\n&quot;);
        }
    }

    memset(slabclass, 0, sizeof(slabclass));

    /*
        这里是初始化slabclass链表的过程,根据最小的size.然后size*factor 逐渐加上去
        直到size = 1M 为止
    */
    while (++i &amp;lt; POWER_LARGEST &amp;amp;&amp;amp; size &amp;lt;= settings.item_size_max / factor) {

    省略..
             if (pre_alloc == NULL || atoi(pre_alloc) != 0) {
            slabs_preallocate(power_largest);
          //这个函数是给没一个slabclass都预先分配一个slabs,也就是1M的大小.
          //所以每一个slabclass都会有一个1M大小的空间.不过这样有存在内存浪费,因为有可能有些
          //slabs不会被用到
        }
}

/*
     预先为所有的slabclass分配空间
*/
static void slabs_preallocate (const unsigned int maxslabs) {
    int i;
    unsigned int prealloc = 0;

    /* pre-allocate a 1MB slab in every size class so people don't get
       confused by non-intuitive &quot;SERVER_ERROR out of memory&quot;
       messages.  this is the most common question on the mailing
       list.  if you really don't want this, you can rebuild without
       these three lines.  */

    for (i = POWER_SMALLEST; i &amp;lt;= POWER_LARGEST; i++) {
        if (++prealloc &amp;gt; maxslabs)
            return;
        do_slabs_newslab(i);
    }
}

/*
    调整slabclass的slab_list指针数组,如果为空,这默认分配16个,如果存在,那么*2的增加slab_list数组*/
static int grow_slab_list (const unsigned int id) {
    slabclass_t *p = &amp;amp;slabclass;[id];
    if (p-&amp;gt;slabs == p-&amp;gt;list_size) {  //当slabclass里面的slabs(当前已使用的slab_list的数量)和list_size(已分配的slab_list的数量)相等时,
                                    //表示这个slab_list的已经用完了,需要生成新的slab_list
        size_t new_size =  (p-&amp;gt;list_size != 0) ? p-&amp;gt;list_size * 2 : 16; //如果list_size是空,自&amp;gt;动生成16个,否则就是*2的增长
        void *new_list = realloc(p-&amp;gt;slab_list, new_size * sizeof(void *)); //把这个list realloc到新的空间去
        if (new_list == 0) return 0;
        p-&amp;gt;list_size = new_size;
        p-&amp;gt;slab_list = new_list;
    }
    return 1;
}

/*
    为某一个slabclass分配一个新的slab.真正执行分配一个slab的是memory_allocate函数
    其实memori_alocate函数做的就是从mem_current找到len大小的空间,并返回mem_current的地址
*/
static int do_slabs_newslab(const unsigned int id) {
    slabclass_t *p = &amp;amp;slabclass;[id];
    int len = p-&amp;gt;size * p-&amp;gt;perslab;
    char *ptr;

    /*
        这里判断slab_list这个指针数据大小够不够,不够分配新的空间.
        memory_allocate分配新的大小的空间
    */
    if ((mem_limit &amp;amp;&amp;amp; mem_malloced + len &amp;gt; mem_limit &amp;amp;&amp;amp; p-&amp;gt;slabs &amp;gt; 0) ||
        (grow_slab_list(id) == 0) ||
        ((ptr = memory_allocate((size_t)len)) == 0)) { //在这里声明大小为 1M的page.

        MEMCACHED_SLABS_SLABCLASS_ALLOCATE_FAILED(id);
        return 0;
    }     

    memset(ptr, 0, (size_t)len);
    p-&amp;gt;end_page_ptr = ptr; //将end_page_ptr 也就是表示最新的可用的chunk的指针指向ptr
    p-&amp;gt;end_page_free = p-&amp;gt;perslab; //end_page_free 因为这里是一个全新的page 所以 end_page_free = p-&amp;gt;perslabs
    p-&amp;gt;slab_list[p-&amp;gt;slabs++] = ptr; //将ptr 加入道p-&amp;gt;slab_list里面去,并且 page 的个数++
    mem_malloced += len;
    MEMCACHED_SLABS_SLABCLASS_ALLOCATE(id);

    return 1;
}

/*
    这个是进行给slab分配内存的函数,会判断是否有足够的空间,已经然后将目前的mem_current返回,然后&amp;gt;调整mem_current的值
*/
static void *memory_allocate(size_t size) {
    void *ret;

    if (mem_base == NULL) {
        /* We are not using a preallocated large memory chunk */
        ret = malloc(size);
    } else {
        ret = mem_current;

        if (size &amp;gt; mem_avail) {
            return NULL;
        }

        /* mem_current pointer _must_ be aligned!!! */
        if (size % CHUNK_ALIGN_BYTES) {
            size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES);
        }

        mem_current = ((char*)mem_current) + size;

        if (size &amp;lt; mem_avail) {
            mem_avail -= size;
        } else {
            mem_avail = 0;
        }
    }

    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到此处理slabs已经初始化结束了.memcached还提供了一个空闲item链表,叫slots.就是当一个slabs里面的item已经过期了,那么这个chunk不是退回给内存池,而是放入到这个空闲链表里面去,同样当申请一个新元素的时候也是先判断这个slots数组是否有空间,没有空间再去slabs里面去获得.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static void *do_slabs_alloc(const size_t size, unsigned int id) {
     ..省略..
/*
        这里判断end_page_ptr是否指向可用的chunk, 当前slabclass的slots的空闲chunk个数
        以及是否可以新分配一块slab
        如果可以获得空间的话,先从slabclass的slots里面获得,然后才是从slab里面的end_page_ptr处去&amp;gt;获得
    */
    if (! (p-&amp;gt;end_page_ptr != 0 || p-&amp;gt;sl_curr != 0 ||
           do_slabs_newslab(id) != 0)) {
        /* We don't have more memory available */
        ret = NULL;
    } else if (p-&amp;gt;sl_curr != 0) {
        /* return off our freelist */
        ret = p-&amp;gt;slots[--p-&amp;gt;sl_curr];
    } else {
        /* if we recently allocated a whole page, return from that */
        assert(p-&amp;gt;end_page_ptr != NULL);
        ret = p-&amp;gt;end_page_ptr;
        if (--p-&amp;gt;end_page_free != 0) {
            p-&amp;gt;end_page_ptr = ((caddr_t)p-&amp;gt;end_page_ptr) + p-&amp;gt;size;
        } else {
            p-&amp;gt;end_page_ptr = 0;
        }
    }

    if (ret) {
        p-&amp;gt;requested += size;
        MEMCACHED_SLABS_ALLOCATE(size, id, p-&amp;gt;size, ret);
    } else {
        MEMCACHED_SLABS_ALLOCATE_FAILED(size, id);
    }

    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数主要是将slab里面的chunk设置成free. 设置free不是把他归还给内存池
而是把这个item放入到这个slabclass的slots中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static void do_slabs_free(void *ptr, const size_t size, unsigned int id) {
    slabclass_t *p;

    assert(((item *)ptr)-&amp;gt;slabs_clsid == 0);
    assert(id &amp;gt;= POWER_SMALLEST &amp;amp;&amp;amp; id &amp;lt;= power_largest);
    if (id &amp;lt; POWER_SMALLEST || id &amp;gt; power_largest)
        return;

    MEMCACHED_SLABS_FREE(size, id, ptr);
    p = &amp;amp;slabclass;[id];

    /*
        刚开始看这里的时候不明白,为什么slots数组需要malloc空间,
        因为slots是指针数组,这里malloc分配的内存空间是给这个指针数组的.
        然后这个数组每一个都指向在slab里面被free的chunk.
    */
    if (p-&amp;gt;sl_curr == p-&amp;gt;sl_total) { /* need more space on the free list */
        int new_size = (p-&amp;gt;sl_total != 0) ? p-&amp;gt;sl_total * 2 : 16;  /* 16 is arbitrary */
        void **new_slots = realloc(p-&amp;gt;slots, new_size * sizeof(void *));
        //这里是给slots数组malloc了这么多数量的void指针.
        if (new_slots == 0)
            return;
        p-&amp;gt;slots = new_slots;
        p-&amp;gt;sl_total = new_size;
    }
    p-&amp;gt;slots[p-&amp;gt;sl_curr++] = ptr; //这里把sl_curr指向了这个ptr,这个ptr就是一个slab里面的一个空&amp;gt;闲的chunk处.所以这里空闲数组又获得了一个空间,这里sl_curr可用的slots数+1.
    p-&amp;gt;requested -= size;
    return;
}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>event + 线程池模型的 server 类似 Memcache线程池模型</title>
   <link href="http://baotiao.github.io//2012/02/event-like-memcache/"/>
   <updated>2012-02-04T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/02/event-like-memcache</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;/*
    main.h
    定义了三个数据结构 conn_queue_item,work_thread,dispatch_thread.
    conn_queue_item 只是存dispatch_thread accept 以后的描述符,然后
    dispatch_thread 将conn_queue_item 存入某一个work_thread.
    work_thread 真正负责work的thread.
    dispatch_thread 监听9877端口,并且将accept后的fd传给work_thread.
*/
#ifndef MAINH
#define MAINH

#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;event.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;netinet/in.h&amp;gt;
#include &amp;lt;sys/socket.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;

typedef struct conn_queue_item CQ;

struct conn_queue_item {
    int sfd;
};

struct WORK_THREAD {
    pthread_t thread_id;
    struct event_base *base;
    struct event notify_event;
    int notify_receive_fd;
    int notify_send_fd;
    struct conn_queue_item cq;
};
typedef struct WORK_THREAD wk_thread;

struct DISPATCH_THREAD {
    pthread_t thread_id;
    struct event_base *base;
};
typedef struct DISPATCH_THREAD dh_thread;

#endif

主要的执行函数main.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;event.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;netinet/in.h&amp;gt;
#include &amp;lt;sys/socket.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &quot;main.h&quot;

static struct event_base *main_base;

void call_accept(int fd, short event, void *arg)
{
    fputs(&quot;a socket has come\n&quot;, stdout);
    struct sockaddr_in cliaddr;
    socklen_t clilen;
    int connfd;
    connfd = accept(fd, (struct sockaddr *) &amp;amp;cliaddr, &amp;amp;clilen);
    dispatch_new_thread(connfd);
}



int main()
{

    int listenfd, connfd;
    struct sockaddr_in cliaddr, servaddr;
    socklen_t clilen;

    listenfd = socket(AF_INET, SOCK_STREAM, 0);
    memset(&amp;amp;servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);
    servaddr.sin_port = htons(9877);
    bind(listenfd, (struct sockaddr *) &amp;amp;servaddr, sizeof(servaddr));
    listen(listenfd, 10);

    struct event_base *mb;
    struct event ev;
    mb = event_init();
    event_set(&amp;amp;ev, listenfd, EV_READ | EV_PERSIST, call_accept, &amp;amp;ev);
    //event_base_set(main_base, &amp;amp;ev);
    event_add(&amp;amp;ev, NULL);
    printf(&quot;add the event\n&quot;);

    thread_init(10, mb);

    printf(&quot;block before accept\n&quot;);
    event_base_loop(mb, 0);

    return 0;
}

线程池模型. 每一个work_thread监听自己的notify_receive_fd READ 事件,然后dispatch_thread 往notify_receive_fd 写入一字节的数据.接着 work_thread
就处理从dispatch_thread 传送过来的fd 的请求
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;event.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;netinet/in.h&amp;gt;
#include &amp;lt;sys/socket.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &quot;main.h&quot;


static dh_thread dispatch_thread;

static wk_thread *threads;

static int last_thread = -1;

void dispatch_new_thread(int fd)
{
    int tid = (last_thread + 1) % 10;
    wk_thread *thread = threads + tid;

    thread-&amp;gt;cq.sfd = fd;
    write(thread-&amp;gt;notify_send_fd, &quot;&quot;, 1);
}


void thread_libevent_process(int fd, short which, void *arg)
{
    wk_thread *work_thread = arg;
    char unuse[1];
    if (read(fd, unuse, 1) != 1) {
        fprintf(stderr, &quot;Can't read from libevent\n&quot;);
    }
    char buf[100];
    int n;
    n = read(work_thread-&amp;gt;cq.sfd, buf, 100);
    write(work_thread-&amp;gt;cq.sfd, buf, n);
}

void setup_thread(wk_thread *work_thread)
{   
    work_thread-&amp;gt;base = event_init();
    if (!work_thread-&amp;gt;base) {
        fprintf(stdout, &quot;Can't allocate event base\n&quot;);
        exit(1);
    }

    event_set(&amp;amp;work_thread-&amp;gt;notify_event, work_thread-&amp;gt;notify_receive_fd, EV_READ | EV_PERSIST, thread_libevent_process, work_thread);
    event_base_set(work_thread-&amp;gt;base, &amp;amp;work_thread-&amp;gt;notify_event);
    if (event_add(&amp;amp;work_thread-&amp;gt;notify_event, 0) == -1) {
        fprintf(stdout, &quot;Can't add libevent notify pipe\n&quot;);
        exit(1);
    }
}

void worker_libevent(void *arg)
{
    wk_thread *work_thread = arg;
    event_base_loop(work_thread-&amp;gt;base, 0);
}

void create_worker(void *(*func)(void *), void *arg)
{
    pthread_t thread;
    pthread_attr_t attr;
    int ret;
    pthread_attr_init(&amp;amp;attr);

    if ((ret = pthread_create(&amp;amp;thread, &amp;amp;attr, func, arg)) != 0) {
        fprintf(stdout, &quot;Can't create thread: %s\n&quot;, strerror(ret));
        exit(1);
    }
}


void thread_init(int t_num, struct event_base *main_base)
{
    dispatch_thread.base = main_base;
    dispatch_thread.thread_id = pthread_self();
    int i;
    threads = calloc(t_num, sizeof(wk_thread));
    if (!threads) {
        perror(&quot;Can't alloc so many thread\n&quot;);
        exit(1);
    }

    for (i = 0; i &amp;lt; t_num; i++) {
        int fds[2];
        if (pipe(fds)) {
            perror(&quot;can't pipe\n&quot;);
            exit(1);
        }
        threads[i].notify_receive_fd = fds[0];
        threads[i].notify_send_fd = fds[1];

        setup_thread(&amp;amp;threads[i]);
    }

    for (i = 0; i &amp;lt; t_num; i++) {
        create_worker(worker_libevent, &amp;amp;threads[i]);
    }

}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Memcache threads analysis</title>
   <link href="http://baotiao.github.io//2012/02/memcached-thread-model/"/>
   <updated>2012-02-01T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2012/02/memcached-thread-model</id>
   <content type="html">&lt;p&gt;memcached 启动时线程处理流程&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://175.41.172.193/wp-content/uploads/2012/02/thread1.jpg&quot;&gt;&lt;img src=&quot;http://175.41.172.193/wp-content/uploads/2012/02/thread1-113x300.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;memcached 是利用libevent实现了一个线程池.有一个dispatch_thread 和 n 个work_thread构成.&lt;/p&gt;

&lt;p&gt;主要的数据结构以及简单操作
在thread.c里面有&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* An item in the connection queue. */
typedef struct conn_queue_item CQ_ITEM;
struct conn_queue_item {
    int               sfd;  //对应每个connection的 fd
    enum conn_states  init_state;
    int               event_flags;
    int               read_buffer_size;
    enum network_transport     transport;
    CQ_ITEM          *next;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个CQ_ITEM 是对每一个connection的描述.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* A connection queue. */
typedef struct conn_queue CQ;
struct conn_queue {
    CQ_ITEM *head;
    CQ_ITEM *tail;
    pthread_mutex_t lock;
    pthread_cond_t  cond;

};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就是connection_queue 每个工作线程都有一个connection queue. CQ中的每个CQ_ITEM都是对一个socket连接的简单描述.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* * Looks for an item on a connection queue, but doesn't block if there isn't
 * one.
 * Returns the item, or NULL if no item is available
 */
static CQ_ITEM *cq_pop(CQ *cq) {
    CQ_ITEM *item;

    pthread_mutex_lock(&amp;amp;cq-;&amp;gt;lock);
    item = cq-&amp;gt;head;
    if (NULL != item) {
        cq-&amp;gt;head = item-&amp;gt;next;
        if (NULL == cq-&amp;gt;head)
            cq-&amp;gt;tail = NULL;
    }
    pthread_mutex_unlock(&amp;amp;cq-;&amp;gt;lock);

    return item;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个是对cq里面的item的pop操作. 可以看出cq只是指向了item,然后通过item之间的链表连接起来.从而获得每个工作线程需要处理的item.&lt;/p&gt;

&lt;p&gt;有1个空闲的CQ_ITEM链表&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static CQ_ITEM *cqi_freelist; //这是空闲的cqitem 链表
static pthread_mutex_t cqi_freelist_lock; //这个是链表的锁.用于对链表添加元素时加锁

/* * Returns a fresh connection queue item.
 */
static CQ_ITEM *cqi_new(void) {
    CQ_ITEM *item = NULL;
    pthread_mutex_lock(&amp;amp;cqi;_freelist_lock);
    if (cqi_freelist) {
        item = cqi_freelist;
        cqi_freelist = item-&amp;gt;next;
    }
    pthread_mutex_unlock(&amp;amp;cqi;_freelist_lock);

    if (NULL == item) {
        int i;

        /* Allocate a bunch of items at once to reduce fragmentation */
        item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC);
        if (NULL == item)
            return NULL;
/*其中 malloc的时候是直接malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC) ITEMS_PER_ALLOC个的CQ_ITEM 减少了每个item之间的碎片的产生.*/

        /*
         * Link together all the new items except the first one
         * (which we'll return to the caller) for placement on
         * the freelist.
         */
        for (i = 2; i &amp;lt; ITEMS_PER_ALLOC; i++)
            item[i - 1].next = &amp;amp;item;[i];

        pthread_mutex_lock(&amp;amp;cqi;_freelist_lock);
        item[ITEMS_PER_ALLOC - 1].next = cqi_freelist;
        cqi_freelist = &amp;amp;item;[1];
        pthread_mutex_unlock(&amp;amp;cqi;_freelist_lock);
    }

    return item;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是new 一个cq_item的操作, 其中 malloc的时候是直接malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC) ITEMS_PER_ALLOC个的CQ_ITEM 减少了每个item之间的碎片的产生.然后是将malloc出来的这么多的cq_item链接起来.然后再将其加入到 cqi_freelist中.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Frees a connection queue item (adds it to the freelist.)
 */
static void cqi_free(CQ_ITEM *item) {
    pthread_mutex_lock(&amp;amp;cqi;_freelist_lock);
    item-&amp;gt;next = cqi_freelist;
    cqi_freelist = item;
    pthread_mutex_unlock(&amp;amp;cqi;_freelist_lock);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Free 一个cq_item 的时候是将其直接放入到cqi_freelist里面去.&lt;/p&gt;

&lt;p&gt;每一个work_thread在初始化的时候都有一个cq&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct conn conn;struct conn {
    int    sfd;
    sasl_conn_t *sasl_conn;
    enum conn_states  state;
    enum bin_substates substate;
    struct event event;
    short  ev_flags;
    short  which;   /** which events were just triggered */

    char   *rbuf;   /** buffer to read commands into */
    char   *rcurr;  /** but if we parsed some already, this is where we stopped */
    int    rsize;   /** total allocated size of rbuf */
    int    rbytes;  /** how much data, starting from rcur, do we have unparsed */

    char   *wbuf;
    char   *wcurr;    int    wsize;
    int    wbytes;
    /** which state to go into after finishing current write */
    enum conn_states  write_and_go;
    void   *write_and_free; /** free this memory after finishing writing */

    char   *ritem;  /** when we read in an item's value, it goes here */
    int    rlbytes;

    /* data for the nread state */

    /**
     * item is used to hold an item structure created after reading the command
     * line of set/add/replace commands, but before we finished reading the actual
     * data. The data is read into ITEM_data(item) to avoid extra copying.
     */

    void   *item;     /* for commands set/add/replace  */

    /* data for the swallow state */
    int    sbytes;    /* how many bytes to swallow */

    /* data for the mwrite state */
    struct iovec *iov;
    int    iovsize;   /* number of elements allocated in iov[] */
    int    iovused;   /* number of elements used in iov[] */

    struct msghdr *msglist;
    int    msgsize;   /* number of elements allocated in msglist[] */
    int    msgused;   /* number of elements used in msglist[] */
    int    msgcurr;   /* element in msglist[] being transmitted now */
    int    msgbytes;  /* number of bytes in current msg */

    item   **ilist;   /* list of items to write out */
    int    isize;
    item   **icurr;
    int    ileft;

    char   **suffixlist;
    int    suffixsize;
    char   **suffixcurr;
    int    suffixleft;

    enum protocol protocol;   /* which protocol this connection speaks */
    enum network_transport transport; /* what transport is used by this connection */

    /* data for UDP clients */
    int    request_id; /* Incoming UDP request ID, if this is a UDP &quot;connection&quot; */
    struct sockaddr request_addr; /* Who sent the most recent request */
    socklen_t request_addr_size;
    unsigned char *hdrbuf; /* udp packet headers */
    int    hdrsize;   /* number of headers' worth of space is allocated */

    bool   noreply;   /* True if the reply should not be sent. */
    /* current stats command */
    struct {
        char *buffer;
        size_t size;
        size_t offset;

    } stats;
    /* Binary protocol stuff */
    /* This is where the binary header goes */
    protocol_binary_request_header binary_header;
    uint64_t cas; /* the cas to return */
    short cmd; /* current command being processed */
    int opaque;
    int keylen;
    conn   *next;     /* Used for generating a list of conn structures */
    LIBEVENT_THREAD *thread; /* Pointer to the thread object serving this connection */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;memcached 的conn 代表一个到memcached的链接.
里面的item是连接成功后,读入 set/add/replace 生成的cq_item.
conn-&gt;thread 是指向要处理的线程对象.然后将item加入到LIBEVENT_THREAD 对象的 struct conn_queue new_conn_queue中
同样也是有一个free list 叫 freeconns&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static conn **freeconns;
static int freetotal; //总的freeconns的大小
static int freecurr; //目前的空闲的 freeconn 的大小

/*
 * Adds a connection to the freelist. 0 = success.
 */
bool conn_add_to_freelist(conn *c) {
    bool ret = true;
    pthread_mutex_lock(&amp;amp;conn;_lock);
    if (freecurr &amp;lt; freetotal) {
        freeconns[freecurr++] = c;
        ret = false;
    } else {
        /* try to enlarge free connections array */
        size_t newsize = freetotal * 2;
        conn **new_freeconns = realloc(freeconns, sizeof(conn *) * newsize);
        if (new_freeconns) {
            freetotal = newsize;
            freeconns = new_freeconns;
            freeconns[freecurr++] = c;
            ret = false;
        }
    }
    pthread_mutex_unlock(&amp;amp;conn;_lock);
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加一个 connection 到 freelist, 如果超过了freetotal的大小,那么就将freetotal*2 然后realloc一块新的是原来2倍内存的大小.然后把这个connection添加进去,发现好多地方都是这么做的&lt;/p&gt;

&lt;p&gt;memcached的多线程主要是通过实例化多个libevent实现的,分别是一个主线程和n个worker线程.无论是主线程还是worker线程全部通过libevent管理网络事件,实际上每个线程都是一个单独的libevent实例.
主线程负责监听客户端的建立连接请求,以及建立连接后将连接好后生成的connection发送给work_thread去负责处理&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://175.41.172.193/wp-content/uploads/2012/02/thread2.jpg&quot;&gt;&lt;img src=&quot;http://175.41.172.193/wp-content/uploads/2012/02/thread2-300x234.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;dispatcher_thread 和 worker_thread 的定义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct {
    pthread_t thread_id;        /* unique ID of this thread */
    struct event_base *base;    /* libevent handle this thread uses */
    struct event notify_event;  /* listen event for notify pipe */
    int notify_receive_fd;      /* receiving end of notify pipe */
    int notify_send_fd;         /* sending end of notify pipe */
    struct thread_stats stats;  /* Stats generated by this thread */
    struct conn_queue *new_conn_queue; /* queue of new connections to handle */
    cache_t *suffix_cache;      /* suffix cache */
} LIBEVENT_THREAD;

typedef struct {
    pthread_t thread_id;        /* unique ID of this thread */
    struct event_base *base;    /* libevent handle this thread uses */
} LIBEVENT_DISPATCHER_THREAD;

thread_init是启动所有的worker线程的核心方法.
void thread_init(int nthreads, struct event_base *main_base) {
     ......//加锁等操作
    for (i = 0; i &amp;lt; item_lock_count; i++) {
        pthread_mutex_init(&amp;amp;item;_locks[i], NULL);
    }

    threads = calloc(nthreads, sizeof(LIBEVENT_THREAD));
    if (! threads) {
        perror(&quot;Can't allocate thread descriptors&quot;);
        exit(1);
    }

    dispatcher_thread.base = main_base; //dispatcher_thread是静态的全局变量.dispatcher_thread 注册的事件是main_base时间,也就是负责监听socket请求的事件
    dispatcher_thread.thread_id = pthread_self(); 

    for (i = 0; i &amp;lt; nthreads; i++) { //这里是为每一个线程创建一个pipe,这个pipe被用来作为dispatch通知worker线程有新的连接到达
        int fds[2];
        if (pipe(fds)) {
            perror(&quot;Can't create notify pipe&quot;);
            exit(1);
        }

        threads[i].notify_receive_fd = fds[0];
        threads[i].notify_send_fd = fds[1];

        setup_thread(&amp;amp;threads;[i]);
        /* Reserve three fds for the libevent base, and two for the pipe */
        stats.reserved_fds += 5;
    }

    /* Create threads after we've done all the libevent setup. */
    for (i = 0; i &amp;lt; nthreads; i++) {
        create_worker(worker_libevent, &amp;amp;threads;[i]);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是setup_thread 方法,setup_thread 方法主要是创建所有worker线程的libevent实例(主线程的libevent实例在main函数里面创建)
注册所有worker线程的管道读端的libevent的读事件,等待主线程的通知.然后初始化所有worker的CQ.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static void setup_thread(LIBEVENT_THREAD *me) {
    me-&amp;gt;base = event_init();
    if (! me-&amp;gt;base) {
        fprintf(stderr, &quot;Can't allocate event base\n&quot;);
        exit(1);
    }

    /* Listen for notifications from other threads */
    event_set(&amp;amp;me-;&amp;gt;notify_event, me-&amp;gt;notify_receive_fd,
              EV_READ | EV_PERSIST, thread_libevent_process, me);
    event_base_set(me-&amp;gt;base, &amp;amp;me-;&amp;gt;notify_event);

    if (event_add(&amp;amp;me-;&amp;gt;notify_event, 0) == -1) {
        fprintf(stderr, &quot;Can't monitor libevent notify pipe\n&quot;);
        exit(1);
    }

    me-&amp;gt;new_conn_queue = malloc(sizeof(struct conn_queue));
    if (me-&amp;gt;new_conn_queue == NULL) {
        perror(&quot;Failed to allocate memory for connection queue&quot;);
        exit(EXIT_FAILURE);
    }
    cq_init(me-&amp;gt;new_conn_queue);

    if (pthread_mutex_init(&amp;amp;me-;&amp;gt;stats.mutex, NULL) != 0) {
        perror(&quot;Failed to initialize mutex&quot;);
        exit(EXIT_FAILURE);
    }

    me-&amp;gt;suffix_cache = cache_create(&quot;suffix&quot;, SUFFIX_SIZE, sizeof(char*),
                                    NULL, NULL);
    if (me-&amp;gt;suffix_cache == NULL) {
        fprintf(stderr, &quot;Failed to create suffix cache\n&quot;);
        exit(EXIT_FAILURE);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后 create_worker启动了所有线程,pthread_create调用worker_libevent方法,这个方法又调用event_base_loop() 启动该线程的libevent.&lt;/p&gt;

&lt;p&gt;在server_socket函数中,主要就是建立一个socket并且绑定到一个port上.然后调用conn_new(这里传入的事件是main_base)注册事件
event_set(&amp;amp;c-&gt;event, sfd, event_flags, event_handler, (void *)c);
事件为持久可读,所以dispatch_thread在当前listen的socket可读时,就会调用event_handler,进而调用driver_machine(c) 进入状态机.而在driver_machin中,如果是主线程(dispatch_thread)则会在accept socket 后调用dispatch_new_conn函数来给各个work_thread派发connection&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static int server_socket(const char *interface,
                         int port,
                         enum network_transport transport,
                         FILE *portnumber_file) {
     ....
            if (!(listen_conn_add = conn_new(sfd, conn_listening,
                                             EV_READ | EV_PERSIST, 1,
                                             transport, main_base))) { 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此 dispatch_thread 和 worker_threads的libevent都已开启&lt;/p&gt;

&lt;p&gt;thread_libevent_process是worker_thread的管道读端有事件的时候调用的方法.参数fd是这个worker_thread的管道读端的描述符.
首先将管道的1个字节读出,这一个字节是dispatch_thread写入的.用来通知表示有数据写入.然后从自己的CQ里面pop出一个item进行处理,这个item是被dispatch_thread丢到这个cq队列中的.
item-&gt;sfd是已建立的socket连接的描述符,通过conn_new函数为该描述符注册libevent的读事件,me-&gt;base 是 struct event_base 代表自己的一个线程结构体,就是说对该描述符的事件处理交给当前这个worker_thread处理.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Processes an incoming &quot;handle a new connection&quot; item. This is called when
 * input arrives on the libevent wakeup pipe.
 */
static void thread_libevent_process(int fd, short which, void *arg) {
    LIBEVENT_THREAD *me = arg;
    CQ_ITEM *item;
    char buf[1];

    if (read(fd, buf, 1) != 1)
        if (settings.verbose &amp;gt; 0)
            fprintf(stderr, &quot;Can't read from libevent pipe\n&quot;);

    item = cq_pop(me-&amp;gt;new_conn_queue);

    if (NULL != item) {
        conn *c = conn_new(item-&amp;gt;sfd, item-&amp;gt;init_state, item-&amp;gt;event_flags,
                           item-&amp;gt;read_buffer_size, item-&amp;gt;transport, me-&amp;gt;base);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来是conn_new函数,前面是一系列的判断,从conn_from_freelist()取得连接.
这里注册了事件,由当前线程处理,(因为这里的event_base是改work_thread自己的)
当该连接有可读时会回调event_handler函数,event_handler调用memcached最核心的方法drive_machine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conn *conn_new(const int sfd, enum conn_states init_state,
                const int event_flags,
                const int read_buffer_size, enum network_transport transport,
                struct event_base *base) {
     ......
    event_set(&amp;amp;c-;&amp;gt;event, sfd, event_flags, event_handler, (void *)c);
    event_base_set(base, &amp;amp;c-;&amp;gt;event);
    c-&amp;gt;ev_flags = event_flags;

    if (event_add(&amp;amp;c-;&amp;gt;event, 0) == -1) {
        if (conn_add_to_freelist(c)) {
            conn_free(c);
        }
        perror(&quot;event_add&quot;);
        return NULL;
    }

    STATS_LOCK();
    stats.curr_conns++;
    stats.total_conns++;
    STATS_UNLOCK();

    MEMCACHED_CONN_ALLOCATE(c-&amp;gt;sfd);

    return c;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面将dispatch_thread 会向work_thread写入一字节的数据.dispatch_thread注册的是监听socket可读的事件,然后当有建立连接请求时,dispatch_thread会处理,回调函数也是event_handler(因为dispatch_thread也是通过conn_new初始化监听socket的libevent可读事件)&lt;/p&gt;

&lt;p&gt;driven_machine 网络事件处理最核心函数 是所有线程在connection来到时都要调用的函数.
driven_machine 主要就是通过当前连接的conn的state来判断进行何种处理,因为libevent注册了读写事件回调的都是这个函数,所以实际上我们在注册libevent相应事件时,会同时把事件的状态写入到conn结构体里,libevent进行回调时会把该conn结构作为参数传过来&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static void drive_machine(conn *c) {
     ...
    while (!stop) {
     ...
        switch(c-&amp;gt;state) {

        case conn_listening:// 该状态是conn_listening状态,只有dispatch_thread才会进入
          ....
          dispatch_conn_new(sfd, conn_new_cmd,EV_READ|EV_PERSIST,
                                     DATA_BUFFER_SIZE, tcp_transport);
          //这里就是dispatch_thread 通知 work_thread 的地方了.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;memcached.h里面conn的stat的声明&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * NOTE: If you modify this table you _MUST_ update the function state_text
 */
/**
 * Possible states of a connection.
 */
enum conn_states {
    conn_listening,  /**&amp;lt; the socket which listens for connections */
    conn_new_cmd,    /**&amp;lt; Prepare connection for next command */
    conn_waiting,    /**&amp;lt; waiting for a readable socket */
    conn_read,       /**&amp;lt; reading in a command line */
    conn_parse_cmd,  /**&amp;lt; try to parse a command from the input buffer */
    conn_write,      /**&amp;lt; writing out a simple response */
    conn_nread,      /**&amp;lt; reading in a fixed number of bytes */
    conn_swallow,    /**&amp;lt; swallowing unnecessary bytes w/o storing */
    conn_closing,    /**&amp;lt; closing this connection */
    conn_mwrite,     /**&amp;lt; writing out many items sequentially */
    conn_max_state   /**&amp;lt; Max state value (used for assertion) */
};

dispatch_conn_new 将一个新的connection给另外一个thread.这个函数只有dispatch_thread才会调用.
/* Which thread we assigned a connection to most recently. */
static int last_thread = -1;
/* 这里是静态变量 last_thread 记录的是上一次调用的thread.所以这里memcached并没有用高深的方法记录将connection 分发给哪一个thread.只是用轮询的方法实现
这里dispatch_thread 创建了一个ca_item,并插入到一个thread的cq里面.然后往对应的work_thread写入1字节的数据来通知他.这个时候work_thread立即回调了thread_libevent_process的方法来对数据进行读取. 然后work_thread线程取出这个item(item 里面包含了这次connection 的连接sfd),注册读时间,当该条连接上有数据时,最终也会回调drive_machine方法,也就是driven_machine 的 conn_read. 其他的conn 的状态全部由work_thread去处理,dispatch_thread 只负责将item 发到对应的work_thread中去.
*/

void dispatch_conn_new(int sfd, enum conn_states init_state, int event_flags,
                       int read_buffer_size, enum network_transport transport) {
    CQ_ITEM *item = cqi_new();
    int tid = (last_thread + 1) % settings.num_threads;
//这里是通过轮询找到目前要分配给的thread

    LIBEVENT_THREAD *thread = threads + tid;

    last_thread = tid;

    item-&amp;gt;sfd = sfd;
    item-&amp;gt;init_state = init_state;
    item-&amp;gt;event_flags = event_flags;
    item-&amp;gt;read_buffer_size = read_buffer_size;
    item-&amp;gt;transport = transport;

    cq_push(thread-&amp;gt;new_conn_queue, item);

    MEMCACHED_CONN_DISPATCH(sfd, thread-&amp;gt;thread_id);
    if (write(thread-&amp;gt;notify_send_fd, &quot;&quot;, 1) != 1) { //这里就是往work_thread的notify_fd 写入1字节的数据.来
        perror(&quot;Writing to thread notify pipe&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Libevent 学习 和 基于event的 echo server</title>
   <link href="http://baotiao.github.io//2012/01/libevent-e7ae80e58d95e5ada6e4b9a0-e5928c-demo/"/>
   <updated>2012-01-31T22:07:08+08:00</updated>
   <id>http://baotiao.github.io//2012/01/libevent-e7ae80e58d95e5ada6e4b9a0-e5928c-demo</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>网络编程 echo server  client</title>
   <link href="http://baotiao.github.io//2012/01/echo-server-client/"/>
   <updated>2012-01-08T23:17:44+08:00</updated>
   <id>http://baotiao.github.io//2012/01/echo-server-client</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Beanstalk 学习</title>
   <link href="http://baotiao.github.io//2011/11/beanstalk-e5ada6e4b9a0/"/>
   <updated>2011-11-12T01:41:18+08:00</updated>
   <id>http://baotiao.github.io//2011/11/beanstalk-e5ada6e4b9a0</id>
   <content type="html">&lt;p&gt;看的Beanstalk第一版的代码,因为代码比较短.小组的分享&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.slideshare.net/baotiao/beanstalk&quot;&gt;Beanstalk&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;View more &lt;a href=&quot;http://www.slideshare.net/&quot;&gt;presentations&lt;/a&gt; from &lt;a href=&quot;http://www.slideshare.net/baotiao&quot;&gt;宗志 陈&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://francepharmacieenligne.com/products/kamagra.htm&quot;&gt;kamagra&lt;/a&gt; &lt;a href=&quot;http://erektilepillenonline.com/products/viagra.htm&quot;&gt;viagra&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>函数指针和指针函数</title>
   <link href="http://baotiao.github.io//2011/10/function-point/"/>
   <updated>2011-10-23T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2011/10/function-point</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;函数指针和指针函数区别. 指针函数. 返回值是指针的函数叫指针函数. 函数的返回值可以是int,char,double,struct,也可以是指针,指针函数就是返回值是指针的函数,也就是返回的是一个地址.比如: 

char *cp(char *s, char *t) 
{ 
    t = s; return t; 
}
int main() 
{ 
    char s1[10] = &quot;hello&quot;; 
    char s2[10] = &quot;world&quot;; 
    printf(&quot;%s %sn&quot;, s1, s2); 
    printf(&quot;%sn&quot;,cp(s1,s2)); 
    return 0; 
}

这里返回值就是一个地址. 这里 char *cp(char *s, char *t)里面的第一个*我们可以看做是跟定义一个指针 char *p,里面的*是一个意思,就是只是表示这是一个指针而已.所以我们调用cp(s1,s2)返回的就是一个地址,printf(&quot;%s&quot;)的时候,传入的是一个地址或者字符串的名字.如果是一个 int *get(),那么获得返回值就是 printf(&quot;%dn&quot;,*get())就可以了.

函数指针 指向函数的指针叫函数指针. 在C语言中，函数也是一种类型，可以定义指向函数的指针。我们知道，指针变量的内存单元存放一个地址值，而函数指针存放的就是函数的入口地址(位于.text段). 下面看一个简单的例子: 例 23.3. 函数指针 

void say_hello(const char *str) 
{ 
    printf(&quot;Hello %sn&quot;, str); 
} 
int main(void) { 
    void (*f)(const char *) = say_hello; //注意这里*f必须加()否则就和上面说的函数指针混乱了. 
    f(&quot;Guys&quot;); 
    return 0; 
}


分析一下变量f的类型声明void (*f)(const char *)，f首先跟*号结合在一起，因此是一个指针。(*f)外面是一个函数原型的格式，参数是const char *，返回值是void，所以f是指向这种函数的指针。而say_hello的参数是const char *，返回值是void，正好是这种函数，因此f可以指向say_hello。注意，say_hello是一种函数类型，而函数类型和数组类型类似，做右值使用时自动转换成函数指针类型，所以可以直接赋给f，当然也可以写成void (*f)(const char *) = &amp;amp;say_hello;，把函数say_hello先取地址再赋给f，就不需要自动类型转换了。
可以直接通过函数指针调用函数，如上面的f(&quot;Guys&quot;)，也可以先用*f取出它所指的函数类型，再调用函数，即(*f)(&quot;Guys&quot;)。可以这么理解：函数调用运算符()要求操作数是函数指针，所以f(&quot;Guys&quot;)是最直接的写法，而say_hello(&quot;Guys&quot;)或(*f)(&quot;Guys&quot;)则是把函数类型自动转换成函数指针然后做函数调用。
就是我们平常调用函数的时候也是先吧函数类型转换程函数指针,然后在做函数调用,有了函数指针直接把指针指向这一个函数在.text段的位置,就直接做函数调用了.函数指针可以指向所有这一类的函数.
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>introduce awk</title>
   <link href="http://baotiao.github.io//2011/08/awk-introduce/"/>
   <updated>2011-08-19T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2011/08/awk-introduce</id>
   <content type="html">&lt;p&gt;由于平常的工作都在linux下面进行,所以经常用到linux下面的awk,sed,grep等工具.
组内的一次分享.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/baotiao/czzawk&quot;&gt;introduce awk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Cola.php的默认配置以及url分发</title>
   <link href="http://baotiao.github.io//2011/08/cola-phpe79a84e9bb98e8aea4e9858de7bdaee4bba5e58f8aurle58886e58f91/"/>
   <updated>2011-08-17T15:10:42+08:00</updated>
   <id>http://baotiao.github.io//2011/08/cola-phpe79a84e9bb98e8aea4e9858de7bdaee4bba5e58f8aurle58886e58f91</id>
   <content type="html">&lt;p&gt;和cola.php 是一个叫付超群写得框架,可能对比较大型的框架理解不清楚,可以先看这个比较小型的.
0.1版就包含了框架里面最主要的几个文件,那些扩张功能还不包括在里面,非常适合让我们理解如何实现一个mvc框架的过程.
这里是对 0.1版代码的阅读记录.
1. 在demo下面的index.php 是所有动态请求的入口,也是框架的入口.
2. 在index.php里面require了Cola.php 和 config.inc.php.
其中Cola.php是最主要的函数,在Cola.php里面的&lt;em&gt;&lt;em&gt;construct函数里面定义的根目录,用spl_autoload_register 实现框架加载任意的类.
3. 其中具体的加载方法是在Cola.php下面的loadClass方法里面.
首先,有三个默认加载的方法
如果是Cola_Router 那么 就加载Cola 下的Router.php.
如果是Cola_View 那么就加载Cola 下的View.php.
如果是Cola_Controller 那么就加载Cola 下的Controller.php
如果不是上面上中情况,那么在建立一个新的类的时候,就是getInstance()的时候必须指定类名,以及目录.
那么loadClass也会找到相应的文件并包含他.
4.config.inc.php 就是包含的默认的配置文件.
$urls 是用于url 分发的时候,定义的规则,与$urls匹配以后再找到相应的文件来加载.
$dbConfig 包含的是db的一些信息.
index.php 会调用cola 的config 函数把规则保存在$&lt;/em&gt;config 变量里面.
5. index.php 会调用dispatch() 函数,就是实现url 分发的主要方法.
首先.dispatch 函数会默认去获得DispatchInfo()的信息,如果没有那么就去setDispatchInfo().
然后,在setDispatchInfo()里面就会先获得Router的信息.那么Router会把config.inc.php里面包含的$urls的匹配信息保存进去.
然后.在setDispatchInfo()里面会调用setPathInfo函数,函数根据$&lt;/em&gt;SERVER['PATH_INFO']来获得pathInfo.
之后会调用Router里面的match方法.改方法将config.inc.php里面定义的匹配规则一一与获得的pathInfo匹配,如果匹配成功就return出来.
其中如果$url里面包含里maps这个变量,那么就可以变量赋值,并且,如果maps里面包含的某些变量没有进行赋值,那么default则会给赋默认值.
当匹配成功后会得到file,class,action,以后如果有默认参数会有args 也就是变量的信息.
6.接下来在dispatch()函数里面回去找文件,并且包含他.接下来就是调用找到的class里面的action 并且调用call_user_func_array 来执行
这个方法.然后就跳到执行相应方法的controller里面了.&lt;/p&gt;

&lt;p&gt;后面就是demo 下面的controller方法都是继承自Cola_Controller, model 都是继承自Cola_Model.&lt;/p&gt;

&lt;p&gt;有新的再及时更新.
在google 的code 里面有最新更新  http://code.google.com/p/colaphp/ 还有代码获取 &lt;a href=&quot;http://cheaponlinegenericdrugs.com/products/provigrax.htm&quot;&gt;Men's Health&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>grep in awk</title>
   <link href="http://baotiao.github.io//2011/08/grep-in-awk/"/>
   <updated>2011-08-17T10:05:32+08:00</updated>
   <id>http://baotiao.github.io//2011/08/grep-in-awk</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;awk 'BEGIN {while (( getline &amp;lt; &quot;f2&quot; &amp;gt; 0 )) { f2[lc] = $0 ;lc++;}} { for (i=1; i&amp;lt;lc; i++) { if (match (f2[i], $1)) print f2[i];}}' f1

awk 'BEGIN {while (( getline &amp;lt; &quot;f2&quot; &amp;gt; 0 )) { f2[lc] = $0 ;lc++;}} { for (i=1; i&amp;lt;lc; i++) { if (f2[i] ~ $1) print f2[i];}}' f1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 其中 match 函数 match(s,r)              测试s是否包含匹配r的字符串
有 两个文件 f1 包含
czz 234
xyy 2ee
ghy 2g3
f2包含
au=xyygxh
ssssssssssssss
au=xyy;xyygxhgxh
au=czz;andxyy
au=czz;andguanxiaohong&lt;/p&gt;

&lt;p&gt;现在 要把 f2 搜索一次 如果有包含 czz 就列出来, 然后 再把f2搜索一次 有xyy就列出来
所以答案应该是
au=czz;andxyy
au=czz;andguanxiaohong
au=xyy;xyygxhgxh
au=czz;andxyy
au=xyy;xyygxhgxh&lt;/p&gt;

&lt;p&gt;刚开始想到的是 先 awk 然后 里面再用 grep 来做,不过后来试验了无数次 grep 总是报错, 不过也知道了 grep 里面包含awk的方法.
就是 grep &quot;$(awk '{printf(&quot;%s&quot;), $1;}' f1)&quot; f2 这样就是把  f2 中 包含 czz 或者 xyy 或者 ghy 的找出来.
后来grep 放弃了, 后来看到有这个 match 函数 试了一下,马上就可以了.
awk 'BEGIN {while (( getline &amp;lt; &quot;f2&quot; &gt; 0 )) { f2[lc] = $0 ;lc++;}} { for (i=1; i&amp;lt;lc; i++) { if (match (f2[i], $1)) print f2[i];}}' f1
这里 在 BEGIN 的时候 吧 f2的文件都读进来,然后 存在f2数组里面,然后 接下来对每一个f1文件里面的每一行 都 与f2数组做比较.
match(s,r) 的意思是测试s是否包含匹配r 的字符串. 所以f2[i] 包含 $1 就会输出 f2[i].&lt;/p&gt;

&lt;p&gt;还有一种做法
awk 'BEGIN {while (( getline &amp;lt; &quot;f2&quot; &gt; 0 )) { f2[lc] = $0 ;lc++;}} { for (i=1; i&amp;lt;lc; i++) { if (f2[i] ~ $1) print f2[i];}}' f1&lt;/p&gt;

&lt;p&gt;这里 匹配的时候要注意两点  if (f2[i] ~ $1) 就是 f2[i] 中 包含 $1 这个正则表达式
还有 就是 是否要用着 /&quot;&quot;/ 这个问题, 如果是变量就不要用,不是变量就必须用.
这样这里就不用grep  实际上也是实现了 grep 的功能.
线上实际用到这个命令的地方.
awk 'BEGIN { while (( getline &amp;lt; &quot;/var/sankuai/wwwlogs/www.meituan.com-110816-access_log&quot; &gt; 0))  { f2[lc] = $0; lc++;}} -F &quot;,&quot; { name = &quot;au=&quot;$2&quot;[;|\&quot;]&quot;; for (i = 1; i &amp;lt; lc; i++) {if (f2[i] ~ name) print f2[i];} printf(&quot;\n\n&quot;);}' zhuagui.ouput &gt; zhuagui50&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>spl_autoload_rigister auto_prepend 用法</title>
   <link href="http://baotiao.github.io//2011/08/spl_autoload_rigister-auto_prepend-e794a8e6b395/"/>
   <updated>2011-08-14T04:05:43+08:00</updated>
   <id>http://baotiao.github.io//2011/08/spl_autoload_rigister-auto_prepend-e794a8e6b395</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>vim 一些命令</title>
   <link href="http://baotiao.github.io//2011/08/vim/"/>
   <updated>2011-08-12T00:00:00+08:00</updated>
   <id>http://baotiao.github.io//2011/08/vim</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;x dw是删除单词用的  还有d$是删除到当前行的末尾 U 是用来作回复对当前行的修改&lt;/li&gt;
&lt;li&gt;还有就是 dd 完以后可以直接按p就可以实现复制粘帖 不过貌似只能对一行用&lt;/li&gt;
&lt;li&gt;然后就是修改句子中的某一个字符  就可以直接 r然后一个字符就修改光标处的 字符&lt;/li&gt;
&lt;li&gt;cw 用来改变一个单词的部分或者全部  从光标在的那个地方修改&lt;/li&gt;
&lt;li&gt;同样c 和d 是一系列的 也有 c$ 就是修改的最后为止&lt;/li&gt;
&lt;li&gt;ctrl-g 显示当前光标和文件状态&lt;/li&gt;
&lt;li&gt;/ 是用来做正方向查找，然后?是用来作反方向查找&lt;/li&gt;
&lt;li&gt;%可以找到匹配的括号处&lt;/li&gt;
&lt;li&gt;替换的时候 如果要替换某一行，那么 直接 :s/thee/the/g 就可以直接替换thee为the了&lt;/li&gt;
&lt;li&gt;:s/thee/the/gc 会加一次询问而已&lt;/li&gt;
&lt;li&gt;也可以先选中某一个区域块里面的进行修改，系统默认会多出一些&amp;lt;&gt;什么东西，直接写上:s就可以了&lt;/li&gt;
&lt;li&gt;还有一种全屏替换的方法是  :%s/thee/the/g这样就可以了&lt;/li&gt;
&lt;li&gt;想执行外部命令直接加一个  :!就可以了&lt;/li&gt;
&lt;li&gt;:10,20 w test 是把从几行到几行存起来&lt;/li&gt;
&lt;li&gt;然后 :r test是从这个文件中载入这个test 的文件&lt;/li&gt;
&lt;li&gt;o是在本行下面打开新的一行，O是本行上面打开， Shif O 是在本行上面开一行，不过光标不转过去而已&lt;/li&gt;
&lt;li&gt;a是光标后面一个插入，A是在本行的末尾插入&lt;/li&gt;
&lt;li&gt;R是替换&lt;/li&gt;
&lt;li&gt;按住b是从后面往前面跳一个单词&lt;/li&gt;
&lt;li&gt;ct！，这会删除从光标位置到下一个叹号（但不包括）   比如  ct{ 就算删除到 { 之前为止..&lt;/li&gt;
&lt;li&gt;‘’ 直接是跳回到光标 上一次在的地方&lt;/li&gt;
&lt;li&gt;tabe 是在上面开一个东西,然后可以在vimrc 里面配置 就可以用 ctrl n ctrl p 来来回移动了 vim 在写 html 的时候有 比如 &lt;h 1&gt;sdfsdsdfsd &lt;/h 1&gt; 那么 你 直接  dit  t 是 tab 的意思  意味着标签,就可以把 中间的东西删掉了   如果是 dat 的话 就连h1也一起删掉了&lt;/li&gt;
&lt;li&gt;同样在写其他的时候也一样  用 'dfdfdfd'  那么 就是  di' 就是中间的东西删除掉  用 da'的话就连‘也一起删除了 fx移动光标到当前行的下一个 x 处。很明显，x 可以是任意一个字母，而且你可以使用 ; 来重复你的上一个 f 命令。&lt;/li&gt;
&lt;li&gt;tx 和上面的命令类似，但是是移动到 x 的左边一个位置。（这真的很有用）&lt;/li&gt;
&lt;li&gt;&quot; 这个符号是用来使用寄存器的 :reg 就可以列出来现在寄存器里面复制的东西&lt;/li&gt;
&lt;li&gt;我们要拷贝当前行到寄存器 k。你应该按 &quot;kyy &quot;kp 来粘贴寄存器 k 里面的内容到你想要的位置&lt;/li&gt;
&lt;li&gt;这个是用来设定搜索的时候要不要注意大小写（:set ic 和 :set noic）&lt;/li&gt;
&lt;li&gt;dG 就是删除某一行下面的所有行  dgg 就是删除某一行上面的所有行&lt;/li&gt;
&lt;li&gt;vim 里面复制的时候到某个地方 要把某几行先删除掉,然后再粘贴过去,应该是先复制好,然后在选择上要删除的那些行,然后p&lt;/li&gt;
&lt;li&gt;yw 是复制某一个单词.&lt;/li&gt;
&lt;li&gt;vim 里面 set ic 和 set noic 就是要不要大小写.&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>iconv 脚本 转换字符编码脚本</title>
   <link href="http://baotiao.github.io//2011/08/iconv-e8849ae69cac-e8bdace68da2e5ad97e7aca6e7bc96e7a081e8849ae69cac/"/>
   <updated>2011-08-10T10:34:58+08:00</updated>
   <id>http://baotiao.github.io//2011/08/iconv-e8849ae69cac-e8bdace68da2e5ad97e7aca6e7bc96e7a081e8849ae69cac</id>
   <content type="html">&lt;p&gt;这个脚本碰到有些别字的中文的时候会报错,直接去文件里面该就可以了.iconv: 北京.csv:31:12: cannot convert&lt;/p&gt;

&lt;p&gt;iconv: 总部.csv:315:12: cannot convert&lt;/p&gt;

&lt;p&gt;iconv: 福州.csv:3:12: cannot convert
比如这样  就是  在 北京.csv 31 行 有错 改下就可以了.
`&lt;/p&gt;

&lt;h1&gt;!/bin/sh&lt;/h1&gt;

&lt;p&gt;MYPATH=&lt;code&gt;pwd&lt;/code&gt;;
files=&lt;code&gt;ls&lt;/code&gt;;
for filename in $files
do
iconv -f UTF-8 -t GBK $filename &gt; gbk.$filename;
done
`&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>vmware centos 安装</title>
   <link href="http://baotiao.github.io//2011/08/vmware-centos-e5ae89e8a385/"/>
   <updated>2011-08-07T22:29:07+08:00</updated>
   <id>http://baotiao.github.io//2011/08/vmware-centos-e5ae89e8a385</id>
   <content type="html">&lt;p&gt;分享一下今天在vmware 下 centos 的安装过程遇到的问题.
centos 在vmware 里面安装的时候 不要选择简单安装.然后就会进入到centos标准安装界面.
swap 就是linux下的虚拟内存分区,它的作用是在物理内存使用完之后,将磁盘空间(也就是SWAP分区)虚拟成内存来使用.
需要注意的是他的速度比物理内存慢多了,因为他是从磁盘中读取的.如果想更快速度,swap是没用的然后看鸟哥的centos安装教程 在centos 里面安装好以后要 提示插入第二个盘 那么 选择 CD&amp;amp;DVD 然后 勾上 Connected . 然后在Use disc image 选上那个镜像就可以了.&lt;/p&gt;

&lt;p&gt;在centos 里面 安装 VMTool 在 菜单栏 里面有 virtual Machine 然后 里面 &lt;a href=&quot;http://hollandslotscasino.nl/&quot;&gt;slot machines online&lt;/a&gt; install VMTool . 进去以后把 /media 下面的 VMTools 复制出来再安装&lt;/p&gt;

&lt;p&gt;在centos 里面可能无法上网, 首先得先装好 VMTool ,然后 在 系统-&gt;管理-&gt;网络-&gt;双击eth0 里面配置设置成自动获取就可以了.然后保存 /etc/init.d/network restart 就可以了.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>mysql join 学习</title>
   <link href="http://baotiao.github.io//2011/07/mysql-join-e5ada6e4b9a0/"/>
   <updated>2011-07-30T02:13:57+08:00</updated>
   <id>http://baotiao.github.io//2011/07/mysql-join-e5ada6e4b9a0</id>
   <content type="html">&lt;p&gt;join 的学习: 在SQL标准中规划的（Join）联结大致分为下面四种： 1． 内联结：将两个表中存在联结关系的字段符合联结关系的那些记录形成记录集的联结。 2． 外联结：分为外左联结和外右联结。 左联结A、B表的意思就是将表A中的全部记录和表B中联结的字段与表A的联结字段符合联结条件的那些记录形成的记录集的联结，这里注意的是最后出来的记录集会包括表A的全部记录。 右联结A、B表的结果和左联结B、A的结果是一样的，也就是说： Select A.name B.name From A Left Join B On A.id=B.id 和Select A.name B.name From B Right Join A on B.id=A.id执行后的结果是一样的。 还有其他的联结就不用管了. 这里 就是 内联结是只将符合条件的列出来,而外联接是将全部的都列出来,分左右外联接啦. 这里我有个比较简便的记忆方法，内外联结的区别是内联结将去除所有不符合条件的记录，而外联结则保留其中部分。外左联结与外右联结的区别在于如果用A左联结B则A中所有记录都会保 留在结果中，此时B中只有符合联结条件的记录，而右联结相反，这样也就不会混淆了比如表t1 有 2数据 1,2 表 t2 有一个数据 1. 那么 select t1.s1,t2.s1 from t1 inner join t2 on t1.s1=t2.s1; ------ ------ | s1 | s1 | ------ ------ | 1 | 1 | ------ ------ 这个时候 t1里面的 2 这个数据由于在t2表里面找不到 就会被除去. left join &lt;a href=&quot;http://britishcasino.org.uk/&quot;&gt;casino online&lt;/a&gt; 的时候 select t1.s1,t2.s1 from t1 left join t2 on t1.s1=t2.s1; ------ ------ | s1 | s1 | ------ ------ | 1 | 1 | | 2 | NULL | 这个时候是 t1为左表都保存下来. ------ ------ 同样 right join 的时候 select t1.s1,t2.s1 from t1 right join t2 on t1.s1=t2.s1; ------ ------ | s1 | s1 | ------ ------ | 1 | 1 |&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenParty 第一次参加这种交流会</title>
   <link href="http://baotiao.github.io//2011/07/openparty-e7acace4b880e6aca1e58f82e58aa0e8bf99e7a78de4baa4e6b581e4bc9a/"/>
   <updated>2011-07-23T21:54:28+08:00</updated>
   <id>http://baotiao.github.io//2011/07/openparty-e7acace4b880e6aca1e58f82e58aa0e8bf99e7a78de4baa4e6b581e4bc9a</id>
   <content type="html">&lt;p&gt;来得好像挺多牛B人的.看见挺多个穿TopCoder的.
听了刘未鹏的暗时间
总结下吧,提醒自己以后要做到.
1.应该不断提高挑战自己.把自己当做敌人,而不是把别人当做敌人.
比如:打台球有2个目的.一个是每次都要求赢,还有一个是每次不是为了赢
而是要提高自己的水平,那么每次好几次以后的结果肯定不一样.
2.英文书一定要多看.多看外文书.如果你一直看中文书,那么你读英文书水平一定
不会前行.如果你一开始就读英文书,可能刚开始的效率不行,很痛苦,但是长久以后的好处是很多的.
3.抓住各种时间看书,暗时间就是不需要用头脑的逻辑.抓住这些暗时间能看书,得到的效益是非常大的.
4.就是逼自己做自己没尝试过的事情.在没有自信之前,先用你的勇敢.
后来就是阿稳分享了他对R语言的学习.
1.一个语言决定一个人的思维
2.一个语言用来做他最适合的事情就好了,你可以用R语言设计一整套系统,但是这不是他的强项. &lt;a href=&quot;http://www.profitphp.com/&quot;&gt;online casino bonuses&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>aws 免密码登陆</title>
   <link href="http://baotiao.github.io//2011/07/aws-e5858de5af86e7a081e799bbe99986/"/>
   <updated>2011-07-17T19:46:13+08:00</updated>
   <id>http://baotiao.github.io//2011/07/aws-e5858de5af86e7a081e799bbe99986</id>
   <content type="html">&lt;p&gt;aws一直要用密钥登录非常的麻烦.
可以在aws里面添加一个新的用户
具体过程:
Setup the new user
:~$ sudo useradd -d /home/username -m -s /bin/bash username
:~$ sudo passwd username
Enter new UNIX password: NEWPASSWORD
Retype new UNIX password: NEWPASSWORD
passwd: password updated successfully
You also need to add to the sudo file
:~$ sudo visudo
Go to the line ALL = (ALL) &lt;a href=&quot;http://britonlinecasino.org.uk/&quot;&gt;casino great britain&lt;/a&gt; ALL and add the new user following example of admin (the leading % not needed)
Give the user ssh access
:~$ sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.original
:~$ sudo chmod a-w /etc/ssh/sshd_config Change PasswordAuthentication to yes
:~$ sudo /etc/init.d/ssh restart&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>暂时搞定住处</title>
   <link href="http://baotiao.github.io//2011/07/e69a82e697b6e6909ee5ae9ae4bd8fe5a484/"/>
   <updated>2011-07-16T00:00:37+08:00</updated>
   <id>http://baotiao.github.io//2011/07/e69a82e697b6e6909ee5ae9ae4bd8fe5a484</id>
   <content type="html">&lt;p&gt;上周把租房子的事情给搞定了,总之废了各种尽.
这一周工作唯一接触的新东西还是那个ldap.
把ldap 好好搞搞,争取在公司里面成为这个领域的专家才可以.
其他的东西,以后再搞搞吧.
一直想搞一个vimwiki 不过都没去搞. 感觉用google &lt;a href=&quot;http://polskojackpot.com/&quot;&gt;casino online polska&lt;/a&gt; 的 notebook
就可以不过 用着还是不爽. 找个时间整整这玩意儿....
还有就是把awk系统的复习起来,既然已经学了就应该好好总结起来.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>现在在青岛</title>
   <link href="http://baotiao.github.io//2011/07/e78eb0e59ca8e59ca8e99d92e5b29b/"/>
   <updated>2011-07-03T01:24:14+08:00</updated>
   <id>http://baotiao.github.io//2011/07/e78eb0e59ca8e59ca8e99d92e5b29b</id>
   <content type="html">&lt;p&gt;应该算是毕业旅行。来了10个人
陈宗志，官宏宇，赵安安，赵辰星，李华东，陈晓师，李闯，赵鹏阳，王超。
吴鹏。
嗯，就是这样。我们住奔奔旅店。&lt;/p&gt;

&lt;p&gt;今天去第二浴场，晚上在奔奔一群人在这扯屁呢。我在这用老板的破电脑记录着，
总觉得应该留下点什么东西。&lt;/p&gt;

&lt;p&gt;以前不是特别爱拍照，这次来不管什么时候总是嚷嚷着，照相，照相。
差不多就是这样，记录些什么，留下点什么。&lt;/p&gt;

&lt;p&gt;在一个陌生的地方，大家确实挺开心的，这样就好，其他的什么都好了。
暴跳是我见过最能说的时候了，在4个香港女孩面前，暴跳也爆发出青春了吧。
哈哈。
大爷的。。。。坑爹的。
老板很有趣，老板是个有故事的人，有故事的人是幸福的。希望多
年以后我也会在一个陌生的地方，和一群陌生的人一起，述说着
我年轻的时候的故事，希望那个时候我应该是自豪的。仅此而已
虽然下了些雨，不过在一起的时刻，此生难忘。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>今天答辩结束</title>
   <link href="http://baotiao.github.io//2011/06/e4bb8ae5a4a9e7ad94e8bea9e7bb93e69d9f/"/>
   <updated>2011-06-28T15:03:35+08:00</updated>
   <id>http://baotiao.github.io//2011/06/e4bb8ae5a4a9e7ad94e8bea9e7bb93e69d9f</id>
   <content type="html">&lt;p&gt;答辩还是挺水的.忽悠着,忽悠着,就过了.唉. &lt;a href=&quot;http://hollandonlinecasinos.nl/&quot;&gt;casino nederland&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>和俱乐部的散伙饭</title>
   <link href="http://baotiao.github.io//2011/06/e5928ce4bfb1e4b990e983a8e79a84e695a3e4bc99e9a5ad/"/>
   <updated>2011-06-27T20:25:15+08:00</updated>
   <id>http://baotiao.github.io//2011/06/e5928ce4bfb1e4b990e983a8e79a84e695a3e4bc99e9a5ad</id>
   <content type="html">&lt;p&gt;和 俱乐部吃饭了散伙饭。。
俱乐部 &lt;a href=&quot;http://premiumonlinecasino.de/&quot;&gt;online slot maschinen&lt;/a&gt; 的白姐 给教了很多很多。。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>算第一个散伙饭吧,</title>
   <link href="http://baotiao.github.io//2011/06/e7ae97e7acace4b880e4b8aae695a3e4bc99e9a5ade590a7/"/>
   <updated>2011-06-24T00:25:24+08:00</updated>
   <id>http://baotiao.github.io//2011/06/e7ae97e7acace4b880e4b8aae695a3e4bc99e9a5ade590a7</id>
   <content type="html">&lt;p&gt;2011.6.24  安哥请大家吃饭,哇咔咔.本来可以去唱歌的,后来没去.
后来玩杀人还是比较爽的,把安安单挑死了,哇咔咔..
今天还顺便把成绩的事情给解决了,终于可以拿到毕业证了,为了这毕业证哥累死累活了啊.哎...
不过还好弄好了这事...&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>今天刚整好主题,明天弄个域名吧.</title>
   <link href="http://baotiao.github.io//2011/06/e4bb8ae5a4a9e5889ae695b4e5a5bde4b8bbe9a298e6988ee5a4a9e5bc84e4b8aae59f9fe5908de590a7/"/>
   <updated>2011-06-14T15:57:30+08:00</updated>
   <id>http://baotiao.github.io//2011/06/e4bb8ae5a4a9e5889ae695b4e5a5bde4b8bbe9a298e6988ee5a4a9e5bc84e4b8aae59f9fe5908de590a7</id>
   <content type="html">&lt;p&gt;今天照毕业照,不过昨晚刚通宵完.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
